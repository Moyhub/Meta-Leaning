nohup: 忽略输入
2022-01-11 16:02:59:INFO:Finish setting logger...
2022-01-11 16:02:59:INFO:==> Training/Evaluation parameters are:
2022-01-11 16:02:59:INFO:	Namespace(model_dir='cnn2dmodels/data-1_n_epochs-5_aug-150_noise-0.01_supportSize-0_innerSteps-1_lrMeta-0.001_lrInner-0.0001_warmUp-0.0_seed-42'
2022-01-11 16:02:59:INFO:	data_fn=1
2022-01-11 16:02:59:INFO:	datatest_fn=1
2022-01-11 16:02:59:INFO:	filter_kernel_size=1
2022-01-11 16:02:59:INFO:	override_data_cache=False
2022-01-11 16:02:59:INFO:	maxRUL=125
2022-01-11 16:02:59:INFO:	low_ratio=0.1
2022-01-11 16:02:59:INFO:	high_ratio=0.99
2022-01-11 16:02:59:INFO:	aug_ratio=150
2022-01-11 16:02:59:INFO:	noise_amplitude=0.01
2022-01-11 16:02:59:INFO:	modeltype='cnn2d'
2022-01-11 16:02:59:INFO:	max_seq_len=550
2022-01-11 16:02:59:INFO:	d_model=128
2022-01-11 16:02:59:INFO:	p_dropout=0.1
2022-01-11 16:02:59:INFO:	n_head=4
2022-01-11 16:02:59:INFO:	n_layer=2
2022-01-11 16:02:59:INFO:	dim_feedforward=512
2022-01-11 16:02:59:INFO:	e_dropout=0.1
2022-01-11 16:02:59:INFO:	activation='relu'
2022-01-11 16:02:59:INFO:	layer_norm=False
2022-01-11 16:02:59:INFO:	support_size=0
2022-01-11 16:02:59:INFO:	inner_steps=1
2022-01-11 16:02:59:INFO:	lr_inner=0.0001
2022-01-11 16:02:59:INFO:	lr_meta=0.001
2022-01-11 16:02:59:INFO:	n_epochs=5
2022-01-11 16:02:59:INFO:	train_batch_size=20
2022-01-11 16:02:59:INFO:	eval_batch_size=1
2022-01-11 16:02:59:INFO:	lr=0.001
2022-01-11 16:02:59:INFO:	weight_decay=0.01
2022-01-11 16:02:59:INFO:	warmup_ratio=0.0
2022-01-11 16:02:59:INFO:	max_grad_norm=5.0
2022-01-11 16:02:59:INFO:	logging_steps=50
2022-01-11 16:02:59:INFO:	seed=42
2022-01-11 16:02:59:INFO:	gpu_id=2
2022-01-11 16:02:59:INFO:	do_train=True
2022-01-11 16:02:59:INFO:	do_eval=False
2022-01-11 16:02:59:INFO:	train_data_fn='data/train_FD001.txt'
2022-01-11 16:02:59:INFO:	test_data_fn='data/test_FD001.txt'
2022-01-11 16:02:59:INFO:	target_ruls_fn='data/RUL_FD001.txt'
2022-01-11 16:02:59:INFO:	device=device(type='cuda'))
2022-01-11 16:02:59:INFO:Dump arguments to cnn2dmodels/data-1_n_epochs-5_aug-150_noise-0.01_supportSize-0_innerSteps-1_lrMeta-0.001_lrInner-0.0001_warmUp-0.0_seed-42...
2022-01-11 16:02:59:INFO:==> Read data from data/train_FD001.txt...
2022-01-11 16:02:59:INFO:	The selected feature idxs are: 0, 1, 4, 5, 6, 9, 10, 11, 13, 14, 15, 16, 17, 19, 22, 23
2022-01-11 16:02:59:INFO:==> Min_max normalization...
2022-01-11 16:02:59:INFO:	The min value is [-0.008700000122189522, -0.0006000000284984708, 641.2100219726562, 1571.0400390625, 1382.25, 549.8499755859375, 2387.89990234375, 9021.73046875, 46.849998474121094, 518.6900024414062, 2387.8798828125, 8099.93994140625, 8.324899673461914, 388.0, 38.13999938964844, 22.89419937133789]
2022-01-11 16:02:59:INFO:	The max value is [0.008700000122189522, 0.0006000000284984708, 644.530029296875, 1616.9100341796875, 1441.489990234375, 556.0599975585938, 2388.56005859375, 9244.58984375, 48.529998779296875, 523.3800048828125, 2388.56005859375, 8293.7197265625, 8.584799766540527, 400.0, 39.43000030517578, 23.61840057373047]
2022-01-11 16:02:59:INFO:==> Read data from data/test_FD001.txt...
2022-01-11 16:02:59:INFO:	The selected feature idxs are: 0, 1, 4, 5, 6, 9, 10, 11, 13, 14, 15, 16, 17, 19, 22, 23
2022-01-11 16:02:59:INFO:==> Read RULsfrom data/RUL_FD001.txt...
2022-01-11 16:02:59:INFO:	min_rul: 7, max_rul: 145
2022-01-11 16:02:59:INFO:==> Input length ratio of the [TEST] data:
2022-01-11 16:02:59:INFO:	min_ratio = 0.2067
2022-01-11 16:02:59:INFO:	max_ratio = 0.9667
2022-01-11 16:02:59:INFO:==> Min_max normalization...
2022-01-11 16:02:59:INFO:	With given min value [-0.008700000122189522, -0.0006000000284984708, 641.2100219726562, 1571.0400390625, 1382.25, 549.8499755859375, 2387.89990234375, 9021.73046875, 46.849998474121094, 518.6900024414062, 2387.8798828125, 8099.93994140625, 8.324899673461914, 388.0, 38.13999938964844, 22.89419937133789]
2022-01-11 16:02:59:INFO:	With given max value [0.008700000122189522, 0.0006000000284984708, 644.530029296875, 1616.9100341796875, 1441.489990234375, 556.0599975585938, 2388.56005859375, 9244.58984375, 48.529998779296875, 523.3800048828125, 2388.56005859375, 8293.7197265625, 8.584799766540527, 400.0, 39.43000030517578, 23.61840057373047]
2022-01-11 16:03:02:INFO:Note: NumExpr detected 40 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2022-01-11 16:03:02:INFO:NumExpr defaulting to 8 threads.
2022-01-11 16:03:03:INFO:=============== Scheme: Normal Learning ===============
2022-01-11 16:03:03:INFO:	Num examples = 15000
2022-01-11 16:03:03:INFO:	Num epochs = 5
2022-01-11 16:03:03:INFO:	Batch size = 20
2022-01-11 16:03:03:INFO:	Total optimization steps = 3750
2022-01-11 16:03:09:INFO:==> Group parameters for optimization...
2022-01-11 16:03:09:INFO:    Parameters to update are:
2022-01-11 16:03:09:INFO:	conv1.0.weight
2022-01-11 16:03:09:INFO:	conv2.0.weight
2022-01-11 16:03:09:INFO:	conv3.0.weight
2022-01-11 16:03:09:INFO:	conv4.0.weight
2022-01-11 16:03:09:INFO:	conv5.0.weight
2022-01-11 16:03:09:INFO:	fc_1.0.weight
2022-01-11 16:03:09:INFO:	fc_1.0.bias
2022-01-11 16:03:09:INFO:	fc_2.weight
2022-01-11 16:03:09:INFO:	fc_2.bias
/data/moy20/Meta-Learning/Meta-prognosis-main/optimizer.py:78: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448255797/work/torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
/data/moy20/miniconda3/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
2022-01-11 16:03:10:INFO:Epoch: 0	 global_step: 0/3750	 lr: 0.00100	 loss: 0.0017
2022-01-11 16:03:22:INFO:Epoch: 0	 global_step: 50/3750	 lr: 0.00099	 loss: 0.0249
2022-01-11 16:03:35:INFO:Epoch: 0	 global_step: 100/3750	 lr: 0.00097	 loss: 0.0078
2022-01-11 16:03:47:INFO:Epoch: 0	 global_step: 150/3750	 lr: 0.00096	 loss: 0.0073
2022-01-11 16:03:59:INFO:Epoch: 0	 global_step: 200/3750	 lr: 0.00095	 loss: 0.0053
2022-01-11 16:04:12:INFO:Epoch: 0	 global_step: 250/3750	 lr: 0.00093	 loss: 0.0039
2022-01-11 16:04:24:INFO:Epoch: 0	 global_step: 300/3750	 lr: 0.00092	 loss: 0.0036
2022-01-11 16:04:37:INFO:Epoch: 0	 global_step: 350/3750	 lr: 0.00091	 loss: 0.0024
2022-01-11 16:04:49:INFO:Epoch: 0	 global_step: 400/3750	 lr: 0.00089	 loss: 0.0018
2022-01-11 16:05:01:INFO:Epoch: 0	 global_step: 450/3750	 lr: 0.00088	 loss: 0.0015
2022-01-11 16:05:14:INFO:Epoch: 0	 global_step: 500/3750	 lr: 0.00087	 loss: 0.0014
2022-01-11 16:05:26:INFO:Epoch: 0	 global_step: 550/3750	 lr: 0.00085	 loss: 0.0014
2022-01-11 16:05:38:INFO:Epoch: 0	 global_step: 600/3750	 lr: 0.00084	 loss: 0.0013
2022-01-11 16:05:51:INFO:Epoch: 0	 global_step: 650/3750	 lr: 0.00083	 loss: 0.0012
2022-01-11 16:06:03:INFO:Epoch: 0	 global_step: 700/3750	 lr: 0.00081	 loss: 0.0011
2022-01-11 16:06:16:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-11 16:06:16:INFO:	Num examples = 100
2022-01-11 16:06:16:INFO:	RMSE = 15.6714
2022-01-11 16:06:18:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-11 16:06:18:INFO:	Num examples = 100
2022-01-11 16:06:18:INFO:	RMSE = 31.2521
2022-01-11 16:06:18:INFO:==> Minimal valid RMSE!
2022-01-11 16:06:18:INFO:Save model to cnn2dmodels/data-1_n_epochs-5_aug-150_noise-0.01_supportSize-0_innerSteps-1_lrMeta-0.001_lrInner-0.0001_warmUp-0.0_seed-42...
2022-01-11 16:06:18:INFO:Epoch: 1	 global_step: 750/3750	 lr: 0.00080	 loss: 0.0010
2022-01-11 16:06:30:INFO:Epoch: 1	 global_step: 800/3750	 lr: 0.00079	 loss: 0.0011
2022-01-11 16:06:42:INFO:Epoch: 1	 global_step: 850/3750	 lr: 0.00077	 loss: 0.0010
2022-01-11 16:06:55:INFO:Epoch: 1	 global_step: 900/3750	 lr: 0.00076	 loss: 0.0010
2022-01-11 16:07:07:INFO:Epoch: 1	 global_step: 950/3750	 lr: 0.00075	 loss: 0.0013
2022-01-11 16:07:19:INFO:Epoch: 1	 global_step: 1000/3750	 lr: 0.00073	 loss: 0.0010
2022-01-11 16:07:32:INFO:Epoch: 1	 global_step: 1050/3750	 lr: 0.00072	 loss: 0.0009
2022-01-11 16:07:44:INFO:Epoch: 1	 global_step: 1100/3750	 lr: 0.00071	 loss: 0.0008
2022-01-11 16:07:56:INFO:Epoch: 1	 global_step: 1150/3750	 lr: 0.00069	 loss: 0.0009
2022-01-11 16:08:09:INFO:Epoch: 1	 global_step: 1200/3750	 lr: 0.00068	 loss: 0.0010
2022-01-11 16:08:21:INFO:Epoch: 1	 global_step: 1250/3750	 lr: 0.00067	 loss: 0.0008
2022-01-11 16:08:33:INFO:Epoch: 1	 global_step: 1300/3750	 lr: 0.00065	 loss: 0.0007
2022-01-11 16:08:46:INFO:Epoch: 1	 global_step: 1350/3750	 lr: 0.00064	 loss: 0.0007
2022-01-11 16:08:58:INFO:Epoch: 1	 global_step: 1400/3750	 lr: 0.00063	 loss: 0.0006
2022-01-11 16:09:10:INFO:Epoch: 1	 global_step: 1450/3750	 lr: 0.00061	 loss: 0.0006
2022-01-11 16:09:24:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-11 16:09:24:INFO:	Num examples = 100
2022-01-11 16:09:24:INFO:	RMSE = 14.9154
2022-01-11 16:09:25:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-11 16:09:25:INFO:	Num examples = 100
2022-01-11 16:09:25:INFO:	RMSE = 28.9345
2022-01-11 16:09:25:INFO:==> Minimal valid RMSE!
2022-01-11 16:09:25:INFO:Save model to cnn2dmodels/data-1_n_epochs-5_aug-150_noise-0.01_supportSize-0_innerSteps-1_lrMeta-0.001_lrInner-0.0001_warmUp-0.0_seed-42...
2022-01-11 16:09:25:INFO:Epoch: 2	 global_step: 1500/3750	 lr: 0.00060	 loss: 0.0006
2022-01-11 16:09:38:INFO:Epoch: 2	 global_step: 1550/3750	 lr: 0.00059	 loss: 0.0007
2022-01-11 16:09:50:INFO:Epoch: 2	 global_step: 1600/3750	 lr: 0.00057	 loss: 0.0006
2022-01-11 16:10:02:INFO:Epoch: 2	 global_step: 1650/3750	 lr: 0.00056	 loss: 0.0006
2022-01-11 16:10:15:INFO:Epoch: 2	 global_step: 1700/3750	 lr: 0.00055	 loss: 0.0006
2022-01-11 16:10:27:INFO:Epoch: 2	 global_step: 1750/3750	 lr: 0.00053	 loss: 0.0006
2022-01-11 16:10:39:INFO:Epoch: 2	 global_step: 1800/3750	 lr: 0.00052	 loss: 0.0006
2022-01-11 16:10:52:INFO:Epoch: 2	 global_step: 1850/3750	 lr: 0.00051	 loss: 0.0006
2022-01-11 16:11:04:INFO:Epoch: 2	 global_step: 1900/3750	 lr: 0.00049	 loss: 0.0006
2022-01-11 16:11:16:INFO:Epoch: 2	 global_step: 1950/3750	 lr: 0.00048	 loss: 0.0006
2022-01-11 16:11:29:INFO:Epoch: 2	 global_step: 2000/3750	 lr: 0.00047	 loss: 0.0005
2022-01-11 16:11:41:INFO:Epoch: 2	 global_step: 2050/3750	 lr: 0.00045	 loss: 0.0005
2022-01-11 16:11:53:INFO:Epoch: 2	 global_step: 2100/3750	 lr: 0.00044	 loss: 0.0005
2022-01-11 16:12:06:INFO:Epoch: 2	 global_step: 2150/3750	 lr: 0.00043	 loss: 0.0005
2022-01-11 16:12:18:INFO:Epoch: 2	 global_step: 2200/3750	 lr: 0.00041	 loss: 0.0005
2022-01-11 16:12:31:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-11 16:12:31:INFO:	Num examples = 100
2022-01-11 16:12:31:INFO:	RMSE = 14.2476
2022-01-11 16:12:33:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-11 16:12:33:INFO:	Num examples = 100
2022-01-11 16:12:33:INFO:	RMSE = 24.5792
2022-01-11 16:12:33:INFO:==> Minimal valid RMSE!
2022-01-11 16:12:33:INFO:Save model to cnn2dmodels/data-1_n_epochs-5_aug-150_noise-0.01_supportSize-0_innerSteps-1_lrMeta-0.001_lrInner-0.0001_warmUp-0.0_seed-42...
2022-01-11 16:12:33:INFO:Epoch: 3	 global_step: 2250/3750	 lr: 0.00040	 loss: 0.0005
2022-01-11 16:12:45:INFO:Epoch: 3	 global_step: 2300/3750	 lr: 0.00039	 loss: 0.0006
2022-01-11 16:12:58:INFO:Epoch: 3	 global_step: 2350/3750	 lr: 0.00037	 loss: 0.0005
2022-01-11 16:13:10:INFO:Epoch: 3	 global_step: 2400/3750	 lr: 0.00036	 loss: 0.0005
2022-01-11 16:13:22:INFO:Epoch: 3	 global_step: 2450/3750	 lr: 0.00035	 loss: 0.0005
2022-01-11 16:13:35:INFO:Epoch: 3	 global_step: 2500/3750	 lr: 0.00033	 loss: 0.0005
2022-01-11 16:13:47:INFO:Epoch: 3	 global_step: 2550/3750	 lr: 0.00032	 loss: 0.0004
2022-01-11 16:13:59:INFO:Epoch: 3	 global_step: 2600/3750	 lr: 0.00031	 loss: 0.0005
2022-01-11 16:14:12:INFO:Epoch: 3	 global_step: 2650/3750	 lr: 0.00029	 loss: 0.0004
2022-01-11 16:14:24:INFO:Epoch: 3	 global_step: 2700/3750	 lr: 0.00028	 loss: 0.0005
2022-01-11 16:14:37:INFO:Epoch: 3	 global_step: 2750/3750	 lr: 0.00027	 loss: 0.0004
2022-01-11 16:14:49:INFO:Epoch: 3	 global_step: 2800/3750	 lr: 0.00025	 loss: 0.0004
2022-01-11 16:15:01:INFO:Epoch: 3	 global_step: 2850/3750	 lr: 0.00024	 loss: 0.0004
2022-01-11 16:15:14:INFO:Epoch: 3	 global_step: 2900/3750	 lr: 0.00023	 loss: 0.0004
2022-01-11 16:15:26:INFO:Epoch: 3	 global_step: 2950/3750	 lr: 0.00021	 loss: 0.0004
2022-01-11 16:15:40:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-11 16:15:40:INFO:	Num examples = 100
2022-01-11 16:15:40:INFO:	RMSE = 12.9827
2022-01-11 16:15:41:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-11 16:15:41:INFO:	Num examples = 100
2022-01-11 16:15:41:INFO:	RMSE = 25.9192
2022-01-11 16:15:41:INFO:Epoch: 4	 global_step: 3000/3750	 lr: 0.00020	 loss: 0.0004
2022-01-11 16:15:53:INFO:Epoch: 4	 global_step: 3050/3750	 lr: 0.00019	 loss: 0.0003
2022-01-11 16:16:06:INFO:Epoch: 4	 global_step: 3100/3750	 lr: 0.00017	 loss: 0.0004
2022-01-11 16:16:18:INFO:Epoch: 4	 global_step: 3150/3750	 lr: 0.00016	 loss: 0.0003
2022-01-11 16:16:30:INFO:Epoch: 4	 global_step: 3200/3750	 lr: 0.00015	 loss: 0.0004
2022-01-11 16:16:43:INFO:Epoch: 4	 global_step: 3250/3750	 lr: 0.00013	 loss: 0.0004
2022-01-11 16:16:55:INFO:Epoch: 4	 global_step: 3300/3750	 lr: 0.00012	 loss: 0.0004
2022-01-11 16:17:07:INFO:Epoch: 4	 global_step: 3350/3750	 lr: 0.00011	 loss: 0.0003
2022-01-11 16:17:20:INFO:Epoch: 4	 global_step: 3400/3750	 lr: 0.00009	 loss: 0.0003
2022-01-11 16:17:32:INFO:Epoch: 4	 global_step: 3450/3750	 lr: 0.00008	 loss: 0.0003
2022-01-11 16:17:44:INFO:Epoch: 4	 global_step: 3500/3750	 lr: 0.00007	 loss: 0.0003
2022-01-11 16:17:57:INFO:Epoch: 4	 global_step: 3550/3750	 lr: 0.00005	 loss: 0.0003
2022-01-11 16:18:09:INFO:Epoch: 4	 global_step: 3600/3750	 lr: 0.00004	 loss: 0.0003
2022-01-11 16:18:21:INFO:Epoch: 4	 global_step: 3650/3750	 lr: 0.00003	 loss: 0.0003
2022-01-11 16:18:34:INFO:Epoch: 4	 global_step: 3700/3750	 lr: 0.00001	 loss: 0.0003
2022-01-11 16:18:47:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-11 16:18:47:INFO:	Num examples = 100
2022-01-11 16:18:47:INFO:	RMSE = 13.0163
2022-01-11 16:18:48:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-11 16:18:48:INFO:	Num examples = 100
2022-01-11 16:18:48:INFO:	RMSE = 25.8875
2022-01-11 16:18:48:INFO:	Output TEST RMSE:	14.2476
2022-01-11 16:18:48:INFO:	VALID RMSEs:	31.2521	28.9345	24.5792	25.9192	25.8875
2022-01-11 16:18:48:INFO:	TEST RMSEs:	15.6714	14.9154	14.2476	12.9827	13.0163
!!! Reset batch info !!! mode: [TRAIN]
!!! Reset batch info !!! mode: [TEST]
!!! Reset batch info !!! mode: [VALID]
!!! Reset batch info !!! mode: [TRAIN]
!!! Reset batch info !!! mode: [TEST]
!!! Reset batch info !!! mode: [VALID]
!!! Reset batch info !!! mode: [TRAIN]
!!! Reset batch info !!! mode: [TEST]
!!! Reset batch info !!! mode: [VALID]
!!! Reset batch info !!! mode: [TRAIN]
!!! Reset batch info !!! mode: [TEST]
!!! Reset batch info !!! mode: [VALID]
2022-01-11 16:18:51:INFO:Finish setting logger...
2022-01-11 16:18:51:INFO:==> Training/Evaluation parameters are:
2022-01-11 16:18:51:INFO:	Namespace(model_dir='cnn2dmodels/data-1_n_epochs-5_aug-150_noise-0.01_supportSize-0_innerSteps-1_lrMeta-0.001_lrInner-0.0001_warmUp-0.0_seed-667'
2022-01-11 16:18:51:INFO:	data_fn=1
2022-01-11 16:18:51:INFO:	datatest_fn=1
2022-01-11 16:18:51:INFO:	filter_kernel_size=1
2022-01-11 16:18:51:INFO:	override_data_cache=False
2022-01-11 16:18:51:INFO:	maxRUL=125
2022-01-11 16:18:51:INFO:	low_ratio=0.1
2022-01-11 16:18:51:INFO:	high_ratio=0.99
2022-01-11 16:18:51:INFO:	aug_ratio=150
2022-01-11 16:18:51:INFO:	noise_amplitude=0.01
2022-01-11 16:18:51:INFO:	modeltype='cnn2d'
2022-01-11 16:18:51:INFO:	max_seq_len=550
2022-01-11 16:18:51:INFO:	d_model=128
2022-01-11 16:18:51:INFO:	p_dropout=0.1
2022-01-11 16:18:51:INFO:	n_head=4
2022-01-11 16:18:51:INFO:	n_layer=2
2022-01-11 16:18:51:INFO:	dim_feedforward=512
2022-01-11 16:18:51:INFO:	e_dropout=0.1
2022-01-11 16:18:51:INFO:	activation='relu'
2022-01-11 16:18:51:INFO:	layer_norm=False
2022-01-11 16:18:51:INFO:	support_size=0
2022-01-11 16:18:51:INFO:	inner_steps=1
2022-01-11 16:18:51:INFO:	lr_inner=0.0001
2022-01-11 16:18:51:INFO:	lr_meta=0.001
2022-01-11 16:18:51:INFO:	n_epochs=5
2022-01-11 16:18:51:INFO:	train_batch_size=20
2022-01-11 16:18:51:INFO:	eval_batch_size=1
2022-01-11 16:18:51:INFO:	lr=0.001
2022-01-11 16:18:51:INFO:	weight_decay=0.01
2022-01-11 16:18:51:INFO:	warmup_ratio=0.0
2022-01-11 16:18:51:INFO:	max_grad_norm=5.0
2022-01-11 16:18:51:INFO:	logging_steps=50
2022-01-11 16:18:51:INFO:	seed=667
2022-01-11 16:18:51:INFO:	gpu_id=2
2022-01-11 16:18:51:INFO:	do_train=True
2022-01-11 16:18:51:INFO:	do_eval=False
2022-01-11 16:18:51:INFO:	train_data_fn='data/train_FD001.txt'
2022-01-11 16:18:51:INFO:	test_data_fn='data/test_FD001.txt'
2022-01-11 16:18:51:INFO:	target_ruls_fn='data/RUL_FD001.txt'
2022-01-11 16:18:51:INFO:	device=device(type='cuda'))
2022-01-11 16:18:51:INFO:Dump arguments to cnn2dmodels/data-1_n_epochs-5_aug-150_noise-0.01_supportSize-0_innerSteps-1_lrMeta-0.001_lrInner-0.0001_warmUp-0.0_seed-667...
2022-01-11 16:18:51:INFO:==> Read data from data/train_FD001.txt...
2022-01-11 16:18:51:INFO:	The selected feature idxs are: 0, 1, 4, 5, 6, 9, 10, 11, 13, 14, 15, 16, 17, 19, 22, 23
2022-01-11 16:18:51:INFO:==> Min_max normalization...
2022-01-11 16:18:51:INFO:	The min value is [-0.008700000122189522, -0.0006000000284984708, 641.2100219726562, 1571.0400390625, 1382.25, 549.8499755859375, 2387.89990234375, 9021.73046875, 46.849998474121094, 518.6900024414062, 2387.8798828125, 8099.93994140625, 8.324899673461914, 388.0, 38.13999938964844, 22.89419937133789]
2022-01-11 16:18:51:INFO:	The max value is [0.008700000122189522, 0.0006000000284984708, 644.530029296875, 1616.9100341796875, 1441.489990234375, 556.0599975585938, 2388.56005859375, 9244.58984375, 48.529998779296875, 523.3800048828125, 2388.56005859375, 8293.7197265625, 8.584799766540527, 400.0, 39.43000030517578, 23.61840057373047]
2022-01-11 16:18:51:INFO:==> Read data from data/test_FD001.txt...
2022-01-11 16:18:51:INFO:	The selected feature idxs are: 0, 1, 4, 5, 6, 9, 10, 11, 13, 14, 15, 16, 17, 19, 22, 23
2022-01-11 16:18:51:INFO:==> Read RULsfrom data/RUL_FD001.txt...
2022-01-11 16:18:51:INFO:	min_rul: 7, max_rul: 145
2022-01-11 16:18:51:INFO:==> Input length ratio of the [TEST] data:
2022-01-11 16:18:51:INFO:	min_ratio = 0.2067
2022-01-11 16:18:51:INFO:	max_ratio = 0.9667
2022-01-11 16:18:51:INFO:==> Min_max normalization...
2022-01-11 16:18:51:INFO:	With given min value [-0.008700000122189522, -0.0006000000284984708, 641.2100219726562, 1571.0400390625, 1382.25, 549.8499755859375, 2387.89990234375, 9021.73046875, 46.849998474121094, 518.6900024414062, 2387.8798828125, 8099.93994140625, 8.324899673461914, 388.0, 38.13999938964844, 22.89419937133789]
2022-01-11 16:18:51:INFO:	With given max value [0.008700000122189522, 0.0006000000284984708, 644.530029296875, 1616.9100341796875, 1441.489990234375, 556.0599975585938, 2388.56005859375, 9244.58984375, 48.529998779296875, 523.3800048828125, 2388.56005859375, 8293.7197265625, 8.584799766540527, 400.0, 39.43000030517578, 23.61840057373047]
2022-01-11 16:18:55:INFO:Note: NumExpr detected 40 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2022-01-11 16:18:55:INFO:NumExpr defaulting to 8 threads.
2022-01-11 16:18:55:INFO:=============== Scheme: Normal Learning ===============
2022-01-11 16:18:55:INFO:	Num examples = 15000
2022-01-11 16:18:55:INFO:	Num epochs = 5
2022-01-11 16:18:55:INFO:	Batch size = 20
2022-01-11 16:18:55:INFO:	Total optimization steps = 3750
2022-01-11 16:19:01:INFO:==> Group parameters for optimization...
2022-01-11 16:19:01:INFO:    Parameters to update are:
2022-01-11 16:19:01:INFO:	conv1.0.weight
2022-01-11 16:19:01:INFO:	conv2.0.weight
2022-01-11 16:19:01:INFO:	conv3.0.weight
2022-01-11 16:19:01:INFO:	conv4.0.weight
2022-01-11 16:19:01:INFO:	conv5.0.weight
2022-01-11 16:19:01:INFO:	fc_1.0.weight
2022-01-11 16:19:01:INFO:	fc_1.0.bias
2022-01-11 16:19:01:INFO:	fc_2.weight
2022-01-11 16:19:01:INFO:	fc_2.bias
/data/moy20/Meta-Learning/Meta-prognosis-main/optimizer.py:78: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448255797/work/torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
/data/moy20/miniconda3/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
2022-01-11 16:19:02:INFO:Epoch: 0	 global_step: 0/3750	 lr: 0.00100	 loss: 0.0012
2022-01-11 16:19:15:INFO:Epoch: 0	 global_step: 50/3750	 lr: 0.00099	 loss: 0.0228
2022-01-11 16:19:27:INFO:Epoch: 0	 global_step: 100/3750	 lr: 0.00097	 loss: 0.0095
2022-01-11 16:19:39:INFO:Epoch: 0	 global_step: 150/3750	 lr: 0.00096	 loss: 0.0072
2022-01-11 16:19:52:INFO:Epoch: 0	 global_step: 200/3750	 lr: 0.00095	 loss: 0.0051
2022-01-11 16:20:04:INFO:Epoch: 0	 global_step: 250/3750	 lr: 0.00093	 loss: 0.0047
2022-01-11 16:20:17:INFO:Epoch: 0	 global_step: 300/3750	 lr: 0.00092	 loss: 0.0037
2022-01-11 16:20:29:INFO:Epoch: 0	 global_step: 350/3750	 lr: 0.00091	 loss: 0.0037
2022-01-11 16:20:41:INFO:Epoch: 0	 global_step: 400/3750	 lr: 0.00089	 loss: 0.0031
2022-01-11 16:20:54:INFO:Epoch: 0	 global_step: 450/3750	 lr: 0.00088	 loss: 0.0028
2022-01-11 16:21:06:INFO:Epoch: 0	 global_step: 500/3750	 lr: 0.00087	 loss: 0.0023
2022-01-11 16:21:18:INFO:Epoch: 0	 global_step: 550/3750	 lr: 0.00085	 loss: 0.0020
2022-01-11 16:21:31:INFO:Epoch: 0	 global_step: 600/3750	 lr: 0.00084	 loss: 0.0018
2022-01-11 16:21:43:INFO:Epoch: 0	 global_step: 650/3750	 lr: 0.00083	 loss: 0.0020
2022-01-11 16:21:55:INFO:Epoch: 0	 global_step: 700/3750	 lr: 0.00081	 loss: 0.0018
2022-01-11 16:22:09:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-11 16:22:09:INFO:	Num examples = 100
2022-01-11 16:22:09:INFO:	RMSE = 15.3366
2022-01-11 16:22:10:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-11 16:22:10:INFO:	Num examples = 100
2022-01-11 16:22:10:INFO:	RMSE = 35.3999
2022-01-11 16:22:10:INFO:==> Minimal valid RMSE!
2022-01-11 16:22:10:INFO:Save model to cnn2dmodels/data-1_n_epochs-5_aug-150_noise-0.01_supportSize-0_innerSteps-1_lrMeta-0.001_lrInner-0.0001_warmUp-0.0_seed-667...
2022-01-11 16:22:10:INFO:Epoch: 1	 global_step: 750/3750	 lr: 0.00080	 loss: 0.0019
2022-01-11 16:22:22:INFO:Epoch: 1	 global_step: 800/3750	 lr: 0.00079	 loss: 0.0018
2022-01-11 16:22:35:INFO:Epoch: 1	 global_step: 850/3750	 lr: 0.00077	 loss: 0.0018
2022-01-11 16:22:47:INFO:Epoch: 1	 global_step: 900/3750	 lr: 0.00076	 loss: 0.0019
2022-01-11 16:22:59:INFO:Epoch: 1	 global_step: 950/3750	 lr: 0.00075	 loss: 0.0015
2022-01-11 16:23:12:INFO:Epoch: 1	 global_step: 1000/3750	 lr: 0.00073	 loss: 0.0016
2022-01-11 16:23:24:INFO:Epoch: 1	 global_step: 1050/3750	 lr: 0.00072	 loss: 0.0014
2022-01-11 16:23:36:INFO:Epoch: 1	 global_step: 1100/3750	 lr: 0.00071	 loss: 0.0013
2022-01-11 16:23:49:INFO:Epoch: 1	 global_step: 1150/3750	 lr: 0.00069	 loss: 0.0014
2022-01-11 16:24:01:INFO:Epoch: 1	 global_step: 1200/3750	 lr: 0.00068	 loss: 0.0012
2022-01-11 16:24:13:INFO:Epoch: 1	 global_step: 1250/3750	 lr: 0.00067	 loss: 0.0013
2022-01-11 16:24:26:INFO:Epoch: 1	 global_step: 1300/3750	 lr: 0.00065	 loss: 0.0011
2022-01-11 16:24:38:INFO:Epoch: 1	 global_step: 1350/3750	 lr: 0.00064	 loss: 0.0011
2022-01-11 16:24:50:INFO:Epoch: 1	 global_step: 1400/3750	 lr: 0.00063	 loss: 0.0011
2022-01-11 16:25:03:INFO:Epoch: 1	 global_step: 1450/3750	 lr: 0.00061	 loss: 0.0011
2022-01-11 16:25:16:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-11 16:25:16:INFO:	Num examples = 100
2022-01-11 16:25:16:INFO:	RMSE = 13.9426
2022-01-11 16:25:17:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-11 16:25:17:INFO:	Num examples = 100
2022-01-11 16:25:17:INFO:	RMSE = 30.7836
2022-01-11 16:25:17:INFO:==> Minimal valid RMSE!
2022-01-11 16:25:17:INFO:Save model to cnn2dmodels/data-1_n_epochs-5_aug-150_noise-0.01_supportSize-0_innerSteps-1_lrMeta-0.001_lrInner-0.0001_warmUp-0.0_seed-667...
2022-01-11 16:25:18:INFO:Epoch: 2	 global_step: 1500/3750	 lr: 0.00060	 loss: 0.0012
2022-01-11 16:25:30:INFO:Epoch: 2	 global_step: 1550/3750	 lr: 0.00059	 loss: 0.0012
2022-01-11 16:25:42:INFO:Epoch: 2	 global_step: 1600/3750	 lr: 0.00057	 loss: 0.0011
2022-01-11 16:25:55:INFO:Epoch: 2	 global_step: 1650/3750	 lr: 0.00056	 loss: 0.0011
2022-01-11 16:26:07:INFO:Epoch: 2	 global_step: 1700/3750	 lr: 0.00055	 loss: 0.0010
2022-01-11 16:26:19:INFO:Epoch: 2	 global_step: 1750/3750	 lr: 0.00053	 loss: 0.0009
2022-01-11 16:26:32:INFO:Epoch: 2	 global_step: 1800/3750	 lr: 0.00052	 loss: 0.0011
2022-01-11 16:26:44:INFO:Epoch: 2	 global_step: 1850/3750	 lr: 0.00051	 loss: 0.0010
2022-01-11 16:26:56:INFO:Epoch: 2	 global_step: 1900/3750	 lr: 0.00049	 loss: 0.0011
2022-01-11 16:27:09:INFO:Epoch: 2	 global_step: 1950/3750	 lr: 0.00048	 loss: 0.0008
2022-01-11 16:27:21:INFO:Epoch: 2	 global_step: 2000/3750	 lr: 0.00047	 loss: 0.0008
2022-01-11 16:27:33:INFO:Epoch: 2	 global_step: 2050/3750	 lr: 0.00045	 loss: 0.0009
2022-01-11 16:27:46:INFO:Epoch: 2	 global_step: 2100/3750	 lr: 0.00044	 loss: 0.0008
2022-01-11 16:27:58:INFO:Epoch: 2	 global_step: 2150/3750	 lr: 0.00043	 loss: 0.0009
2022-01-11 16:28:10:INFO:Epoch: 2	 global_step: 2200/3750	 lr: 0.00041	 loss: 0.0008
2022-01-11 16:28:24:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-11 16:28:24:INFO:	Num examples = 100
2022-01-11 16:28:24:INFO:	RMSE = 14.0739
2022-01-11 16:28:25:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-11 16:28:25:INFO:	Num examples = 100
2022-01-11 16:28:25:INFO:	RMSE = 29.2165
2022-01-11 16:28:25:INFO:==> Minimal valid RMSE!
2022-01-11 16:28:25:INFO:Save model to cnn2dmodels/data-1_n_epochs-5_aug-150_noise-0.01_supportSize-0_innerSteps-1_lrMeta-0.001_lrInner-0.0001_warmUp-0.0_seed-667...
2022-01-11 16:28:25:INFO:Epoch: 3	 global_step: 2250/3750	 lr: 0.00040	 loss: 0.0008
2022-01-11 16:28:38:INFO:Epoch: 3	 global_step: 2300/3750	 lr: 0.00039	 loss: 0.0009
2022-01-11 16:28:50:INFO:Epoch: 3	 global_step: 2350/3750	 lr: 0.00037	 loss: 0.0008
2022-01-11 16:29:02:INFO:Epoch: 3	 global_step: 2400/3750	 lr: 0.00036	 loss: 0.0007
2022-01-11 16:29:15:INFO:Epoch: 3	 global_step: 2450/3750	 lr: 0.00035	 loss: 0.0008
2022-01-11 16:29:27:INFO:Epoch: 3	 global_step: 2500/3750	 lr: 0.00033	 loss: 0.0008
2022-01-11 16:29:39:INFO:Epoch: 3	 global_step: 2550/3750	 lr: 0.00032	 loss: 0.0007
2022-01-11 16:29:52:INFO:Epoch: 3	 global_step: 2600/3750	 lr: 0.00031	 loss: 0.0008
2022-01-11 16:30:07:INFO:Epoch: 3	 global_step: 2650/3750	 lr: 0.00029	 loss: 0.0007
2022-01-11 16:30:26:INFO:Epoch: 3	 global_step: 2700/3750	 lr: 0.00028	 loss: 0.0007
2022-01-11 16:30:45:INFO:Epoch: 3	 global_step: 2750/3750	 lr: 0.00027	 loss: 0.0006
2022-01-11 16:31:05:INFO:Epoch: 3	 global_step: 2800/3750	 lr: 0.00025	 loss: 0.0006
2022-01-11 16:31:24:INFO:Epoch: 3	 global_step: 2850/3750	 lr: 0.00024	 loss: 0.0007
2022-01-11 16:31:43:INFO:Epoch: 3	 global_step: 2900/3750	 lr: 0.00023	 loss: 0.0006
2022-01-11 16:32:03:INFO:Epoch: 3	 global_step: 2950/3750	 lr: 0.00021	 loss: 0.0007
2022-01-11 16:32:23:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-11 16:32:23:INFO:	Num examples = 100
2022-01-11 16:32:23:INFO:	RMSE = 14.2210
2022-01-11 16:32:25:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-11 16:32:25:INFO:	Num examples = 100
2022-01-11 16:32:25:INFO:	RMSE = 32.3771
2022-01-11 16:32:26:INFO:Epoch: 4	 global_step: 3000/3750	 lr: 0.00020	 loss: 0.0007
2022-01-11 16:32:45:INFO:Epoch: 4	 global_step: 3050/3750	 lr: 0.00019	 loss: 0.0006
2022-01-11 16:33:04:INFO:Epoch: 4	 global_step: 3100/3750	 lr: 0.00017	 loss: 0.0006
2022-01-11 16:33:24:INFO:Epoch: 4	 global_step: 3150/3750	 lr: 0.00016	 loss: 0.0006
2022-01-11 16:33:43:INFO:Epoch: 4	 global_step: 3200/3750	 lr: 0.00015	 loss: 0.0006
2022-01-11 16:34:02:INFO:Epoch: 4	 global_step: 3250/3750	 lr: 0.00013	 loss: 0.0005
2022-01-11 16:34:21:INFO:Epoch: 4	 global_step: 3300/3750	 lr: 0.00012	 loss: 0.0006
2022-01-11 16:34:41:INFO:Epoch: 4	 global_step: 3350/3750	 lr: 0.00011	 loss: 0.0006
2022-01-11 16:35:00:INFO:Epoch: 4	 global_step: 3400/3750	 lr: 0.00009	 loss: 0.0006
2022-01-11 16:35:19:INFO:Epoch: 4	 global_step: 3450/3750	 lr: 0.00008	 loss: 0.0006
2022-01-11 16:35:39:INFO:Epoch: 4	 global_step: 3500/3750	 lr: 0.00007	 loss: 0.0006
2022-01-11 16:35:58:INFO:Epoch: 4	 global_step: 3550/3750	 lr: 0.00005	 loss: 0.0005
2022-01-11 16:36:18:INFO:Epoch: 4	 global_step: 3600/3750	 lr: 0.00004	 loss: 0.0006
2022-01-11 16:36:37:INFO:Epoch: 4	 global_step: 3650/3750	 lr: 0.00003	 loss: 0.0005
2022-01-11 16:36:56:INFO:Epoch: 4	 global_step: 3700/3750	 lr: 0.00001	 loss: 0.0005
2022-01-11 16:37:17:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-11 16:37:17:INFO:	Num examples = 100
2022-01-11 16:37:17:INFO:	RMSE = 13.7765
2022-01-11 16:37:19:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-11 16:37:19:INFO:	Num examples = 100
2022-01-11 16:37:19:INFO:	RMSE = 28.3021
2022-01-11 16:37:19:INFO:==> Minimal valid RMSE!
2022-01-11 16:37:19:INFO:Save model to cnn2dmodels/data-1_n_epochs-5_aug-150_noise-0.01_supportSize-0_innerSteps-1_lrMeta-0.001_lrInner-0.0001_warmUp-0.0_seed-667...
2022-01-11 16:37:19:INFO:	Output TEST RMSE:	13.7765
2022-01-11 16:37:19:INFO:	VALID RMSEs:	35.3999	30.7836	29.2165	32.3771	28.3021
2022-01-11 16:37:19:INFO:	TEST RMSEs:	15.3366	13.9426	14.0739	14.2210	13.7765
!!! Reset batch info !!! mode: [TRAIN]
!!! Reset batch info !!! mode: [TEST]
!!! Reset batch info !!! mode: [VALID]
!!! Reset batch info !!! mode: [TRAIN]
!!! Reset batch info !!! mode: [TEST]
!!! Reset batch info !!! mode: [VALID]
!!! Reset batch info !!! mode: [TRAIN]
!!! Reset batch info !!! mode: [TEST]
!!! Reset batch info !!! mode: [VALID]
!!! Reset batch info !!! mode: [TRAIN]
!!! Reset batch info !!! mode: [TEST]
!!! Reset batch info !!! mode: [VALID]
2022-01-11 16:37:22:INFO:Finish setting logger...
2022-01-11 16:37:22:INFO:==> Training/Evaluation parameters are:
2022-01-11 16:37:22:INFO:	Namespace(model_dir='cnn2dmodels/data-1_n_epochs-5_aug-150_noise-0.01_supportSize-0_innerSteps-1_lrMeta-0.001_lrInner-0.0001_warmUp-0.0_seed-128'
2022-01-11 16:37:22:INFO:	data_fn=1
2022-01-11 16:37:22:INFO:	datatest_fn=1
2022-01-11 16:37:22:INFO:	filter_kernel_size=1
2022-01-11 16:37:22:INFO:	override_data_cache=False
2022-01-11 16:37:22:INFO:	maxRUL=125
2022-01-11 16:37:22:INFO:	low_ratio=0.1
2022-01-11 16:37:22:INFO:	high_ratio=0.99
2022-01-11 16:37:22:INFO:	aug_ratio=150
2022-01-11 16:37:22:INFO:	noise_amplitude=0.01
2022-01-11 16:37:22:INFO:	modeltype='cnn2d'
2022-01-11 16:37:22:INFO:	max_seq_len=550
2022-01-11 16:37:22:INFO:	d_model=128
2022-01-11 16:37:22:INFO:	p_dropout=0.1
2022-01-11 16:37:22:INFO:	n_head=4
2022-01-11 16:37:22:INFO:	n_layer=2
2022-01-11 16:37:22:INFO:	dim_feedforward=512
2022-01-11 16:37:22:INFO:	e_dropout=0.1
2022-01-11 16:37:22:INFO:	activation='relu'
2022-01-11 16:37:22:INFO:	layer_norm=False
2022-01-11 16:37:22:INFO:	support_size=0
2022-01-11 16:37:22:INFO:	inner_steps=1
2022-01-11 16:37:22:INFO:	lr_inner=0.0001
2022-01-11 16:37:22:INFO:	lr_meta=0.001
2022-01-11 16:37:22:INFO:	n_epochs=5
2022-01-11 16:37:22:INFO:	train_batch_size=20
2022-01-11 16:37:22:INFO:	eval_batch_size=1
2022-01-11 16:37:22:INFO:	lr=0.001
2022-01-11 16:37:22:INFO:	weight_decay=0.01
2022-01-11 16:37:22:INFO:	warmup_ratio=0.0
2022-01-11 16:37:22:INFO:	max_grad_norm=5.0
2022-01-11 16:37:22:INFO:	logging_steps=50
2022-01-11 16:37:22:INFO:	seed=128
2022-01-11 16:37:22:INFO:	gpu_id=2
2022-01-11 16:37:22:INFO:	do_train=True
2022-01-11 16:37:22:INFO:	do_eval=False
2022-01-11 16:37:22:INFO:	train_data_fn='data/train_FD001.txt'
2022-01-11 16:37:22:INFO:	test_data_fn='data/test_FD001.txt'
2022-01-11 16:37:22:INFO:	target_ruls_fn='data/RUL_FD001.txt'
2022-01-11 16:37:22:INFO:	device=device(type='cuda'))
2022-01-11 16:37:22:INFO:Dump arguments to cnn2dmodels/data-1_n_epochs-5_aug-150_noise-0.01_supportSize-0_innerSteps-1_lrMeta-0.001_lrInner-0.0001_warmUp-0.0_seed-128...
2022-01-11 16:37:22:INFO:==> Read data from data/train_FD001.txt...
2022-01-11 16:37:22:INFO:	The selected feature idxs are: 0, 1, 4, 5, 6, 9, 10, 11, 13, 14, 15, 16, 17, 19, 22, 23
2022-01-11 16:37:22:INFO:==> Min_max normalization...
2022-01-11 16:37:22:INFO:	The min value is [-0.008700000122189522, -0.0006000000284984708, 641.2100219726562, 1571.0400390625, 1382.25, 549.8499755859375, 2387.89990234375, 9021.73046875, 46.849998474121094, 518.6900024414062, 2387.8798828125, 8099.93994140625, 8.324899673461914, 388.0, 38.13999938964844, 22.89419937133789]
2022-01-11 16:37:22:INFO:	The max value is [0.008700000122189522, 0.0006000000284984708, 644.530029296875, 1616.9100341796875, 1441.489990234375, 556.0599975585938, 2388.56005859375, 9244.58984375, 48.529998779296875, 523.3800048828125, 2388.56005859375, 8293.7197265625, 8.584799766540527, 400.0, 39.43000030517578, 23.61840057373047]
2022-01-11 16:37:22:INFO:==> Read data from data/test_FD001.txt...
2022-01-11 16:37:22:INFO:	The selected feature idxs are: 0, 1, 4, 5, 6, 9, 10, 11, 13, 14, 15, 16, 17, 19, 22, 23
2022-01-11 16:37:22:INFO:==> Read RULsfrom data/RUL_FD001.txt...
2022-01-11 16:37:22:INFO:	min_rul: 7, max_rul: 145
2022-01-11 16:37:22:INFO:==> Input length ratio of the [TEST] data:
2022-01-11 16:37:22:INFO:	min_ratio = 0.2067
2022-01-11 16:37:22:INFO:	max_ratio = 0.9667
2022-01-11 16:37:22:INFO:==> Min_max normalization...
2022-01-11 16:37:22:INFO:	With given min value [-0.008700000122189522, -0.0006000000284984708, 641.2100219726562, 1571.0400390625, 1382.25, 549.8499755859375, 2387.89990234375, 9021.73046875, 46.849998474121094, 518.6900024414062, 2387.8798828125, 8099.93994140625, 8.324899673461914, 388.0, 38.13999938964844, 22.89419937133789]
2022-01-11 16:37:22:INFO:	With given max value [0.008700000122189522, 0.0006000000284984708, 644.530029296875, 1616.9100341796875, 1441.489990234375, 556.0599975585938, 2388.56005859375, 9244.58984375, 48.529998779296875, 523.3800048828125, 2388.56005859375, 8293.7197265625, 8.584799766540527, 400.0, 39.43000030517578, 23.61840057373047]
2022-01-11 16:37:26:INFO:Note: NumExpr detected 40 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2022-01-11 16:37:26:INFO:NumExpr defaulting to 8 threads.
2022-01-11 16:37:26:INFO:=============== Scheme: Normal Learning ===============
2022-01-11 16:37:26:INFO:	Num examples = 15000
2022-01-11 16:37:26:INFO:	Num epochs = 5
2022-01-11 16:37:26:INFO:	Batch size = 20
2022-01-11 16:37:26:INFO:	Total optimization steps = 3750
2022-01-11 16:37:34:INFO:==> Group parameters for optimization...
2022-01-11 16:37:34:INFO:    Parameters to update are:
2022-01-11 16:37:34:INFO:	conv1.0.weight
2022-01-11 16:37:34:INFO:	conv2.0.weight
2022-01-11 16:37:34:INFO:	conv3.0.weight
2022-01-11 16:37:34:INFO:	conv4.0.weight
2022-01-11 16:37:34:INFO:	conv5.0.weight
2022-01-11 16:37:34:INFO:	fc_1.0.weight
2022-01-11 16:37:34:INFO:	fc_1.0.bias
2022-01-11 16:37:34:INFO:	fc_2.weight
2022-01-11 16:37:34:INFO:	fc_2.bias
/data/moy20/Meta-Learning/Meta-prognosis-main/optimizer.py:78: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448255797/work/torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
/data/moy20/miniconda3/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
2022-01-11 16:37:36:INFO:Epoch: 0	 global_step: 0/3750	 lr: 0.00100	 loss: 0.0012
2022-01-11 16:37:55:INFO:Epoch: 0	 global_step: 50/3750	 lr: 0.00099	 loss: 0.0152
2022-01-11 16:38:14:INFO:Epoch: 0	 global_step: 100/3750	 lr: 0.00097	 loss: 0.0093
2022-01-11 16:38:34:INFO:Epoch: 0	 global_step: 150/3750	 lr: 0.00096	 loss: 0.0067
2022-01-11 16:38:53:INFO:Epoch: 0	 global_step: 200/3750	 lr: 0.00095	 loss: 0.0049
2022-01-11 16:39:12:INFO:Epoch: 0	 global_step: 250/3750	 lr: 0.00093	 loss: 0.0046
2022-01-11 16:39:31:INFO:Epoch: 0	 global_step: 300/3750	 lr: 0.00092	 loss: 0.0036
2022-01-11 16:39:51:INFO:Epoch: 0	 global_step: 350/3750	 lr: 0.00091	 loss: 0.0035
2022-01-11 16:40:10:INFO:Epoch: 0	 global_step: 400/3750	 lr: 0.00089	 loss: 0.0023
2022-01-11 16:40:29:INFO:Epoch: 0	 global_step: 450/3750	 lr: 0.00088	 loss: 0.0019
2022-01-11 16:40:49:INFO:Epoch: 0	 global_step: 500/3750	 lr: 0.00087	 loss: 0.0018
2022-01-11 16:41:08:INFO:Epoch: 0	 global_step: 550/3750	 lr: 0.00085	 loss: 0.0018
2022-01-11 16:41:27:INFO:Epoch: 0	 global_step: 600/3750	 lr: 0.00084	 loss: 0.0016
2022-01-11 16:41:47:INFO:Epoch: 0	 global_step: 650/3750	 lr: 0.00083	 loss: 0.0015
2022-01-11 16:42:06:INFO:Epoch: 0	 global_step: 700/3750	 lr: 0.00081	 loss: 0.0015
2022-01-11 16:42:27:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-11 16:42:27:INFO:	Num examples = 100
2022-01-11 16:42:27:INFO:	RMSE = 17.2464
2022-01-11 16:42:29:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-11 16:42:29:INFO:	Num examples = 100
2022-01-11 16:42:29:INFO:	RMSE = 30.9978
2022-01-11 16:42:29:INFO:==> Minimal valid RMSE!
2022-01-11 16:42:29:INFO:Save model to cnn2dmodels/data-1_n_epochs-5_aug-150_noise-0.01_supportSize-0_innerSteps-1_lrMeta-0.001_lrInner-0.0001_warmUp-0.0_seed-128...
2022-01-11 16:42:29:INFO:Epoch: 1	 global_step: 750/3750	 lr: 0.00080	 loss: 0.0019
2022-01-11 16:42:49:INFO:Epoch: 1	 global_step: 800/3750	 lr: 0.00079	 loss: 0.0014
2022-01-11 16:43:08:INFO:Epoch: 1	 global_step: 850/3750	 lr: 0.00077	 loss: 0.0012
2022-01-11 16:43:27:INFO:Epoch: 1	 global_step: 900/3750	 lr: 0.00076	 loss: 0.0013
2022-01-11 16:43:46:INFO:Epoch: 1	 global_step: 950/3750	 lr: 0.00075	 loss: 0.0013
2022-01-11 16:44:06:INFO:Epoch: 1	 global_step: 1000/3750	 lr: 0.00073	 loss: 0.0012
2022-01-11 16:44:25:INFO:Epoch: 1	 global_step: 1050/3750	 lr: 0.00072	 loss: 0.0011
2022-01-11 16:44:44:INFO:Epoch: 1	 global_step: 1100/3750	 lr: 0.00071	 loss: 0.0011
2022-01-11 16:45:03:INFO:Epoch: 1	 global_step: 1150/3750	 lr: 0.00069	 loss: 0.0012
2022-01-11 16:45:22:INFO:Epoch: 1	 global_step: 1200/3750	 lr: 0.00068	 loss: 0.0009
2022-01-11 16:45:42:INFO:Epoch: 1	 global_step: 1250/3750	 lr: 0.00067	 loss: 0.0010
2022-01-11 16:46:01:INFO:Epoch: 1	 global_step: 1300/3750	 lr: 0.00065	 loss: 0.0011
2022-01-11 16:46:20:INFO:Epoch: 1	 global_step: 1350/3750	 lr: 0.00064	 loss: 0.0010
2022-01-11 16:46:39:INFO:Epoch: 1	 global_step: 1400/3750	 lr: 0.00063	 loss: 0.0009
2022-01-11 16:46:59:INFO:Epoch: 1	 global_step: 1450/3750	 lr: 0.00061	 loss: 0.0010
2022-01-11 16:47:20:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-11 16:47:20:INFO:	Num examples = 100
2022-01-11 16:47:20:INFO:	RMSE = 15.6644
2022-01-11 16:47:22:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-11 16:47:22:INFO:	Num examples = 100
2022-01-11 16:47:22:INFO:	RMSE = 32.0355
2022-01-11 16:47:22:INFO:Epoch: 2	 global_step: 1500/3750	 lr: 0.00060	 loss: 0.0010
2022-01-11 16:47:41:INFO:Epoch: 2	 global_step: 1550/3750	 lr: 0.00059	 loss: 0.0009
2022-01-11 16:48:01:INFO:Epoch: 2	 global_step: 1600/3750	 lr: 0.00057	 loss: 0.0009
2022-01-11 16:48:20:INFO:Epoch: 2	 global_step: 1650/3750	 lr: 0.00056	 loss: 0.0008
2022-01-11 16:48:39:INFO:Epoch: 2	 global_step: 1700/3750	 lr: 0.00055	 loss: 0.0008
2022-01-11 16:48:58:INFO:Epoch: 2	 global_step: 1750/3750	 lr: 0.00053	 loss: 0.0008
2022-01-11 16:49:17:INFO:Epoch: 2	 global_step: 1800/3750	 lr: 0.00052	 loss: 0.0009
2022-01-11 16:49:36:INFO:Epoch: 2	 global_step: 1850/3750	 lr: 0.00051	 loss: 0.0008
2022-01-11 16:49:55:INFO:Epoch: 2	 global_step: 1900/3750	 lr: 0.00049	 loss: 0.0008
2022-01-11 16:50:14:INFO:Epoch: 2	 global_step: 1950/3750	 lr: 0.00048	 loss: 0.0008
2022-01-11 16:50:33:INFO:Epoch: 2	 global_step: 2000/3750	 lr: 0.00047	 loss: 0.0007
2022-01-11 16:50:52:INFO:Epoch: 2	 global_step: 2050/3750	 lr: 0.00045	 loss: 0.0007
2022-01-11 16:51:12:INFO:Epoch: 2	 global_step: 2100/3750	 lr: 0.00044	 loss: 0.0007
2022-01-11 16:51:31:INFO:Epoch: 2	 global_step: 2150/3750	 lr: 0.00043	 loss: 0.0006
2022-01-11 16:51:50:INFO:Epoch: 2	 global_step: 2200/3750	 lr: 0.00041	 loss: 0.0007
2022-01-11 16:52:11:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-11 16:52:11:INFO:	Num examples = 100
2022-01-11 16:52:11:INFO:	RMSE = 13.5406
2022-01-11 16:52:13:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-11 16:52:13:INFO:	Num examples = 100
2022-01-11 16:52:13:INFO:	RMSE = 35.1876
2022-01-11 16:52:14:INFO:Epoch: 3	 global_step: 2250/3750	 lr: 0.00040	 loss: 0.0006
2022-01-11 16:52:33:INFO:Epoch: 3	 global_step: 2300/3750	 lr: 0.00039	 loss: 0.0007
2022-01-11 16:52:52:INFO:Epoch: 3	 global_step: 2350/3750	 lr: 0.00037	 loss: 0.0007
2022-01-11 16:53:12:INFO:Epoch: 3	 global_step: 2400/3750	 lr: 0.00036	 loss: 0.0006
2022-01-11 16:53:31:INFO:Epoch: 3	 global_step: 2450/3750	 lr: 0.00035	 loss: 0.0006
2022-01-11 16:53:50:INFO:Epoch: 3	 global_step: 2500/3750	 lr: 0.00033	 loss: 0.0006
2022-01-11 16:54:10:INFO:Epoch: 3	 global_step: 2550/3750	 lr: 0.00032	 loss: 0.0006
2022-01-11 16:54:29:INFO:Epoch: 3	 global_step: 2600/3750	 lr: 0.00031	 loss: 0.0006
2022-01-11 16:54:49:INFO:Epoch: 3	 global_step: 2650/3750	 lr: 0.00029	 loss: 0.0005
2022-01-11 16:55:08:INFO:Epoch: 3	 global_step: 2700/3750	 lr: 0.00028	 loss: 0.0006
2022-01-11 16:55:27:INFO:Epoch: 3	 global_step: 2750/3750	 lr: 0.00027	 loss: 0.0005
2022-01-11 16:55:47:INFO:Epoch: 3	 global_step: 2800/3750	 lr: 0.00025	 loss: 0.0005
2022-01-11 16:56:06:INFO:Epoch: 3	 global_step: 2850/3750	 lr: 0.00024	 loss: 0.0006
2022-01-11 16:56:25:INFO:Epoch: 3	 global_step: 2900/3750	 lr: 0.00023	 loss: 0.0005
2022-01-11 16:56:45:INFO:Epoch: 3	 global_step: 2950/3750	 lr: 0.00021	 loss: 0.0005
2022-01-11 16:57:06:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-11 16:57:06:INFO:	Num examples = 100
2022-01-11 16:57:06:INFO:	RMSE = 13.2034
2022-01-11 16:57:08:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-11 16:57:08:INFO:	Num examples = 100
2022-01-11 16:57:08:INFO:	RMSE = 33.0059
2022-01-11 16:57:08:INFO:Epoch: 4	 global_step: 3000/3750	 lr: 0.00020	 loss: 0.0005
2022-01-11 16:57:27:INFO:Epoch: 4	 global_step: 3050/3750	 lr: 0.00019	 loss: 0.0005
2022-01-11 16:57:47:INFO:Epoch: 4	 global_step: 3100/3750	 lr: 0.00017	 loss: 0.0005
2022-01-11 16:58:06:INFO:Epoch: 4	 global_step: 3150/3750	 lr: 0.00016	 loss: 0.0005
2022-01-11 16:58:26:INFO:Epoch: 4	 global_step: 3200/3750	 lr: 0.00015	 loss: 0.0005
2022-01-11 16:58:45:INFO:Epoch: 4	 global_step: 3250/3750	 lr: 0.00013	 loss: 0.0004
2022-01-11 16:59:05:INFO:Epoch: 4	 global_step: 3300/3750	 lr: 0.00012	 loss: 0.0005
2022-01-11 16:59:24:INFO:Epoch: 4	 global_step: 3350/3750	 lr: 0.00011	 loss: 0.0005
2022-01-11 16:59:43:INFO:Epoch: 4	 global_step: 3400/3750	 lr: 0.00009	 loss: 0.0004
2022-01-11 17:00:03:INFO:Epoch: 4	 global_step: 3450/3750	 lr: 0.00008	 loss: 0.0005
2022-01-11 17:00:22:INFO:Epoch: 4	 global_step: 3500/3750	 lr: 0.00007	 loss: 0.0004
2022-01-11 17:00:41:INFO:Epoch: 4	 global_step: 3550/3750	 lr: 0.00005	 loss: 0.0005
2022-01-11 17:01:01:INFO:Epoch: 4	 global_step: 3600/3750	 lr: 0.00004	 loss: 0.0004
2022-01-11 17:01:20:INFO:Epoch: 4	 global_step: 3650/3750	 lr: 0.00003	 loss: 0.0005
2022-01-11 17:01:39:INFO:Epoch: 4	 global_step: 3700/3750	 lr: 0.00001	 loss: 0.0004
2022-01-11 17:02:00:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-11 17:02:00:INFO:	Num examples = 100
2022-01-11 17:02:00:INFO:	RMSE = 13.1790
2022-01-11 17:02:02:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-11 17:02:02:INFO:	Num examples = 100
2022-01-11 17:02:02:INFO:	RMSE = 32.0726
2022-01-11 17:02:02:INFO:	Output TEST RMSE:	17.2464
2022-01-11 17:02:02:INFO:	VALID RMSEs:	30.9978	32.0355	35.1876	33.0059	32.0726
2022-01-11 17:02:02:INFO:	TEST RMSEs:	17.2464	15.6644	13.5406	13.2034	13.1790
!!! Reset batch info !!! mode: [TRAIN]
!!! Reset batch info !!! mode: [TEST]
!!! Reset batch info !!! mode: [VALID]
!!! Reset batch info !!! mode: [TRAIN]
!!! Reset batch info !!! mode: [TEST]
!!! Reset batch info !!! mode: [VALID]
!!! Reset batch info !!! mode: [TRAIN]
!!! Reset batch info !!! mode: [TEST]
!!! Reset batch info !!! mode: [VALID]
!!! Reset batch info !!! mode: [TRAIN]
!!! Reset batch info !!! mode: [TEST]
!!! Reset batch info !!! mode: [VALID]
2022-01-11 17:02:05:INFO:Finish setting logger...
2022-01-11 17:02:05:INFO:==> Training/Evaluation parameters are:
2022-01-11 17:02:05:INFO:	Namespace(model_dir='cnn2dmodels/data-1_n_epochs-5_aug-150_noise-0.01_supportSize-2_innerSteps-2_lrMeta-0.001_lrInner-0.0001_warmUp-0.0_seed-42'
2022-01-11 17:02:05:INFO:	data_fn=1
2022-01-11 17:02:05:INFO:	datatest_fn=1
2022-01-11 17:02:05:INFO:	filter_kernel_size=1
2022-01-11 17:02:05:INFO:	override_data_cache=False
2022-01-11 17:02:05:INFO:	maxRUL=125
2022-01-11 17:02:05:INFO:	low_ratio=0.1
2022-01-11 17:02:05:INFO:	high_ratio=0.99
2022-01-11 17:02:05:INFO:	aug_ratio=150
2022-01-11 17:02:05:INFO:	noise_amplitude=0.01
2022-01-11 17:02:05:INFO:	modeltype='cnn2d'
2022-01-11 17:02:05:INFO:	max_seq_len=550
2022-01-11 17:02:05:INFO:	d_model=128
2022-01-11 17:02:05:INFO:	p_dropout=0.1
2022-01-11 17:02:05:INFO:	n_head=4
2022-01-11 17:02:05:INFO:	n_layer=2
2022-01-11 17:02:05:INFO:	dim_feedforward=512
2022-01-11 17:02:05:INFO:	e_dropout=0.1
2022-01-11 17:02:05:INFO:	activation='relu'
2022-01-11 17:02:05:INFO:	layer_norm=False
2022-01-11 17:02:05:INFO:	support_size=2
2022-01-11 17:02:05:INFO:	inner_steps=2
2022-01-11 17:02:05:INFO:	lr_inner=0.0001
2022-01-11 17:02:05:INFO:	lr_meta=0.001
2022-01-11 17:02:05:INFO:	n_epochs=5
2022-01-11 17:02:05:INFO:	train_batch_size=20
2022-01-11 17:02:05:INFO:	eval_batch_size=1
2022-01-11 17:02:05:INFO:	lr=0.001
2022-01-11 17:02:05:INFO:	weight_decay=0.01
2022-01-11 17:02:05:INFO:	warmup_ratio=0.0
2022-01-11 17:02:05:INFO:	max_grad_norm=5.0
2022-01-11 17:02:05:INFO:	logging_steps=50
2022-01-11 17:02:05:INFO:	seed=42
2022-01-11 17:02:05:INFO:	gpu_id=2
2022-01-11 17:02:05:INFO:	do_train=True
2022-01-11 17:02:05:INFO:	do_eval=False
2022-01-11 17:02:05:INFO:	train_data_fn='data/train_FD001.txt'
2022-01-11 17:02:05:INFO:	test_data_fn='data/test_FD001.txt'
2022-01-11 17:02:05:INFO:	target_ruls_fn='data/RUL_FD001.txt'
2022-01-11 17:02:05:INFO:	device=device(type='cuda'))
2022-01-11 17:02:05:INFO:Dump arguments to cnn2dmodels/data-1_n_epochs-5_aug-150_noise-0.01_supportSize-2_innerSteps-2_lrMeta-0.001_lrInner-0.0001_warmUp-0.0_seed-42...
2022-01-11 17:02:05:INFO:==> Read data from data/train_FD001.txt...
2022-01-11 17:02:05:INFO:	The selected feature idxs are: 0, 1, 4, 5, 6, 9, 10, 11, 13, 14, 15, 16, 17, 19, 22, 23
2022-01-11 17:02:06:INFO:==> Min_max normalization...
2022-01-11 17:02:06:INFO:	The min value is [-0.008700000122189522, -0.0006000000284984708, 641.2100219726562, 1571.0400390625, 1382.25, 549.8499755859375, 2387.89990234375, 9021.73046875, 46.849998474121094, 518.6900024414062, 2387.8798828125, 8099.93994140625, 8.324899673461914, 388.0, 38.13999938964844, 22.89419937133789]
2022-01-11 17:02:06:INFO:	The max value is [0.008700000122189522, 0.0006000000284984708, 644.530029296875, 1616.9100341796875, 1441.489990234375, 556.0599975585938, 2388.56005859375, 9244.58984375, 48.529998779296875, 523.3800048828125, 2388.56005859375, 8293.7197265625, 8.584799766540527, 400.0, 39.43000030517578, 23.61840057373047]
2022-01-11 17:02:06:INFO:==> Read data from data/test_FD001.txt...
2022-01-11 17:02:06:INFO:	The selected feature idxs are: 0, 1, 4, 5, 6, 9, 10, 11, 13, 14, 15, 16, 17, 19, 22, 23
2022-01-11 17:02:06:INFO:==> Read RULsfrom data/RUL_FD001.txt...
2022-01-11 17:02:06:INFO:	min_rul: 7, max_rul: 145
2022-01-11 17:02:06:INFO:==> Input length ratio of the [TEST] data:
2022-01-11 17:02:06:INFO:	min_ratio = 0.2067
2022-01-11 17:02:06:INFO:	max_ratio = 0.9667
2022-01-11 17:02:06:INFO:==> Min_max normalization...
2022-01-11 17:02:06:INFO:	With given min value [-0.008700000122189522, -0.0006000000284984708, 641.2100219726562, 1571.0400390625, 1382.25, 549.8499755859375, 2387.89990234375, 9021.73046875, 46.849998474121094, 518.6900024414062, 2387.8798828125, 8099.93994140625, 8.324899673461914, 388.0, 38.13999938964844, 22.89419937133789]
2022-01-11 17:02:06:INFO:	With given max value [0.008700000122189522, 0.0006000000284984708, 644.530029296875, 1616.9100341796875, 1441.489990234375, 556.0599975585938, 2388.56005859375, 9244.58984375, 48.529998779296875, 523.3800048828125, 2388.56005859375, 8293.7197265625, 8.584799766540527, 400.0, 39.43000030517578, 23.61840057373047]
2022-01-11 17:02:06:INFO:==> Computing Criterion...
2022-01-11 17:02:06:INFO:	The weights are: 0.007887763902544975, 0.008001004345715046, 0.06667434424161911, 0.0634712353348732, 0.07656104862689972, 0.0755249634385109, 0.06726357340812683, 0.0644979178905487, 0.0795108750462532, 0.07743842899799347, 0.0671684592962265, 0.06869389116764069, 0.07147877663373947, 0.06516212970018387, 0.07012488692998886, 0.07054071873426437
2022-01-11 17:02:13:INFO:Note: NumExpr detected 40 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2022-01-11 17:02:13:INFO:NumExpr defaulting to 8 threads.
2022-01-11 17:02:13:INFO:=============== Scheme: Meta Learning ===============
2022-01-11 17:02:13:INFO:	Num examples = 15000
2022-01-11 17:02:13:INFO:	Num epochs = 5
2022-01-11 17:02:13:INFO:	Batch size = 20
2022-01-11 17:02:13:INFO:	Total meta optimization steps = 3750
2022-01-11 17:02:13:INFO:	Total inner optimization steps = 7500
2022-01-11 17:02:21:INFO:==> Group parameters for optimization...
2022-01-11 17:02:21:INFO:    Parameters to update are:
2022-01-11 17:02:21:INFO:	conv1.0.weight
2022-01-11 17:02:21:INFO:	conv2.0.weight
2022-01-11 17:02:21:INFO:	conv3.0.weight
2022-01-11 17:02:21:INFO:	conv4.0.weight
2022-01-11 17:02:21:INFO:	conv5.0.weight
2022-01-11 17:02:21:INFO:	fc_1.0.weight
2022-01-11 17:02:21:INFO:	fc_1.0.bias
2022-01-11 17:02:21:INFO:	fc_2.weight
2022-01-11 17:02:21:INFO:	fc_2.bias
/data/moy20/Meta-Learning/Meta-prognosis-main/optimizer.py:78: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448255797/work/torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
/data/moy20/miniconda3/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
2022-01-11 17:02:24:INFO:Epoch: 0	 global_step: 0/3750	 lr: 0.00100	 loss: 0.0017
2022-01-11 17:03:40:INFO:Epoch: 0	 global_step: 50/3750	 lr: 0.00099	 loss: 0.0195
2022-01-11 17:04:55:INFO:Epoch: 0	 global_step: 100/3750	 lr: 0.00097	 loss: 0.0067
2022-01-11 17:06:10:INFO:Epoch: 0	 global_step: 150/3750	 lr: 0.00096	 loss: 0.0061
2022-01-11 17:07:25:INFO:Epoch: 0	 global_step: 200/3750	 lr: 0.00095	 loss: 0.0039
2022-01-11 17:08:41:INFO:Epoch: 0	 global_step: 250/3750	 lr: 0.00093	 loss: 0.0038
2022-01-11 17:09:56:INFO:Epoch: 0	 global_step: 300/3750	 lr: 0.00092	 loss: 0.0032
2022-01-11 17:11:12:INFO:Epoch: 0	 global_step: 350/3750	 lr: 0.00091	 loss: 0.0027
2022-01-11 17:12:27:INFO:Epoch: 0	 global_step: 400/3750	 lr: 0.00089	 loss: 0.0035
2022-01-11 17:13:43:INFO:Epoch: 0	 global_step: 450/3750	 lr: 0.00088	 loss: 0.0022
2022-01-11 17:14:58:INFO:Epoch: 0	 global_step: 500/3750	 lr: 0.00087	 loss: 0.0023
2022-01-11 17:16:14:INFO:Epoch: 0	 global_step: 550/3750	 lr: 0.00085	 loss: 0.0018
2022-01-11 17:17:29:INFO:Epoch: 0	 global_step: 600/3750	 lr: 0.00084	 loss: 0.0018
2022-01-11 17:18:45:INFO:Epoch: 0	 global_step: 650/3750	 lr: 0.00083	 loss: 0.0019
2022-01-11 17:19:59:INFO:Epoch: 0	 global_step: 700/3750	 lr: 0.00081	 loss: 0.0015
2022-01-11 17:21:20:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-11 17:21:20:INFO:	Num examples = 100
2022-01-11 17:21:20:INFO:	RMSE = 23.4757
2022-01-11 17:21:28:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-11 17:21:28:INFO:	Num examples = 100
2022-01-11 17:21:28:INFO:	RMSE = 27.5359
2022-01-11 17:21:28:INFO:==> Minimal valid RMSE!
2022-01-11 17:21:28:INFO:Save model to cnn2dmodels/data-1_n_epochs-5_aug-150_noise-0.01_supportSize-2_innerSteps-2_lrMeta-0.001_lrInner-0.0001_warmUp-0.0_seed-42...
2022-01-11 17:21:29:INFO:Epoch: 1	 global_step: 750/3750	 lr: 0.00080	 loss: 0.0015
2022-01-11 17:22:44:INFO:Epoch: 1	 global_step: 800/3750	 lr: 0.00079	 loss: 0.0023
2022-01-11 17:24:00:INFO:Epoch: 1	 global_step: 850/3750	 lr: 0.00077	 loss: 0.0016
2022-01-11 17:25:14:INFO:Epoch: 1	 global_step: 900/3750	 lr: 0.00076	 loss: 0.0011
2022-01-11 17:26:29:INFO:Epoch: 1	 global_step: 950/3750	 lr: 0.00075	 loss: 0.0015
2022-01-11 17:27:44:INFO:Epoch: 1	 global_step: 1000/3750	 lr: 0.00073	 loss: 0.0011
2022-01-11 17:28:59:INFO:Epoch: 1	 global_step: 1050/3750	 lr: 0.00072	 loss: 0.0017
2022-01-11 17:30:14:INFO:Epoch: 1	 global_step: 1100/3750	 lr: 0.00071	 loss: 0.0011
2022-01-11 17:31:29:INFO:Epoch: 1	 global_step: 1150/3750	 lr: 0.00069	 loss: 0.0011
2022-01-11 17:32:44:INFO:Epoch: 1	 global_step: 1200/3750	 lr: 0.00068	 loss: 0.0016
2022-01-11 17:33:59:INFO:Epoch: 1	 global_step: 1250/3750	 lr: 0.00067	 loss: 0.0009
2022-01-11 17:35:14:INFO:Epoch: 1	 global_step: 1300/3750	 lr: 0.00065	 loss: 0.0010
2022-01-11 17:36:29:INFO:Epoch: 1	 global_step: 1350/3750	 lr: 0.00064	 loss: 0.0009
2022-01-11 17:37:45:INFO:Epoch: 1	 global_step: 1400/3750	 lr: 0.00063	 loss: 0.0010
2022-01-11 17:39:00:INFO:Epoch: 1	 global_step: 1450/3750	 lr: 0.00061	 loss: 0.0009
2022-01-11 17:40:21:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-11 17:40:21:INFO:	Num examples = 100
2022-01-11 17:40:21:INFO:	RMSE = 19.1940
2022-01-11 17:40:28:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-11 17:40:28:INFO:	Num examples = 100
2022-01-11 17:40:28:INFO:	RMSE = 25.8986
2022-01-11 17:40:28:INFO:==> Minimal valid RMSE!
2022-01-11 17:40:28:INFO:Save model to cnn2dmodels/data-1_n_epochs-5_aug-150_noise-0.01_supportSize-2_innerSteps-2_lrMeta-0.001_lrInner-0.0001_warmUp-0.0_seed-42...
2022-01-11 17:40:29:INFO:Epoch: 2	 global_step: 1500/3750	 lr: 0.00060	 loss: 0.0009
2022-01-11 17:41:44:INFO:Epoch: 2	 global_step: 1550/3750	 lr: 0.00059	 loss: 0.0009
2022-01-11 17:42:58:INFO:Epoch: 2	 global_step: 1600/3750	 lr: 0.00057	 loss: 0.0008
2022-01-11 17:44:13:INFO:Epoch: 2	 global_step: 1650/3750	 lr: 0.00056	 loss: 0.0010
2022-01-11 17:45:28:INFO:Epoch: 2	 global_step: 1700/3750	 lr: 0.00055	 loss: 0.0008
2022-01-11 17:46:43:INFO:Epoch: 2	 global_step: 1750/3750	 lr: 0.00053	 loss: 0.0008
2022-01-11 17:47:58:INFO:Epoch: 2	 global_step: 1800/3750	 lr: 0.00052	 loss: 0.0008
2022-01-11 17:49:13:INFO:Epoch: 2	 global_step: 1850/3750	 lr: 0.00051	 loss: 0.0007
2022-01-11 17:50:28:INFO:Epoch: 2	 global_step: 1900/3750	 lr: 0.00049	 loss: 0.0006
2022-01-11 17:51:42:INFO:Epoch: 2	 global_step: 1950/3750	 lr: 0.00048	 loss: 0.0007
2022-01-11 17:52:57:INFO:Epoch: 2	 global_step: 2000/3750	 lr: 0.00047	 loss: 0.0006
2022-01-11 17:54:12:INFO:Epoch: 2	 global_step: 2050/3750	 lr: 0.00045	 loss: 0.0006
2022-01-11 17:55:26:INFO:Epoch: 2	 global_step: 2100/3750	 lr: 0.00044	 loss: 0.0007
2022-01-11 17:56:40:INFO:Epoch: 2	 global_step: 2150/3750	 lr: 0.00043	 loss: 0.0005
2022-01-11 17:57:55:INFO:Epoch: 2	 global_step: 2200/3750	 lr: 0.00041	 loss: 0.0006
2022-01-11 17:59:15:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-11 17:59:15:INFO:	Num examples = 100
2022-01-11 17:59:15:INFO:	RMSE = 18.7697
2022-01-11 17:59:22:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-11 17:59:22:INFO:	Num examples = 100
2022-01-11 17:59:22:INFO:	RMSE = 23.3787
2022-01-11 17:59:22:INFO:==> Minimal valid RMSE!
2022-01-11 17:59:22:INFO:Save model to cnn2dmodels/data-1_n_epochs-5_aug-150_noise-0.01_supportSize-2_innerSteps-2_lrMeta-0.001_lrInner-0.0001_warmUp-0.0_seed-42...
2022-01-11 17:59:24:INFO:Epoch: 3	 global_step: 2250/3750	 lr: 0.00040	 loss: 0.0005
2022-01-11 18:00:38:INFO:Epoch: 3	 global_step: 2300/3750	 lr: 0.00039	 loss: 0.0005
2022-01-11 18:01:53:INFO:Epoch: 3	 global_step: 2350/3750	 lr: 0.00037	 loss: 0.0005
2022-01-11 18:03:08:INFO:Epoch: 3	 global_step: 2400/3750	 lr: 0.00036	 loss: 0.0004
2022-01-11 18:04:22:INFO:Epoch: 3	 global_step: 2450/3750	 lr: 0.00035	 loss: 0.0005
2022-01-11 18:05:37:INFO:Epoch: 3	 global_step: 2500/3750	 lr: 0.00033	 loss: 0.0005
2022-01-11 18:06:52:INFO:Epoch: 3	 global_step: 2550/3750	 lr: 0.00032	 loss: 0.0004
2022-01-11 18:08:07:INFO:Epoch: 3	 global_step: 2600/3750	 lr: 0.00031	 loss: 0.0005
2022-01-11 18:09:22:INFO:Epoch: 3	 global_step: 2650/3750	 lr: 0.00029	 loss: 0.0004
2022-01-11 18:10:37:INFO:Epoch: 3	 global_step: 2700/3750	 lr: 0.00028	 loss: 0.0005
2022-01-11 18:11:52:INFO:Epoch: 3	 global_step: 2750/3750	 lr: 0.00027	 loss: 0.0004
2022-01-11 18:13:07:INFO:Epoch: 3	 global_step: 2800/3750	 lr: 0.00025	 loss: 0.0004
2022-01-11 18:14:22:INFO:Epoch: 3	 global_step: 2850/3750	 lr: 0.00024	 loss: 0.0004
2022-01-11 18:15:37:INFO:Epoch: 3	 global_step: 2900/3750	 lr: 0.00023	 loss: 0.0003
2022-01-11 18:16:52:INFO:Epoch: 3	 global_step: 2950/3750	 lr: 0.00021	 loss: 0.0003
2022-01-11 18:18:12:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-11 18:18:12:INFO:	Num examples = 100
2022-01-11 18:18:12:INFO:	RMSE = 16.0879
2022-01-11 18:18:19:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-11 18:18:19:INFO:	Num examples = 100
2022-01-11 18:18:19:INFO:	RMSE = 21.9694
2022-01-11 18:18:19:INFO:==> Minimal valid RMSE!
2022-01-11 18:18:19:INFO:Save model to cnn2dmodels/data-1_n_epochs-5_aug-150_noise-0.01_supportSize-2_innerSteps-2_lrMeta-0.001_lrInner-0.0001_warmUp-0.0_seed-42...
2022-01-11 18:18:21:INFO:Epoch: 4	 global_step: 3000/3750	 lr: 0.00020	 loss: 0.0004
2022-01-11 18:19:35:INFO:Epoch: 4	 global_step: 3050/3750	 lr: 0.00019	 loss: 0.0003
2022-01-11 18:20:50:INFO:Epoch: 4	 global_step: 3100/3750	 lr: 0.00017	 loss: 0.0003
2022-01-11 18:22:05:INFO:Epoch: 4	 global_step: 3150/3750	 lr: 0.00016	 loss: 0.0004
2022-01-11 18:23:21:INFO:Epoch: 4	 global_step: 3200/3750	 lr: 0.00015	 loss: 0.0004
2022-01-11 18:24:36:INFO:Epoch: 4	 global_step: 3250/3750	 lr: 0.00013	 loss: 0.0003
2022-01-11 18:25:52:INFO:Epoch: 4	 global_step: 3300/3750	 lr: 0.00012	 loss: 0.0004
2022-01-11 18:27:06:INFO:Epoch: 4	 global_step: 3350/3750	 lr: 0.00011	 loss: 0.0003
2022-01-11 18:28:21:INFO:Epoch: 4	 global_step: 3400/3750	 lr: 0.00009	 loss: 0.0004
2022-01-11 18:29:36:INFO:Epoch: 4	 global_step: 3450/3750	 lr: 0.00008	 loss: 0.0004
2022-01-11 18:30:51:INFO:Epoch: 4	 global_step: 3500/3750	 lr: 0.00007	 loss: 0.0004
2022-01-11 18:32:05:INFO:Epoch: 4	 global_step: 3550/3750	 lr: 0.00005	 loss: 0.0004
2022-01-11 18:33:20:INFO:Epoch: 4	 global_step: 3600/3750	 lr: 0.00004	 loss: 0.0004
2022-01-11 18:34:35:INFO:Epoch: 4	 global_step: 3650/3750	 lr: 0.00003	 loss: 0.0003
2022-01-11 18:35:50:INFO:Epoch: 4	 global_step: 3700/3750	 lr: 0.00001	 loss: 0.0004
2022-01-11 18:37:11:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-11 18:37:11:INFO:	Num examples = 100
2022-01-11 18:37:11:INFO:	RMSE = 13.7529
2022-01-11 18:37:18:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-11 18:37:18:INFO:	Num examples = 100
2022-01-11 18:37:18:INFO:	RMSE = 25.5516
2022-01-11 18:37:18:INFO:	Output TEST RMSE:	16.0879
2022-01-11 18:37:18:INFO:	VALID RMSEs:	27.5359	25.8986	23.3787	21.9694	25.5516
2022-01-11 18:37:18:INFO:	TEST RMSEs:	23.4757	19.1940	18.7697	16.0879	13.7529
!!! Reset batch info !!! mode: [TRAIN]
!!! Reset batch info !!! mode: [TEST]
!!! Reset batch info !!! mode: [VALID]
!!! Reset batch info !!! mode: [TRAIN]
!!! Reset batch info !!! mode: [TEST]
!!! Reset batch info !!! mode: [VALID]
!!! Reset batch info !!! mode: [TRAIN]
!!! Reset batch info !!! mode: [TEST]
!!! Reset batch info !!! mode: [VALID]
!!! Reset batch info !!! mode: [TRAIN]
!!! Reset batch info !!! mode: [TEST]
!!! Reset batch info !!! mode: [VALID]
2022-01-11 18:37:22:INFO:Finish setting logger...
2022-01-11 18:37:22:INFO:==> Training/Evaluation parameters are:
2022-01-11 18:37:22:INFO:	Namespace(model_dir='cnn2dmodels/data-1_n_epochs-5_aug-150_noise-0.01_supportSize-2_innerSteps-2_lrMeta-0.001_lrInner-0.001_warmUp-0.0_seed-42'
2022-01-11 18:37:22:INFO:	data_fn=1
2022-01-11 18:37:22:INFO:	datatest_fn=1
2022-01-11 18:37:22:INFO:	filter_kernel_size=1
2022-01-11 18:37:22:INFO:	override_data_cache=False
2022-01-11 18:37:22:INFO:	maxRUL=125
2022-01-11 18:37:22:INFO:	low_ratio=0.1
2022-01-11 18:37:22:INFO:	high_ratio=0.99
2022-01-11 18:37:22:INFO:	aug_ratio=150
2022-01-11 18:37:22:INFO:	noise_amplitude=0.01
2022-01-11 18:37:22:INFO:	modeltype='cnn2d'
2022-01-11 18:37:22:INFO:	max_seq_len=550
2022-01-11 18:37:22:INFO:	d_model=128
2022-01-11 18:37:22:INFO:	p_dropout=0.1
2022-01-11 18:37:22:INFO:	n_head=4
2022-01-11 18:37:22:INFO:	n_layer=2
2022-01-11 18:37:22:INFO:	dim_feedforward=512
2022-01-11 18:37:22:INFO:	e_dropout=0.1
2022-01-11 18:37:22:INFO:	activation='relu'
2022-01-11 18:37:22:INFO:	layer_norm=False
2022-01-11 18:37:22:INFO:	support_size=2
2022-01-11 18:37:22:INFO:	inner_steps=2
2022-01-11 18:37:22:INFO:	lr_inner=0.001
2022-01-11 18:37:22:INFO:	lr_meta=0.001
2022-01-11 18:37:22:INFO:	n_epochs=5
2022-01-11 18:37:22:INFO:	train_batch_size=20
2022-01-11 18:37:22:INFO:	eval_batch_size=1
2022-01-11 18:37:22:INFO:	lr=0.001
2022-01-11 18:37:22:INFO:	weight_decay=0.01
2022-01-11 18:37:22:INFO:	warmup_ratio=0.0
2022-01-11 18:37:22:INFO:	max_grad_norm=5.0
2022-01-11 18:37:22:INFO:	logging_steps=50
2022-01-11 18:37:22:INFO:	seed=42
2022-01-11 18:37:22:INFO:	gpu_id=2
2022-01-11 18:37:22:INFO:	do_train=True
2022-01-11 18:37:22:INFO:	do_eval=False
2022-01-11 18:37:22:INFO:	train_data_fn='data/train_FD001.txt'
2022-01-11 18:37:22:INFO:	test_data_fn='data/test_FD001.txt'
2022-01-11 18:37:22:INFO:	target_ruls_fn='data/RUL_FD001.txt'
2022-01-11 18:37:22:INFO:	device=device(type='cuda'))
2022-01-11 18:37:22:INFO:Dump arguments to cnn2dmodels/data-1_n_epochs-5_aug-150_noise-0.01_supportSize-2_innerSteps-2_lrMeta-0.001_lrInner-0.001_warmUp-0.0_seed-42...
2022-01-11 18:37:22:INFO:==> Read data from data/train_FD001.txt...
2022-01-11 18:37:22:INFO:	The selected feature idxs are: 0, 1, 4, 5, 6, 9, 10, 11, 13, 14, 15, 16, 17, 19, 22, 23
2022-01-11 18:37:22:INFO:==> Min_max normalization...
2022-01-11 18:37:22:INFO:	The min value is [-0.008700000122189522, -0.0006000000284984708, 641.2100219726562, 1571.0400390625, 1382.25, 549.8499755859375, 2387.89990234375, 9021.73046875, 46.849998474121094, 518.6900024414062, 2387.8798828125, 8099.93994140625, 8.324899673461914, 388.0, 38.13999938964844, 22.89419937133789]
2022-01-11 18:37:22:INFO:	The max value is [0.008700000122189522, 0.0006000000284984708, 644.530029296875, 1616.9100341796875, 1441.489990234375, 556.0599975585938, 2388.56005859375, 9244.58984375, 48.529998779296875, 523.3800048828125, 2388.56005859375, 8293.7197265625, 8.584799766540527, 400.0, 39.43000030517578, 23.61840057373047]
2022-01-11 18:37:22:INFO:==> Read data from data/test_FD001.txt...
2022-01-11 18:37:22:INFO:	The selected feature idxs are: 0, 1, 4, 5, 6, 9, 10, 11, 13, 14, 15, 16, 17, 19, 22, 23
2022-01-11 18:37:22:INFO:==> Read RULsfrom data/RUL_FD001.txt...
2022-01-11 18:37:22:INFO:	min_rul: 7, max_rul: 145
2022-01-11 18:37:22:INFO:==> Input length ratio of the [TEST] data:
2022-01-11 18:37:22:INFO:	min_ratio = 0.2067
2022-01-11 18:37:22:INFO:	max_ratio = 0.9667
2022-01-11 18:37:22:INFO:==> Min_max normalization...
2022-01-11 18:37:22:INFO:	With given min value [-0.008700000122189522, -0.0006000000284984708, 641.2100219726562, 1571.0400390625, 1382.25, 549.8499755859375, 2387.89990234375, 9021.73046875, 46.849998474121094, 518.6900024414062, 2387.8798828125, 8099.93994140625, 8.324899673461914, 388.0, 38.13999938964844, 22.89419937133789]
2022-01-11 18:37:22:INFO:	With given max value [0.008700000122189522, 0.0006000000284984708, 644.530029296875, 1616.9100341796875, 1441.489990234375, 556.0599975585938, 2388.56005859375, 9244.58984375, 48.529998779296875, 523.3800048828125, 2388.56005859375, 8293.7197265625, 8.584799766540527, 400.0, 39.43000030517578, 23.61840057373047]
2022-01-11 18:37:22:INFO:==> Computing Criterion...
2022-01-11 18:37:23:INFO:	The weights are: 0.007887763902544975, 0.008001004345715046, 0.06667434424161911, 0.0634712353348732, 0.07656104862689972, 0.0755249634385109, 0.06726357340812683, 0.0644979178905487, 0.0795108750462532, 0.07743842899799347, 0.0671684592962265, 0.06869389116764069, 0.07147877663373947, 0.06516212970018387, 0.07012488692998886, 0.07054071873426437
2022-01-11 18:37:31:INFO:Note: NumExpr detected 40 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2022-01-11 18:37:31:INFO:NumExpr defaulting to 8 threads.
2022-01-11 18:37:31:INFO:=============== Scheme: Meta Learning ===============
2022-01-11 18:37:31:INFO:	Num examples = 15000
2022-01-11 18:37:31:INFO:	Num epochs = 5
2022-01-11 18:37:31:INFO:	Batch size = 20
2022-01-11 18:37:31:INFO:	Total meta optimization steps = 3750
2022-01-11 18:37:31:INFO:	Total inner optimization steps = 7500
2022-01-11 18:37:38:INFO:==> Group parameters for optimization...
2022-01-11 18:37:38:INFO:    Parameters to update are:
2022-01-11 18:37:38:INFO:	conv1.0.weight
2022-01-11 18:37:38:INFO:	conv2.0.weight
2022-01-11 18:37:38:INFO:	conv3.0.weight
2022-01-11 18:37:38:INFO:	conv4.0.weight
2022-01-11 18:37:38:INFO:	conv5.0.weight
2022-01-11 18:37:38:INFO:	fc_1.0.weight
2022-01-11 18:37:38:INFO:	fc_1.0.bias
2022-01-11 18:37:38:INFO:	fc_2.weight
2022-01-11 18:37:38:INFO:	fc_2.bias
/data/moy20/Meta-Learning/Meta-prognosis-main/optimizer.py:78: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448255797/work/torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
/data/moy20/miniconda3/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
2022-01-11 18:37:41:INFO:Epoch: 0	 global_step: 0/3750	 lr: 0.00100	 loss: 0.0017
2022-01-11 18:38:56:INFO:Epoch: 0	 global_step: 50/3750	 lr: 0.00099	 loss: 0.0195
2022-01-11 18:40:11:INFO:Epoch: 0	 global_step: 100/3750	 lr: 0.00097	 loss: 0.0067
2022-01-11 18:41:26:INFO:Epoch: 0	 global_step: 150/3750	 lr: 0.00096	 loss: 0.0061
2022-01-11 18:42:41:INFO:Epoch: 0	 global_step: 200/3750	 lr: 0.00095	 loss: 0.0039
2022-01-11 18:43:56:INFO:Epoch: 0	 global_step: 250/3750	 lr: 0.00093	 loss: 0.0038
2022-01-11 18:45:11:INFO:Epoch: 0	 global_step: 300/3750	 lr: 0.00092	 loss: 0.0032
2022-01-11 18:46:26:INFO:Epoch: 0	 global_step: 350/3750	 lr: 0.00091	 loss: 0.0027
2022-01-11 18:47:40:INFO:Epoch: 0	 global_step: 400/3750	 lr: 0.00089	 loss: 0.0035
2022-01-11 18:48:56:INFO:Epoch: 0	 global_step: 450/3750	 lr: 0.00088	 loss: 0.0022
2022-01-11 18:50:11:INFO:Epoch: 0	 global_step: 500/3750	 lr: 0.00087	 loss: 0.0023
2022-01-11 18:51:26:INFO:Epoch: 0	 global_step: 550/3750	 lr: 0.00085	 loss: 0.0018
2022-01-11 18:52:40:INFO:Epoch: 0	 global_step: 600/3750	 lr: 0.00084	 loss: 0.0018
2022-01-11 18:53:55:INFO:Epoch: 0	 global_step: 650/3750	 lr: 0.00083	 loss: 0.0019
2022-01-11 18:55:10:INFO:Epoch: 0	 global_step: 700/3750	 lr: 0.00081	 loss: 0.0015
2022-01-11 18:56:30:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-11 18:56:30:INFO:	Num examples = 100
2022-01-11 18:56:30:INFO:	RMSE = 23.4757
2022-01-11 18:56:37:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-11 18:56:37:INFO:	Num examples = 100
2022-01-11 18:56:37:INFO:	RMSE = 27.5359
2022-01-11 18:56:37:INFO:==> Minimal valid RMSE!
2022-01-11 18:56:37:INFO:Save model to cnn2dmodels/data-1_n_epochs-5_aug-150_noise-0.01_supportSize-2_innerSteps-2_lrMeta-0.001_lrInner-0.001_warmUp-0.0_seed-42...
2022-01-11 18:56:39:INFO:Epoch: 1	 global_step: 750/3750	 lr: 0.00080	 loss: 0.0015
2022-01-11 18:57:53:INFO:Epoch: 1	 global_step: 800/3750	 lr: 0.00079	 loss: 0.0023
2022-01-11 18:59:08:INFO:Epoch: 1	 global_step: 850/3750	 lr: 0.00077	 loss: 0.0016
2022-01-11 19:00:23:INFO:Epoch: 1	 global_step: 900/3750	 lr: 0.00076	 loss: 0.0011
2022-01-11 19:01:38:INFO:Epoch: 1	 global_step: 950/3750	 lr: 0.00075	 loss: 0.0015
2022-01-11 19:02:53:INFO:Epoch: 1	 global_step: 1000/3750	 lr: 0.00073	 loss: 0.0011
2022-01-11 19:04:09:INFO:Epoch: 1	 global_step: 1050/3750	 lr: 0.00072	 loss: 0.0017
2022-01-11 19:05:24:INFO:Epoch: 1	 global_step: 1100/3750	 lr: 0.00071	 loss: 0.0011
2022-01-11 19:06:40:INFO:Epoch: 1	 global_step: 1150/3750	 lr: 0.00069	 loss: 0.0011
2022-01-11 19:07:56:INFO:Epoch: 1	 global_step: 1200/3750	 lr: 0.00068	 loss: 0.0016
2022-01-11 19:09:11:INFO:Epoch: 1	 global_step: 1250/3750	 lr: 0.00067	 loss: 0.0009
2022-01-11 19:10:27:INFO:Epoch: 1	 global_step: 1300/3750	 lr: 0.00065	 loss: 0.0010
2022-01-11 19:11:42:INFO:Epoch: 1	 global_step: 1350/3750	 lr: 0.00064	 loss: 0.0009
2022-01-11 19:12:58:INFO:Epoch: 1	 global_step: 1400/3750	 lr: 0.00063	 loss: 0.0010
2022-01-11 19:14:13:INFO:Epoch: 1	 global_step: 1450/3750	 lr: 0.00061	 loss: 0.0009
2022-01-11 19:15:34:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-11 19:15:34:INFO:	Num examples = 100
2022-01-11 19:15:34:INFO:	RMSE = 19.1940
2022-01-11 19:15:42:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-11 19:15:42:INFO:	Num examples = 100
2022-01-11 19:15:42:INFO:	RMSE = 25.8986
2022-01-11 19:15:42:INFO:==> Minimal valid RMSE!
2022-01-11 19:15:42:INFO:Save model to cnn2dmodels/data-1_n_epochs-5_aug-150_noise-0.01_supportSize-2_innerSteps-2_lrMeta-0.001_lrInner-0.001_warmUp-0.0_seed-42...
2022-01-11 19:15:43:INFO:Epoch: 2	 global_step: 1500/3750	 lr: 0.00060	 loss: 0.0009
2022-01-11 19:16:59:INFO:Epoch: 2	 global_step: 1550/3750	 lr: 0.00059	 loss: 0.0009
2022-01-11 19:18:16:INFO:Epoch: 2	 global_step: 1600/3750	 lr: 0.00057	 loss: 0.0008
2022-01-11 19:19:32:INFO:Epoch: 2	 global_step: 1650/3750	 lr: 0.00056	 loss: 0.0010
2022-01-11 19:20:46:INFO:Epoch: 2	 global_step: 1700/3750	 lr: 0.00055	 loss: 0.0008
2022-01-11 19:22:01:INFO:Epoch: 2	 global_step: 1750/3750	 lr: 0.00053	 loss: 0.0008
2022-01-11 19:23:17:INFO:Epoch: 2	 global_step: 1800/3750	 lr: 0.00052	 loss: 0.0008
2022-01-11 19:24:30:INFO:Epoch: 2	 global_step: 1850/3750	 lr: 0.00051	 loss: 0.0007
2022-01-11 19:25:44:INFO:Epoch: 2	 global_step: 1900/3750	 lr: 0.00049	 loss: 0.0006
2022-01-11 19:26:58:INFO:Epoch: 2	 global_step: 1950/3750	 lr: 0.00048	 loss: 0.0007
2022-01-11 19:28:12:INFO:Epoch: 2	 global_step: 2000/3750	 lr: 0.00047	 loss: 0.0006
2022-01-11 19:29:26:INFO:Epoch: 2	 global_step: 2050/3750	 lr: 0.00045	 loss: 0.0006
2022-01-11 19:30:40:INFO:Epoch: 2	 global_step: 2100/3750	 lr: 0.00044	 loss: 0.0007
2022-01-11 19:31:55:INFO:Epoch: 2	 global_step: 2150/3750	 lr: 0.00043	 loss: 0.0005
2022-01-11 19:33:09:INFO:Epoch: 2	 global_step: 2200/3750	 lr: 0.00041	 loss: 0.0006
2022-01-11 19:34:29:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-11 19:34:29:INFO:	Num examples = 100
2022-01-11 19:34:29:INFO:	RMSE = 18.7697
2022-01-11 19:34:36:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-11 19:34:36:INFO:	Num examples = 100
2022-01-11 19:34:36:INFO:	RMSE = 23.3787
2022-01-11 19:34:36:INFO:==> Minimal valid RMSE!
2022-01-11 19:34:36:INFO:Save model to cnn2dmodels/data-1_n_epochs-5_aug-150_noise-0.01_supportSize-2_innerSteps-2_lrMeta-0.001_lrInner-0.001_warmUp-0.0_seed-42...
2022-01-11 19:34:38:INFO:Epoch: 3	 global_step: 2250/3750	 lr: 0.00040	 loss: 0.0005
2022-01-11 19:35:52:INFO:Epoch: 3	 global_step: 2300/3750	 lr: 0.00039	 loss: 0.0005
2022-01-11 19:37:06:INFO:Epoch: 3	 global_step: 2350/3750	 lr: 0.00037	 loss: 0.0005
2022-01-11 19:38:20:INFO:Epoch: 3	 global_step: 2400/3750	 lr: 0.00036	 loss: 0.0004
2022-01-11 19:39:35:INFO:Epoch: 3	 global_step: 2450/3750	 lr: 0.00035	 loss: 0.0005
2022-01-11 19:40:48:INFO:Epoch: 3	 global_step: 2500/3750	 lr: 0.00033	 loss: 0.0005
2022-01-11 19:42:03:INFO:Epoch: 3	 global_step: 2550/3750	 lr: 0.00032	 loss: 0.0004
2022-01-11 19:43:17:INFO:Epoch: 3	 global_step: 2600/3750	 lr: 0.00031	 loss: 0.0005
2022-01-11 19:44:32:INFO:Epoch: 3	 global_step: 2650/3750	 lr: 0.00029	 loss: 0.0004
2022-01-11 19:45:46:INFO:Epoch: 3	 global_step: 2700/3750	 lr: 0.00028	 loss: 0.0005
2022-01-11 19:47:00:INFO:Epoch: 3	 global_step: 2750/3750	 lr: 0.00027	 loss: 0.0004
2022-01-11 19:48:14:INFO:Epoch: 3	 global_step: 2800/3750	 lr: 0.00025	 loss: 0.0004
2022-01-11 19:49:28:INFO:Epoch: 3	 global_step: 2850/3750	 lr: 0.00024	 loss: 0.0004
2022-01-11 19:50:42:INFO:Epoch: 3	 global_step: 2900/3750	 lr: 0.00023	 loss: 0.0003
2022-01-11 19:51:56:INFO:Epoch: 3	 global_step: 2950/3750	 lr: 0.00021	 loss: 0.0003
2022-01-11 19:53:15:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-11 19:53:15:INFO:	Num examples = 100
2022-01-11 19:53:15:INFO:	RMSE = 16.0879
2022-01-11 19:53:22:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-11 19:53:22:INFO:	Num examples = 100
2022-01-11 19:53:22:INFO:	RMSE = 21.9694
2022-01-11 19:53:22:INFO:==> Minimal valid RMSE!
2022-01-11 19:53:22:INFO:Save model to cnn2dmodels/data-1_n_epochs-5_aug-150_noise-0.01_supportSize-2_innerSteps-2_lrMeta-0.001_lrInner-0.001_warmUp-0.0_seed-42...
2022-01-11 19:53:24:INFO:Epoch: 4	 global_step: 3000/3750	 lr: 0.00020	 loss: 0.0004
2022-01-11 19:54:38:INFO:Epoch: 4	 global_step: 3050/3750	 lr: 0.00019	 loss: 0.0003
2022-01-11 19:55:52:INFO:Epoch: 4	 global_step: 3100/3750	 lr: 0.00017	 loss: 0.0003
2022-01-11 19:57:06:INFO:Epoch: 4	 global_step: 3150/3750	 lr: 0.00016	 loss: 0.0004
2022-01-11 19:58:20:INFO:Epoch: 4	 global_step: 3200/3750	 lr: 0.00015	 loss: 0.0004
2022-01-11 19:59:34:INFO:Epoch: 4	 global_step: 3250/3750	 lr: 0.00013	 loss: 0.0003
2022-01-11 20:00:48:INFO:Epoch: 4	 global_step: 3300/3750	 lr: 0.00012	 loss: 0.0004
2022-01-11 20:02:02:INFO:Epoch: 4	 global_step: 3350/3750	 lr: 0.00011	 loss: 0.0003
2022-01-11 20:03:16:INFO:Epoch: 4	 global_step: 3400/3750	 lr: 0.00009	 loss: 0.0004
2022-01-11 20:04:30:INFO:Epoch: 4	 global_step: 3450/3750	 lr: 0.00008	 loss: 0.0004
2022-01-11 20:05:44:INFO:Epoch: 4	 global_step: 3500/3750	 lr: 0.00007	 loss: 0.0004
2022-01-11 20:06:58:INFO:Epoch: 4	 global_step: 3550/3750	 lr: 0.00005	 loss: 0.0004
2022-01-11 20:08:12:INFO:Epoch: 4	 global_step: 3600/3750	 lr: 0.00004	 loss: 0.0004
2022-01-11 20:09:27:INFO:Epoch: 4	 global_step: 3650/3750	 lr: 0.00003	 loss: 0.0003
2022-01-11 20:10:42:INFO:Epoch: 4	 global_step: 3700/3750	 lr: 0.00001	 loss: 0.0004
2022-01-11 20:12:02:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-11 20:12:02:INFO:	Num examples = 100
2022-01-11 20:12:02:INFO:	RMSE = 13.7529
2022-01-11 20:12:09:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-11 20:12:09:INFO:	Num examples = 100
2022-01-11 20:12:09:INFO:	RMSE = 25.5516
2022-01-11 20:12:09:INFO:	Output TEST RMSE:	16.0879
2022-01-11 20:12:09:INFO:	VALID RMSEs:	27.5359	25.8986	23.3787	21.9694	25.5516
2022-01-11 20:12:09:INFO:	TEST RMSEs:	23.4757	19.1940	18.7697	16.0879	13.7529
!!! Reset batch info !!! mode: [TRAIN]
!!! Reset batch info !!! mode: [TEST]
!!! Reset batch info !!! mode: [VALID]
!!! Reset batch info !!! mode: [TRAIN]
!!! Reset batch info !!! mode: [TEST]
!!! Reset batch info !!! mode: [VALID]
!!! Reset batch info !!! mode: [TRAIN]
!!! Reset batch info !!! mode: [TEST]
!!! Reset batch info !!! mode: [VALID]
!!! Reset batch info !!! mode: [TRAIN]
!!! Reset batch info !!! mode: [TEST]
!!! Reset batch info !!! mode: [VALID]
2022-01-11 20:12:13:INFO:Finish setting logger...
2022-01-11 20:12:13:INFO:==> Training/Evaluation parameters are:
2022-01-11 20:12:13:INFO:	Namespace(model_dir='cnn2dmodels/data-1_n_epochs-5_aug-150_noise-0.01_supportSize-5_innerSteps-2_lrMeta-0.001_lrInner-0.0001_warmUp-0.0_seed-42'
2022-01-11 20:12:13:INFO:	data_fn=1
2022-01-11 20:12:13:INFO:	datatest_fn=1
2022-01-11 20:12:13:INFO:	filter_kernel_size=1
2022-01-11 20:12:13:INFO:	override_data_cache=False
2022-01-11 20:12:13:INFO:	maxRUL=125
2022-01-11 20:12:13:INFO:	low_ratio=0.1
2022-01-11 20:12:13:INFO:	high_ratio=0.99
2022-01-11 20:12:13:INFO:	aug_ratio=150
2022-01-11 20:12:13:INFO:	noise_amplitude=0.01
2022-01-11 20:12:13:INFO:	modeltype='cnn2d'
2022-01-11 20:12:13:INFO:	max_seq_len=550
2022-01-11 20:12:13:INFO:	d_model=128
2022-01-11 20:12:13:INFO:	p_dropout=0.1
2022-01-11 20:12:13:INFO:	n_head=4
2022-01-11 20:12:13:INFO:	n_layer=2
2022-01-11 20:12:13:INFO:	dim_feedforward=512
2022-01-11 20:12:13:INFO:	e_dropout=0.1
2022-01-11 20:12:13:INFO:	activation='relu'
2022-01-11 20:12:13:INFO:	layer_norm=False
2022-01-11 20:12:13:INFO:	support_size=5
2022-01-11 20:12:13:INFO:	inner_steps=2
2022-01-11 20:12:13:INFO:	lr_inner=0.0001
2022-01-11 20:12:13:INFO:	lr_meta=0.001
2022-01-11 20:12:13:INFO:	n_epochs=5
2022-01-11 20:12:13:INFO:	train_batch_size=20
2022-01-11 20:12:13:INFO:	eval_batch_size=1
2022-01-11 20:12:13:INFO:	lr=0.001
2022-01-11 20:12:13:INFO:	weight_decay=0.01
2022-01-11 20:12:13:INFO:	warmup_ratio=0.0
2022-01-11 20:12:13:INFO:	max_grad_norm=5.0
2022-01-11 20:12:13:INFO:	logging_steps=50
2022-01-11 20:12:13:INFO:	seed=42
2022-01-11 20:12:13:INFO:	gpu_id=2
2022-01-11 20:12:13:INFO:	do_train=True
2022-01-11 20:12:13:INFO:	do_eval=False
2022-01-11 20:12:13:INFO:	train_data_fn='data/train_FD001.txt'
2022-01-11 20:12:13:INFO:	test_data_fn='data/test_FD001.txt'
2022-01-11 20:12:13:INFO:	target_ruls_fn='data/RUL_FD001.txt'
2022-01-11 20:12:13:INFO:	device=device(type='cuda'))
2022-01-11 20:12:13:INFO:Dump arguments to cnn2dmodels/data-1_n_epochs-5_aug-150_noise-0.01_supportSize-5_innerSteps-2_lrMeta-0.001_lrInner-0.0001_warmUp-0.0_seed-42...
2022-01-11 20:12:13:INFO:==> Read data from data/train_FD001.txt...
2022-01-11 20:12:13:INFO:	The selected feature idxs are: 0, 1, 4, 5, 6, 9, 10, 11, 13, 14, 15, 16, 17, 19, 22, 23
2022-01-11 20:12:13:INFO:==> Min_max normalization...
2022-01-11 20:12:13:INFO:	The min value is [-0.008700000122189522, -0.0006000000284984708, 641.2100219726562, 1571.0400390625, 1382.25, 549.8499755859375, 2387.89990234375, 9021.73046875, 46.849998474121094, 518.6900024414062, 2387.8798828125, 8099.93994140625, 8.324899673461914, 388.0, 38.13999938964844, 22.89419937133789]
2022-01-11 20:12:13:INFO:	The max value is [0.008700000122189522, 0.0006000000284984708, 644.530029296875, 1616.9100341796875, 1441.489990234375, 556.0599975585938, 2388.56005859375, 9244.58984375, 48.529998779296875, 523.3800048828125, 2388.56005859375, 8293.7197265625, 8.584799766540527, 400.0, 39.43000030517578, 23.61840057373047]
2022-01-11 20:12:13:INFO:==> Read data from data/test_FD001.txt...
2022-01-11 20:12:13:INFO:	The selected feature idxs are: 0, 1, 4, 5, 6, 9, 10, 11, 13, 14, 15, 16, 17, 19, 22, 23
2022-01-11 20:12:14:INFO:==> Read RULsfrom data/RUL_FD001.txt...
2022-01-11 20:12:14:INFO:	min_rul: 7, max_rul: 145
2022-01-11 20:12:14:INFO:==> Input length ratio of the [TEST] data:
2022-01-11 20:12:14:INFO:	min_ratio = 0.2067
2022-01-11 20:12:14:INFO:	max_ratio = 0.9667
2022-01-11 20:12:14:INFO:==> Min_max normalization...
2022-01-11 20:12:14:INFO:	With given min value [-0.008700000122189522, -0.0006000000284984708, 641.2100219726562, 1571.0400390625, 1382.25, 549.8499755859375, 2387.89990234375, 9021.73046875, 46.849998474121094, 518.6900024414062, 2387.8798828125, 8099.93994140625, 8.324899673461914, 388.0, 38.13999938964844, 22.89419937133789]
2022-01-11 20:12:14:INFO:	With given max value [0.008700000122189522, 0.0006000000284984708, 644.530029296875, 1616.9100341796875, 1441.489990234375, 556.0599975585938, 2388.56005859375, 9244.58984375, 48.529998779296875, 523.3800048828125, 2388.56005859375, 8293.7197265625, 8.584799766540527, 400.0, 39.43000030517578, 23.61840057373047]
2022-01-11 20:12:14:INFO:==> Computing Criterion...
2022-01-11 20:12:14:INFO:	The weights are: 0.007887763902544975, 0.008001004345715046, 0.06667434424161911, 0.0634712353348732, 0.07656104862689972, 0.0755249634385109, 0.06726357340812683, 0.0644979178905487, 0.0795108750462532, 0.07743842899799347, 0.0671684592962265, 0.06869389116764069, 0.07147877663373947, 0.06516212970018387, 0.07012488692998886, 0.07054071873426437
2022-01-11 20:12:27:INFO:Note: NumExpr detected 40 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2022-01-11 20:12:27:INFO:NumExpr defaulting to 8 threads.
2022-01-11 20:12:28:INFO:=============== Scheme: Meta Learning ===============
2022-01-11 20:12:28:INFO:	Num examples = 15000
2022-01-11 20:12:28:INFO:	Num epochs = 5
2022-01-11 20:12:28:INFO:	Batch size = 20
2022-01-11 20:12:28:INFO:	Total meta optimization steps = 3750
2022-01-11 20:12:28:INFO:	Total inner optimization steps = 7500
2022-01-11 20:12:35:INFO:==> Group parameters for optimization...
2022-01-11 20:12:35:INFO:    Parameters to update are:
2022-01-11 20:12:35:INFO:	conv1.0.weight
2022-01-11 20:12:35:INFO:	conv2.0.weight
2022-01-11 20:12:35:INFO:	conv3.0.weight
2022-01-11 20:12:35:INFO:	conv4.0.weight
2022-01-11 20:12:35:INFO:	conv5.0.weight
2022-01-11 20:12:35:INFO:	fc_1.0.weight
2022-01-11 20:12:35:INFO:	fc_1.0.bias
2022-01-11 20:12:35:INFO:	fc_2.weight
2022-01-11 20:12:35:INFO:	fc_2.bias
/data/moy20/Meta-Learning/Meta-prognosis-main/optimizer.py:78: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448255797/work/torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
/data/moy20/miniconda3/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
2022-01-11 20:12:39:INFO:Epoch: 0	 global_step: 0/3750	 lr: 0.00100	 loss: 0.0017
2022-01-11 20:14:09:INFO:Epoch: 0	 global_step: 50/3750	 lr: 0.00099	 loss: 0.0202
2022-01-11 20:15:39:INFO:Epoch: 0	 global_step: 100/3750	 lr: 0.00097	 loss: 0.0073
2022-01-11 20:17:09:INFO:Epoch: 0	 global_step: 150/3750	 lr: 0.00096	 loss: 0.0064
2022-01-11 20:18:40:INFO:Epoch: 0	 global_step: 200/3750	 lr: 0.00095	 loss: 0.0041
2022-01-11 20:20:10:INFO:Epoch: 0	 global_step: 250/3750	 lr: 0.00093	 loss: 0.0044
2022-01-11 20:21:41:INFO:Epoch: 0	 global_step: 300/3750	 lr: 0.00092	 loss: 0.0035
2022-01-11 20:23:11:INFO:Epoch: 0	 global_step: 350/3750	 lr: 0.00091	 loss: 0.0029
2022-01-11 20:24:42:INFO:Epoch: 0	 global_step: 400/3750	 lr: 0.00089	 loss: 0.0032
2022-01-11 20:26:13:INFO:Epoch: 0	 global_step: 450/3750	 lr: 0.00088	 loss: 0.0021
2022-01-11 20:27:44:INFO:Epoch: 0	 global_step: 500/3750	 lr: 0.00087	 loss: 0.0026
2022-01-11 20:29:14:INFO:Epoch: 0	 global_step: 550/3750	 lr: 0.00085	 loss: 0.0020
2022-01-11 20:30:45:INFO:Epoch: 0	 global_step: 600/3750	 lr: 0.00084	 loss: 0.0014
2022-01-11 20:32:16:INFO:Epoch: 0	 global_step: 650/3750	 lr: 0.00083	 loss: 0.0019
2022-01-11 20:33:47:INFO:Epoch: 0	 global_step: 700/3750	 lr: 0.00081	 loss: 0.0014
2022-01-11 20:35:25:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-11 20:35:25:INFO:	Num examples = 100
2022-01-11 20:35:25:INFO:	RMSE = 21.9415
2022-01-11 20:35:34:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-11 20:35:34:INFO:	Num examples = 100
2022-01-11 20:35:34:INFO:	RMSE = 25.1696
2022-01-11 20:35:34:INFO:==> Minimal valid RMSE!
2022-01-11 20:35:34:INFO:Save model to cnn2dmodels/data-1_n_epochs-5_aug-150_noise-0.01_supportSize-5_innerSteps-2_lrMeta-0.001_lrInner-0.0001_warmUp-0.0_seed-42...
2022-01-11 20:35:35:INFO:Epoch: 1	 global_step: 750/3750	 lr: 0.00080	 loss: 0.0014
2022-01-11 20:37:06:INFO:Epoch: 1	 global_step: 800/3750	 lr: 0.00079	 loss: 0.0016
2022-01-11 20:38:36:INFO:Epoch: 1	 global_step: 850/3750	 lr: 0.00077	 loss: 0.0012
2022-01-11 20:40:06:INFO:Epoch: 1	 global_step: 900/3750	 lr: 0.00076	 loss: 0.0011
2022-01-11 20:41:37:INFO:Epoch: 1	 global_step: 950/3750	 lr: 0.00075	 loss: 0.0012
2022-01-11 20:43:07:INFO:Epoch: 1	 global_step: 1000/3750	 lr: 0.00073	 loss: 0.0009
2022-01-11 20:44:38:INFO:Epoch: 1	 global_step: 1050/3750	 lr: 0.00072	 loss: 0.0009
2022-01-11 20:46:08:INFO:Epoch: 1	 global_step: 1100/3750	 lr: 0.00071	 loss: 0.0010
2022-01-11 20:47:39:INFO:Epoch: 1	 global_step: 1150/3750	 lr: 0.00069	 loss: 0.0010
2022-01-11 20:49:09:INFO:Epoch: 1	 global_step: 1200/3750	 lr: 0.00068	 loss: 0.0009
2022-01-11 20:50:40:INFO:Epoch: 1	 global_step: 1250/3750	 lr: 0.00067	 loss: 0.0008
2022-01-11 20:52:11:INFO:Epoch: 1	 global_step: 1300/3750	 lr: 0.00065	 loss: 0.0009
2022-01-11 20:53:42:INFO:Epoch: 1	 global_step: 1350/3750	 lr: 0.00064	 loss: 0.0009
2022-01-11 20:55:13:INFO:Epoch: 1	 global_step: 1400/3750	 lr: 0.00063	 loss: 0.0008
2022-01-11 20:56:43:INFO:Epoch: 1	 global_step: 1450/3750	 lr: 0.00061	 loss: 0.0007
2022-01-11 20:58:21:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-11 20:58:21:INFO:	Num examples = 100
2022-01-11 20:58:21:INFO:	RMSE = 17.3069
2022-01-11 20:58:30:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-11 20:58:30:INFO:	Num examples = 100
2022-01-11 20:58:30:INFO:	RMSE = 23.5998
2022-01-11 20:58:30:INFO:==> Minimal valid RMSE!
2022-01-11 20:58:30:INFO:Save model to cnn2dmodels/data-1_n_epochs-5_aug-150_noise-0.01_supportSize-5_innerSteps-2_lrMeta-0.001_lrInner-0.0001_warmUp-0.0_seed-42...
2022-01-11 20:58:32:INFO:Epoch: 2	 global_step: 1500/3750	 lr: 0.00060	 loss: 0.0010
2022-01-11 21:00:02:INFO:Epoch: 2	 global_step: 1550/3750	 lr: 0.00059	 loss: 0.0008
2022-01-11 21:01:32:INFO:Epoch: 2	 global_step: 1600/3750	 lr: 0.00057	 loss: 0.0006
2022-01-11 21:03:03:INFO:Epoch: 2	 global_step: 1650/3750	 lr: 0.00056	 loss: 0.0008
2022-01-11 21:04:34:INFO:Epoch: 2	 global_step: 1700/3750	 lr: 0.00055	 loss: 0.0007
2022-01-11 21:06:05:INFO:Epoch: 2	 global_step: 1750/3750	 lr: 0.00053	 loss: 0.0006
2022-01-11 21:07:36:INFO:Epoch: 2	 global_step: 1800/3750	 lr: 0.00052	 loss: 0.0006
2022-01-11 21:09:07:INFO:Epoch: 2	 global_step: 1850/3750	 lr: 0.00051	 loss: 0.0006
2022-01-11 21:10:38:INFO:Epoch: 2	 global_step: 1900/3750	 lr: 0.00049	 loss: 0.0006
2022-01-11 21:12:09:INFO:Epoch: 2	 global_step: 1950/3750	 lr: 0.00048	 loss: 0.0006
2022-01-11 21:13:40:INFO:Epoch: 2	 global_step: 2000/3750	 lr: 0.00047	 loss: 0.0006
2022-01-11 21:15:11:INFO:Epoch: 2	 global_step: 2050/3750	 lr: 0.00045	 loss: 0.0006
2022-01-11 21:16:41:INFO:Epoch: 2	 global_step: 2100/3750	 lr: 0.00044	 loss: 0.0005
2022-01-11 21:18:12:INFO:Epoch: 2	 global_step: 2150/3750	 lr: 0.00043	 loss: 0.0005
2022-01-11 21:19:43:INFO:Epoch: 2	 global_step: 2200/3750	 lr: 0.00041	 loss: 0.0005
2022-01-11 21:21:21:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-11 21:21:21:INFO:	Num examples = 100
2022-01-11 21:21:21:INFO:	RMSE = 15.1000
2022-01-11 21:21:29:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-11 21:21:29:INFO:	Num examples = 100
2022-01-11 21:21:29:INFO:	RMSE = 23.9737
2022-01-11 21:21:31:INFO:Epoch: 3	 global_step: 2250/3750	 lr: 0.00040	 loss: 0.0005
2022-01-11 21:23:02:INFO:Epoch: 3	 global_step: 2300/3750	 lr: 0.00039	 loss: 0.0005
2022-01-11 21:24:32:INFO:Epoch: 3	 global_step: 2350/3750	 lr: 0.00037	 loss: 0.0004
2022-01-11 21:26:02:INFO:Epoch: 3	 global_step: 2400/3750	 lr: 0.00036	 loss: 0.0004
2022-01-11 21:27:33:INFO:Epoch: 3	 global_step: 2450/3750	 lr: 0.00035	 loss: 0.0005
2022-01-11 21:29:03:INFO:Epoch: 3	 global_step: 2500/3750	 lr: 0.00033	 loss: 0.0005
2022-01-11 21:30:34:INFO:Epoch: 3	 global_step: 2550/3750	 lr: 0.00032	 loss: 0.0004
2022-01-11 21:32:04:INFO:Epoch: 3	 global_step: 2600/3750	 lr: 0.00031	 loss: 0.0005
2022-01-11 21:33:35:INFO:Epoch: 3	 global_step: 2650/3750	 lr: 0.00029	 loss: 0.0004
2022-01-11 21:35:06:INFO:Epoch: 3	 global_step: 2700/3750	 lr: 0.00028	 loss: 0.0005
2022-01-11 21:36:37:INFO:Epoch: 3	 global_step: 2750/3750	 lr: 0.00027	 loss: 0.0004
2022-01-11 21:38:07:INFO:Epoch: 3	 global_step: 2800/3750	 lr: 0.00025	 loss: 0.0004
2022-01-11 21:39:38:INFO:Epoch: 3	 global_step: 2850/3750	 lr: 0.00024	 loss: 0.0005
2022-01-11 21:41:08:INFO:Epoch: 3	 global_step: 2900/3750	 lr: 0.00023	 loss: 0.0004
2022-01-11 21:42:38:INFO:Epoch: 3	 global_step: 2950/3750	 lr: 0.00021	 loss: 0.0004
2022-01-11 21:44:15:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-11 21:44:15:INFO:	Num examples = 100
2022-01-11 21:44:15:INFO:	RMSE = 14.1533
2022-01-11 21:44:24:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-11 21:44:24:INFO:	Num examples = 100
2022-01-11 21:44:24:INFO:	RMSE = 24.2035
2022-01-11 21:44:26:INFO:Epoch: 4	 global_step: 3000/3750	 lr: 0.00020	 loss: 0.0004
2022-01-11 21:45:57:INFO:Epoch: 4	 global_step: 3050/3750	 lr: 0.00019	 loss: 0.0004
2022-01-11 21:47:28:INFO:Epoch: 4	 global_step: 3100/3750	 lr: 0.00017	 loss: 0.0004
2022-01-11 21:48:58:INFO:Epoch: 4	 global_step: 3150/3750	 lr: 0.00016	 loss: 0.0004
2022-01-11 21:50:28:INFO:Epoch: 4	 global_step: 3200/3750	 lr: 0.00015	 loss: 0.0004
2022-01-11 21:51:59:INFO:Epoch: 4	 global_step: 3250/3750	 lr: 0.00013	 loss: 0.0004
2022-01-11 21:53:29:INFO:Epoch: 4	 global_step: 3300/3750	 lr: 0.00012	 loss: 0.0004
2022-01-11 21:54:59:INFO:Epoch: 4	 global_step: 3350/3750	 lr: 0.00011	 loss: 0.0004
2022-01-11 21:56:29:INFO:Epoch: 4	 global_step: 3400/3750	 lr: 0.00009	 loss: 0.0004
2022-01-11 21:58:00:INFO:Epoch: 4	 global_step: 3450/3750	 lr: 0.00008	 loss: 0.0004
2022-01-11 21:59:31:INFO:Epoch: 4	 global_step: 3500/3750	 lr: 0.00007	 loss: 0.0003
2022-01-11 22:01:01:INFO:Epoch: 4	 global_step: 3550/3750	 lr: 0.00005	 loss: 0.0004
2022-01-11 22:02:32:INFO:Epoch: 4	 global_step: 3600/3750	 lr: 0.00004	 loss: 0.0004
2022-01-11 22:04:02:INFO:Epoch: 4	 global_step: 3650/3750	 lr: 0.00003	 loss: 0.0003
2022-01-11 22:05:33:INFO:Epoch: 4	 global_step: 3700/3750	 lr: 0.00001	 loss: 0.0004
2022-01-11 22:07:11:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-11 22:07:11:INFO:	Num examples = 100
2022-01-11 22:07:11:INFO:	RMSE = 12.9613
2022-01-11 22:07:20:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-11 22:07:20:INFO:	Num examples = 100
2022-01-11 22:07:20:INFO:	RMSE = 26.8088
2022-01-11 22:07:20:INFO:	Output TEST RMSE:	17.3069
2022-01-11 22:07:20:INFO:	VALID RMSEs:	25.1696	23.5998	23.9737	24.2035	26.8088
2022-01-11 22:07:20:INFO:	TEST RMSEs:	21.9415	17.3069	15.1000	14.1533	12.9613
!!! Reset batch info !!! mode: [TRAIN]
!!! Reset batch info !!! mode: [TEST]
!!! Reset batch info !!! mode: [VALID]
!!! Reset batch info !!! mode: [TRAIN]
!!! Reset batch info !!! mode: [TEST]
!!! Reset batch info !!! mode: [VALID]
!!! Reset batch info !!! mode: [TRAIN]
!!! Reset batch info !!! mode: [TEST]
!!! Reset batch info !!! mode: [VALID]
!!! Reset batch info !!! mode: [TRAIN]
!!! Reset batch info !!! mode: [TEST]
!!! Reset batch info !!! mode: [VALID]
2022-01-11 22:07:26:INFO:Finish setting logger...
2022-01-11 22:07:26:INFO:==> Training/Evaluation parameters are:
2022-01-11 22:07:26:INFO:	Namespace(model_dir='cnn2dmodels/data-1_n_epochs-5_aug-150_noise-0.01_supportSize-5_innerSteps-2_lrMeta-0.001_lrInner-0.001_warmUp-0.0_seed-42'
2022-01-11 22:07:26:INFO:	data_fn=1
2022-01-11 22:07:26:INFO:	datatest_fn=1
2022-01-11 22:07:26:INFO:	filter_kernel_size=1
2022-01-11 22:07:26:INFO:	override_data_cache=False
2022-01-11 22:07:26:INFO:	maxRUL=125
2022-01-11 22:07:26:INFO:	low_ratio=0.1
2022-01-11 22:07:26:INFO:	high_ratio=0.99
2022-01-11 22:07:26:INFO:	aug_ratio=150
2022-01-11 22:07:26:INFO:	noise_amplitude=0.01
2022-01-11 22:07:26:INFO:	modeltype='cnn2d'
2022-01-11 22:07:26:INFO:	max_seq_len=550
2022-01-11 22:07:26:INFO:	d_model=128
2022-01-11 22:07:26:INFO:	p_dropout=0.1
2022-01-11 22:07:26:INFO:	n_head=4
2022-01-11 22:07:26:INFO:	n_layer=2
2022-01-11 22:07:26:INFO:	dim_feedforward=512
2022-01-11 22:07:26:INFO:	e_dropout=0.1
2022-01-11 22:07:26:INFO:	activation='relu'
2022-01-11 22:07:26:INFO:	layer_norm=False
2022-01-11 22:07:26:INFO:	support_size=5
2022-01-11 22:07:26:INFO:	inner_steps=2
2022-01-11 22:07:26:INFO:	lr_inner=0.001
2022-01-11 22:07:26:INFO:	lr_meta=0.001
2022-01-11 22:07:26:INFO:	n_epochs=5
2022-01-11 22:07:26:INFO:	train_batch_size=20
2022-01-11 22:07:26:INFO:	eval_batch_size=1
2022-01-11 22:07:26:INFO:	lr=0.001
2022-01-11 22:07:26:INFO:	weight_decay=0.01
2022-01-11 22:07:26:INFO:	warmup_ratio=0.0
2022-01-11 22:07:26:INFO:	max_grad_norm=5.0
2022-01-11 22:07:26:INFO:	logging_steps=50
2022-01-11 22:07:26:INFO:	seed=42
2022-01-11 22:07:26:INFO:	gpu_id=2
2022-01-11 22:07:26:INFO:	do_train=True
2022-01-11 22:07:26:INFO:	do_eval=False
2022-01-11 22:07:26:INFO:	train_data_fn='data/train_FD001.txt'
2022-01-11 22:07:26:INFO:	test_data_fn='data/test_FD001.txt'
2022-01-11 22:07:26:INFO:	target_ruls_fn='data/RUL_FD001.txt'
2022-01-11 22:07:26:INFO:	device=device(type='cuda'))
2022-01-11 22:07:26:INFO:Dump arguments to cnn2dmodels/data-1_n_epochs-5_aug-150_noise-0.01_supportSize-5_innerSteps-2_lrMeta-0.001_lrInner-0.001_warmUp-0.0_seed-42...
2022-01-11 22:07:26:INFO:==> Read data from data/train_FD001.txt...
2022-01-11 22:07:26:INFO:	The selected feature idxs are: 0, 1, 4, 5, 6, 9, 10, 11, 13, 14, 15, 16, 17, 19, 22, 23
2022-01-11 22:07:26:INFO:==> Min_max normalization...
2022-01-11 22:07:26:INFO:	The min value is [-0.008700000122189522, -0.0006000000284984708, 641.2100219726562, 1571.0400390625, 1382.25, 549.8499755859375, 2387.89990234375, 9021.73046875, 46.849998474121094, 518.6900024414062, 2387.8798828125, 8099.93994140625, 8.324899673461914, 388.0, 38.13999938964844, 22.89419937133789]
2022-01-11 22:07:26:INFO:	The max value is [0.008700000122189522, 0.0006000000284984708, 644.530029296875, 1616.9100341796875, 1441.489990234375, 556.0599975585938, 2388.56005859375, 9244.58984375, 48.529998779296875, 523.3800048828125, 2388.56005859375, 8293.7197265625, 8.584799766540527, 400.0, 39.43000030517578, 23.61840057373047]
2022-01-11 22:07:26:INFO:==> Read data from data/test_FD001.txt...
2022-01-11 22:07:26:INFO:	The selected feature idxs are: 0, 1, 4, 5, 6, 9, 10, 11, 13, 14, 15, 16, 17, 19, 22, 23
2022-01-11 22:07:26:INFO:==> Read RULsfrom data/RUL_FD001.txt...
2022-01-11 22:07:26:INFO:	min_rul: 7, max_rul: 145
2022-01-11 22:07:26:INFO:==> Input length ratio of the [TEST] data:
2022-01-11 22:07:26:INFO:	min_ratio = 0.2067
2022-01-11 22:07:26:INFO:	max_ratio = 0.9667
2022-01-11 22:07:26:INFO:==> Min_max normalization...
2022-01-11 22:07:26:INFO:	With given min value [-0.008700000122189522, -0.0006000000284984708, 641.2100219726562, 1571.0400390625, 1382.25, 549.8499755859375, 2387.89990234375, 9021.73046875, 46.849998474121094, 518.6900024414062, 2387.8798828125, 8099.93994140625, 8.324899673461914, 388.0, 38.13999938964844, 22.89419937133789]
2022-01-11 22:07:26:INFO:	With given max value [0.008700000122189522, 0.0006000000284984708, 644.530029296875, 1616.9100341796875, 1441.489990234375, 556.0599975585938, 2388.56005859375, 9244.58984375, 48.529998779296875, 523.3800048828125, 2388.56005859375, 8293.7197265625, 8.584799766540527, 400.0, 39.43000030517578, 23.61840057373047]
2022-01-11 22:07:26:INFO:==> Computing Criterion...
2022-01-11 22:07:26:INFO:	The weights are: 0.007887763902544975, 0.008001004345715046, 0.06667434424161911, 0.0634712353348732, 0.07656104862689972, 0.0755249634385109, 0.06726357340812683, 0.0644979178905487, 0.0795108750462532, 0.07743842899799347, 0.0671684592962265, 0.06869389116764069, 0.07147877663373947, 0.06516212970018387, 0.07012488692998886, 0.07054071873426437
2022-01-11 22:07:40:INFO:Note: NumExpr detected 40 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2022-01-11 22:07:40:INFO:NumExpr defaulting to 8 threads.
2022-01-11 22:07:41:INFO:=============== Scheme: Meta Learning ===============
2022-01-11 22:07:41:INFO:	Num examples = 15000
2022-01-11 22:07:41:INFO:	Num epochs = 5
2022-01-11 22:07:41:INFO:	Batch size = 20
2022-01-11 22:07:41:INFO:	Total meta optimization steps = 3750
2022-01-11 22:07:41:INFO:	Total inner optimization steps = 7500
2022-01-11 22:07:48:INFO:==> Group parameters for optimization...
2022-01-11 22:07:48:INFO:    Parameters to update are:
2022-01-11 22:07:48:INFO:	conv1.0.weight
2022-01-11 22:07:48:INFO:	conv2.0.weight
2022-01-11 22:07:48:INFO:	conv3.0.weight
2022-01-11 22:07:48:INFO:	conv4.0.weight
2022-01-11 22:07:48:INFO:	conv5.0.weight
2022-01-11 22:07:48:INFO:	fc_1.0.weight
2022-01-11 22:07:48:INFO:	fc_1.0.bias
2022-01-11 22:07:48:INFO:	fc_2.weight
2022-01-11 22:07:48:INFO:	fc_2.bias
/data/moy20/Meta-Learning/Meta-prognosis-main/optimizer.py:78: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448255797/work/torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
/data/moy20/miniconda3/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
2022-01-11 22:07:52:INFO:Epoch: 0	 global_step: 0/3750	 lr: 0.00100	 loss: 0.0017
2022-01-11 22:09:22:INFO:Epoch: 0	 global_step: 50/3750	 lr: 0.00099	 loss: 0.0202
2022-01-11 22:10:53:INFO:Epoch: 0	 global_step: 100/3750	 lr: 0.00097	 loss: 0.0073
2022-01-11 22:12:23:INFO:Epoch: 0	 global_step: 150/3750	 lr: 0.00096	 loss: 0.0064
2022-01-11 22:13:54:INFO:Epoch: 0	 global_step: 200/3750	 lr: 0.00095	 loss: 0.0041
2022-01-11 22:15:25:INFO:Epoch: 0	 global_step: 250/3750	 lr: 0.00093	 loss: 0.0044
2022-01-11 22:16:55:INFO:Epoch: 0	 global_step: 300/3750	 lr: 0.00092	 loss: 0.0035
2022-01-11 22:18:26:INFO:Epoch: 0	 global_step: 350/3750	 lr: 0.00091	 loss: 0.0029
2022-01-11 22:19:57:INFO:Epoch: 0	 global_step: 400/3750	 lr: 0.00089	 loss: 0.0032
2022-01-11 22:21:27:INFO:Epoch: 0	 global_step: 450/3750	 lr: 0.00088	 loss: 0.0021
2022-01-11 22:22:57:INFO:Epoch: 0	 global_step: 500/3750	 lr: 0.00087	 loss: 0.0026
2022-01-11 22:24:28:INFO:Epoch: 0	 global_step: 550/3750	 lr: 0.00085	 loss: 0.0020
2022-01-11 22:25:58:INFO:Epoch: 0	 global_step: 600/3750	 lr: 0.00084	 loss: 0.0014
2022-01-11 22:27:28:INFO:Epoch: 0	 global_step: 650/3750	 lr: 0.00083	 loss: 0.0019
2022-01-11 22:28:58:INFO:Epoch: 0	 global_step: 700/3750	 lr: 0.00081	 loss: 0.0014
2022-01-11 22:30:35:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-11 22:30:35:INFO:	Num examples = 100
2022-01-11 22:30:35:INFO:	RMSE = 21.9415
2022-01-11 22:30:43:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-11 22:30:44:INFO:	Num examples = 100
2022-01-11 22:30:44:INFO:	RMSE = 25.1696
2022-01-11 22:30:44:INFO:==> Minimal valid RMSE!
2022-01-11 22:30:44:INFO:Save model to cnn2dmodels/data-1_n_epochs-5_aug-150_noise-0.01_supportSize-5_innerSteps-2_lrMeta-0.001_lrInner-0.001_warmUp-0.0_seed-42...
2022-01-11 22:30:45:INFO:Epoch: 1	 global_step: 750/3750	 lr: 0.00080	 loss: 0.0014
2022-01-11 22:32:16:INFO:Epoch: 1	 global_step: 800/3750	 lr: 0.00079	 loss: 0.0016
2022-01-11 22:33:46:INFO:Epoch: 1	 global_step: 850/3750	 lr: 0.00077	 loss: 0.0012
2022-01-11 22:35:16:INFO:Epoch: 1	 global_step: 900/3750	 lr: 0.00076	 loss: 0.0011
2022-01-11 22:36:46:INFO:Epoch: 1	 global_step: 950/3750	 lr: 0.00075	 loss: 0.0012
2022-01-11 22:38:17:INFO:Epoch: 1	 global_step: 1000/3750	 lr: 0.00073	 loss: 0.0009
2022-01-11 22:39:47:INFO:Epoch: 1	 global_step: 1050/3750	 lr: 0.00072	 loss: 0.0009
2022-01-11 22:41:18:INFO:Epoch: 1	 global_step: 1100/3750	 lr: 0.00071	 loss: 0.0010
2022-01-11 22:42:48:INFO:Epoch: 1	 global_step: 1150/3750	 lr: 0.00069	 loss: 0.0010
2022-01-11 22:44:19:INFO:Epoch: 1	 global_step: 1200/3750	 lr: 0.00068	 loss: 0.0009
2022-01-11 22:45:49:INFO:Epoch: 1	 global_step: 1250/3750	 lr: 0.00067	 loss: 0.0008
2022-01-11 22:47:19:INFO:Epoch: 1	 global_step: 1300/3750	 lr: 0.00065	 loss: 0.0009
2022-01-11 22:48:50:INFO:Epoch: 1	 global_step: 1350/3750	 lr: 0.00064	 loss: 0.0009
2022-01-11 22:50:20:INFO:Epoch: 1	 global_step: 1400/3750	 lr: 0.00063	 loss: 0.0008
2022-01-11 22:51:50:INFO:Epoch: 1	 global_step: 1450/3750	 lr: 0.00061	 loss: 0.0007
2022-01-11 22:53:28:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-11 22:53:28:INFO:	Num examples = 100
2022-01-11 22:53:28:INFO:	RMSE = 17.3069
2022-01-11 22:53:37:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-11 22:53:37:INFO:	Num examples = 100
2022-01-11 22:53:37:INFO:	RMSE = 23.5998
2022-01-11 22:53:37:INFO:==> Minimal valid RMSE!
2022-01-11 22:53:37:INFO:Save model to cnn2dmodels/data-1_n_epochs-5_aug-150_noise-0.01_supportSize-5_innerSteps-2_lrMeta-0.001_lrInner-0.001_warmUp-0.0_seed-42...
2022-01-11 22:53:39:INFO:Epoch: 2	 global_step: 1500/3750	 lr: 0.00060	 loss: 0.0010
2022-01-11 22:55:09:INFO:Epoch: 2	 global_step: 1550/3750	 lr: 0.00059	 loss: 0.0008
2022-01-11 22:56:39:INFO:Epoch: 2	 global_step: 1600/3750	 lr: 0.00057	 loss: 0.0006
2022-01-11 22:58:10:INFO:Epoch: 2	 global_step: 1650/3750	 lr: 0.00056	 loss: 0.0008
2022-01-11 22:59:40:INFO:Epoch: 2	 global_step: 1700/3750	 lr: 0.00055	 loss: 0.0007
2022-01-11 23:01:10:INFO:Epoch: 2	 global_step: 1750/3750	 lr: 0.00053	 loss: 0.0006
2022-01-11 23:02:40:INFO:Epoch: 2	 global_step: 1800/3750	 lr: 0.00052	 loss: 0.0006
2022-01-11 23:04:10:INFO:Epoch: 2	 global_step: 1850/3750	 lr: 0.00051	 loss: 0.0006
2022-01-11 23:05:40:INFO:Epoch: 2	 global_step: 1900/3750	 lr: 0.00049	 loss: 0.0006
2022-01-11 23:07:10:INFO:Epoch: 2	 global_step: 1950/3750	 lr: 0.00048	 loss: 0.0006
2022-01-11 23:08:41:INFO:Epoch: 2	 global_step: 2000/3750	 lr: 0.00047	 loss: 0.0006
2022-01-11 23:10:11:INFO:Epoch: 2	 global_step: 2050/3750	 lr: 0.00045	 loss: 0.0006
2022-01-11 23:11:41:INFO:Epoch: 2	 global_step: 2100/3750	 lr: 0.00044	 loss: 0.0005
2022-01-11 23:13:11:INFO:Epoch: 2	 global_step: 2150/3750	 lr: 0.00043	 loss: 0.0005
2022-01-11 23:14:41:INFO:Epoch: 2	 global_step: 2200/3750	 lr: 0.00041	 loss: 0.0005
2022-01-11 23:16:18:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-11 23:16:18:INFO:	Num examples = 100
2022-01-11 23:16:18:INFO:	RMSE = 15.1000
2022-01-11 23:16:27:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-11 23:16:27:INFO:	Num examples = 100
2022-01-11 23:16:27:INFO:	RMSE = 23.9737
2022-01-11 23:16:28:INFO:Epoch: 3	 global_step: 2250/3750	 lr: 0.00040	 loss: 0.0005
2022-01-11 23:17:59:INFO:Epoch: 3	 global_step: 2300/3750	 lr: 0.00039	 loss: 0.0005
2022-01-11 23:19:29:INFO:Epoch: 3	 global_step: 2350/3750	 lr: 0.00037	 loss: 0.0004
2022-01-11 23:20:58:INFO:Epoch: 3	 global_step: 2400/3750	 lr: 0.00036	 loss: 0.0004
2022-01-11 23:22:29:INFO:Epoch: 3	 global_step: 2450/3750	 lr: 0.00035	 loss: 0.0005
2022-01-11 23:23:59:INFO:Epoch: 3	 global_step: 2500/3750	 lr: 0.00033	 loss: 0.0005
2022-01-11 23:25:29:INFO:Epoch: 3	 global_step: 2550/3750	 lr: 0.00032	 loss: 0.0004
2022-01-11 23:26:59:INFO:Epoch: 3	 global_step: 2600/3750	 lr: 0.00031	 loss: 0.0005
2022-01-11 23:28:29:INFO:Epoch: 3	 global_step: 2650/3750	 lr: 0.00029	 loss: 0.0004
2022-01-11 23:29:59:INFO:Epoch: 3	 global_step: 2700/3750	 lr: 0.00028	 loss: 0.0005
2022-01-11 23:31:29:INFO:Epoch: 3	 global_step: 2750/3750	 lr: 0.00027	 loss: 0.0004
2022-01-11 23:33:00:INFO:Epoch: 3	 global_step: 2800/3750	 lr: 0.00025	 loss: 0.0004
2022-01-11 23:34:30:INFO:Epoch: 3	 global_step: 2850/3750	 lr: 0.00024	 loss: 0.0005
2022-01-11 23:36:01:INFO:Epoch: 3	 global_step: 2900/3750	 lr: 0.00023	 loss: 0.0004
2022-01-11 23:37:32:INFO:Epoch: 3	 global_step: 2950/3750	 lr: 0.00021	 loss: 0.0004
2022-01-11 23:39:09:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-11 23:39:09:INFO:	Num examples = 100
2022-01-11 23:39:09:INFO:	RMSE = 14.1533
2022-01-11 23:39:18:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-11 23:39:18:INFO:	Num examples = 100
2022-01-11 23:39:18:INFO:	RMSE = 24.2035
2022-01-11 23:39:20:INFO:Epoch: 4	 global_step: 3000/3750	 lr: 0.00020	 loss: 0.0004
2022-01-11 23:40:50:INFO:Epoch: 4	 global_step: 3050/3750	 lr: 0.00019	 loss: 0.0004
2022-01-11 23:42:21:INFO:Epoch: 4	 global_step: 3100/3750	 lr: 0.00017	 loss: 0.0004
2022-01-11 23:43:51:INFO:Epoch: 4	 global_step: 3150/3750	 lr: 0.00016	 loss: 0.0004
2022-01-11 23:45:21:INFO:Epoch: 4	 global_step: 3200/3750	 lr: 0.00015	 loss: 0.0004
2022-01-11 23:46:52:INFO:Epoch: 4	 global_step: 3250/3750	 lr: 0.00013	 loss: 0.0004
2022-01-11 23:48:22:INFO:Epoch: 4	 global_step: 3300/3750	 lr: 0.00012	 loss: 0.0004
2022-01-11 23:49:53:INFO:Epoch: 4	 global_step: 3350/3750	 lr: 0.00011	 loss: 0.0004
2022-01-11 23:51:23:INFO:Epoch: 4	 global_step: 3400/3750	 lr: 0.00009	 loss: 0.0004
2022-01-11 23:52:53:INFO:Epoch: 4	 global_step: 3450/3750	 lr: 0.00008	 loss: 0.0004
2022-01-11 23:54:24:INFO:Epoch: 4	 global_step: 3500/3750	 lr: 0.00007	 loss: 0.0003
2022-01-11 23:55:54:INFO:Epoch: 4	 global_step: 3550/3750	 lr: 0.00005	 loss: 0.0004
2022-01-11 23:57:24:INFO:Epoch: 4	 global_step: 3600/3750	 lr: 0.00004	 loss: 0.0004
2022-01-11 23:58:55:INFO:Epoch: 4	 global_step: 3650/3750	 lr: 0.00003	 loss: 0.0003
2022-01-12 00:00:25:INFO:Epoch: 4	 global_step: 3700/3750	 lr: 0.00001	 loss: 0.0004
2022-01-12 00:02:02:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-12 00:02:02:INFO:	Num examples = 100
2022-01-12 00:02:02:INFO:	RMSE = 12.9613
2022-01-12 00:02:11:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-12 00:02:11:INFO:	Num examples = 100
2022-01-12 00:02:11:INFO:	RMSE = 26.8088
2022-01-12 00:02:11:INFO:	Output TEST RMSE:	17.3069
2022-01-12 00:02:11:INFO:	VALID RMSEs:	25.1696	23.5998	23.9737	24.2035	26.8088
2022-01-12 00:02:11:INFO:	TEST RMSEs:	21.9415	17.3069	15.1000	14.1533	12.9613
!!! Reset batch info !!! mode: [TRAIN]
!!! Reset batch info !!! mode: [TEST]
!!! Reset batch info !!! mode: [VALID]
!!! Reset batch info !!! mode: [TRAIN]
!!! Reset batch info !!! mode: [TEST]
!!! Reset batch info !!! mode: [VALID]
!!! Reset batch info !!! mode: [TRAIN]
!!! Reset batch info !!! mode: [TEST]
!!! Reset batch info !!! mode: [VALID]
!!! Reset batch info !!! mode: [TRAIN]
!!! Reset batch info !!! mode: [TEST]
!!! Reset batch info !!! mode: [VALID]
2022-01-12 00:02:15:INFO:Finish setting logger...
2022-01-12 00:02:15:INFO:==> Training/Evaluation parameters are:
2022-01-12 00:02:15:INFO:	Namespace(model_dir='cnn2dmodels/data-1_n_epochs-5_aug-150_noise-0.01_supportSize-2_innerSteps-2_lrMeta-0.001_lrInner-0.0001_warmUp-0.0_seed-667'
2022-01-12 00:02:15:INFO:	data_fn=1
2022-01-12 00:02:15:INFO:	datatest_fn=1
2022-01-12 00:02:15:INFO:	filter_kernel_size=1
2022-01-12 00:02:15:INFO:	override_data_cache=False
2022-01-12 00:02:15:INFO:	maxRUL=125
2022-01-12 00:02:15:INFO:	low_ratio=0.1
2022-01-12 00:02:15:INFO:	high_ratio=0.99
2022-01-12 00:02:15:INFO:	aug_ratio=150
2022-01-12 00:02:15:INFO:	noise_amplitude=0.01
2022-01-12 00:02:15:INFO:	modeltype='cnn2d'
2022-01-12 00:02:15:INFO:	max_seq_len=550
2022-01-12 00:02:15:INFO:	d_model=128
2022-01-12 00:02:15:INFO:	p_dropout=0.1
2022-01-12 00:02:15:INFO:	n_head=4
2022-01-12 00:02:15:INFO:	n_layer=2
2022-01-12 00:02:15:INFO:	dim_feedforward=512
2022-01-12 00:02:15:INFO:	e_dropout=0.1
2022-01-12 00:02:15:INFO:	activation='relu'
2022-01-12 00:02:15:INFO:	layer_norm=False
2022-01-12 00:02:15:INFO:	support_size=2
2022-01-12 00:02:15:INFO:	inner_steps=2
2022-01-12 00:02:15:INFO:	lr_inner=0.0001
2022-01-12 00:02:15:INFO:	lr_meta=0.001
2022-01-12 00:02:15:INFO:	n_epochs=5
2022-01-12 00:02:15:INFO:	train_batch_size=20
2022-01-12 00:02:15:INFO:	eval_batch_size=1
2022-01-12 00:02:15:INFO:	lr=0.001
2022-01-12 00:02:15:INFO:	weight_decay=0.01
2022-01-12 00:02:15:INFO:	warmup_ratio=0.0
2022-01-12 00:02:15:INFO:	max_grad_norm=5.0
2022-01-12 00:02:15:INFO:	logging_steps=50
2022-01-12 00:02:15:INFO:	seed=667
2022-01-12 00:02:15:INFO:	gpu_id=2
2022-01-12 00:02:15:INFO:	do_train=True
2022-01-12 00:02:15:INFO:	do_eval=False
2022-01-12 00:02:15:INFO:	train_data_fn='data/train_FD001.txt'
2022-01-12 00:02:15:INFO:	test_data_fn='data/test_FD001.txt'
2022-01-12 00:02:15:INFO:	target_ruls_fn='data/RUL_FD001.txt'
2022-01-12 00:02:15:INFO:	device=device(type='cuda'))
2022-01-12 00:02:15:INFO:Dump arguments to cnn2dmodels/data-1_n_epochs-5_aug-150_noise-0.01_supportSize-2_innerSteps-2_lrMeta-0.001_lrInner-0.0001_warmUp-0.0_seed-667...
2022-01-12 00:02:15:INFO:==> Read data from data/train_FD001.txt...
2022-01-12 00:02:15:INFO:	The selected feature idxs are: 0, 1, 4, 5, 6, 9, 10, 11, 13, 14, 15, 16, 17, 19, 22, 23
2022-01-12 00:02:16:INFO:==> Min_max normalization...
2022-01-12 00:02:16:INFO:	The min value is [-0.008700000122189522, -0.0006000000284984708, 641.2100219726562, 1571.0400390625, 1382.25, 549.8499755859375, 2387.89990234375, 9021.73046875, 46.849998474121094, 518.6900024414062, 2387.8798828125, 8099.93994140625, 8.324899673461914, 388.0, 38.13999938964844, 22.89419937133789]
2022-01-12 00:02:16:INFO:	The max value is [0.008700000122189522, 0.0006000000284984708, 644.530029296875, 1616.9100341796875, 1441.489990234375, 556.0599975585938, 2388.56005859375, 9244.58984375, 48.529998779296875, 523.3800048828125, 2388.56005859375, 8293.7197265625, 8.584799766540527, 400.0, 39.43000030517578, 23.61840057373047]
2022-01-12 00:02:16:INFO:==> Read data from data/test_FD001.txt...
2022-01-12 00:02:16:INFO:	The selected feature idxs are: 0, 1, 4, 5, 6, 9, 10, 11, 13, 14, 15, 16, 17, 19, 22, 23
2022-01-12 00:02:16:INFO:==> Read RULsfrom data/RUL_FD001.txt...
2022-01-12 00:02:16:INFO:	min_rul: 7, max_rul: 145
2022-01-12 00:02:16:INFO:==> Input length ratio of the [TEST] data:
2022-01-12 00:02:16:INFO:	min_ratio = 0.2067
2022-01-12 00:02:16:INFO:	max_ratio = 0.9667
2022-01-12 00:02:16:INFO:==> Min_max normalization...
2022-01-12 00:02:16:INFO:	With given min value [-0.008700000122189522, -0.0006000000284984708, 641.2100219726562, 1571.0400390625, 1382.25, 549.8499755859375, 2387.89990234375, 9021.73046875, 46.849998474121094, 518.6900024414062, 2387.8798828125, 8099.93994140625, 8.324899673461914, 388.0, 38.13999938964844, 22.89419937133789]
2022-01-12 00:02:16:INFO:	With given max value [0.008700000122189522, 0.0006000000284984708, 644.530029296875, 1616.9100341796875, 1441.489990234375, 556.0599975585938, 2388.56005859375, 9244.58984375, 48.529998779296875, 523.3800048828125, 2388.56005859375, 8293.7197265625, 8.584799766540527, 400.0, 39.43000030517578, 23.61840057373047]
2022-01-12 00:02:16:INFO:==> Computing Criterion...
2022-01-12 00:02:16:INFO:	The weights are: 0.007887763902544975, 0.008001004345715046, 0.06667434424161911, 0.0634712353348732, 0.07656104862689972, 0.0755249634385109, 0.06726357340812683, 0.0644979178905487, 0.0795108750462532, 0.07743842899799347, 0.0671684592962265, 0.06869389116764069, 0.07147877663373947, 0.06516212970018387, 0.07012488692998886, 0.07054071873426437
2022-01-12 00:02:23:INFO:Note: NumExpr detected 40 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2022-01-12 00:02:23:INFO:NumExpr defaulting to 8 threads.
2022-01-12 00:02:24:INFO:=============== Scheme: Meta Learning ===============
2022-01-12 00:02:24:INFO:	Num examples = 15000
2022-01-12 00:02:24:INFO:	Num epochs = 5
2022-01-12 00:02:24:INFO:	Batch size = 20
2022-01-12 00:02:24:INFO:	Total meta optimization steps = 3750
2022-01-12 00:02:24:INFO:	Total inner optimization steps = 7500
2022-01-12 00:02:31:INFO:==> Group parameters for optimization...
2022-01-12 00:02:31:INFO:    Parameters to update are:
2022-01-12 00:02:31:INFO:	conv1.0.weight
2022-01-12 00:02:31:INFO:	conv2.0.weight
2022-01-12 00:02:31:INFO:	conv3.0.weight
2022-01-12 00:02:31:INFO:	conv4.0.weight
2022-01-12 00:02:31:INFO:	conv5.0.weight
2022-01-12 00:02:31:INFO:	fc_1.0.weight
2022-01-12 00:02:31:INFO:	fc_1.0.bias
2022-01-12 00:02:31:INFO:	fc_2.weight
2022-01-12 00:02:31:INFO:	fc_2.bias
/data/moy20/Meta-Learning/Meta-prognosis-main/optimizer.py:78: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448255797/work/torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
/data/moy20/miniconda3/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
2022-01-12 00:02:34:INFO:Epoch: 0	 global_step: 0/3750	 lr: 0.00100	 loss: 0.0011
2022-01-12 00:03:48:INFO:Epoch: 0	 global_step: 50/3750	 lr: 0.00099	 loss: 0.0187
2022-01-12 00:05:02:INFO:Epoch: 0	 global_step: 100/3750	 lr: 0.00097	 loss: 0.0091
2022-01-12 00:06:16:INFO:Epoch: 0	 global_step: 150/3750	 lr: 0.00096	 loss: 0.0065
2022-01-12 00:07:30:INFO:Epoch: 0	 global_step: 200/3750	 lr: 0.00095	 loss: 0.0049
2022-01-12 00:08:44:INFO:Epoch: 0	 global_step: 250/3750	 lr: 0.00093	 loss: 0.0056
2022-01-12 00:09:58:INFO:Epoch: 0	 global_step: 300/3750	 lr: 0.00092	 loss: 0.0035
2022-01-12 00:11:12:INFO:Epoch: 0	 global_step: 350/3750	 lr: 0.00091	 loss: 0.0036
2022-01-12 00:12:25:INFO:Epoch: 0	 global_step: 400/3750	 lr: 0.00089	 loss: 0.0029
2022-01-12 00:13:40:INFO:Epoch: 0	 global_step: 450/3750	 lr: 0.00088	 loss: 0.0031
2022-01-12 00:14:54:INFO:Epoch: 0	 global_step: 500/3750	 lr: 0.00087	 loss: 0.0025
2022-01-12 00:16:08:INFO:Epoch: 0	 global_step: 550/3750	 lr: 0.00085	 loss: 0.0025
2022-01-12 00:17:22:INFO:Epoch: 0	 global_step: 600/3750	 lr: 0.00084	 loss: 0.0020
2022-01-12 00:18:37:INFO:Epoch: 0	 global_step: 650/3750	 lr: 0.00083	 loss: 0.0018
2022-01-12 00:19:51:INFO:Epoch: 0	 global_step: 700/3750	 lr: 0.00081	 loss: 0.0019
2022-01-12 00:21:10:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-12 00:21:10:INFO:	Num examples = 100
2022-01-12 00:21:10:INFO:	RMSE = 20.3023
2022-01-12 00:21:18:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-12 00:21:18:INFO:	Num examples = 100
2022-01-12 00:21:18:INFO:	RMSE = 29.6559
2022-01-12 00:21:18:INFO:==> Minimal valid RMSE!
2022-01-12 00:21:18:INFO:Save model to cnn2dmodels/data-1_n_epochs-5_aug-150_noise-0.01_supportSize-2_innerSteps-2_lrMeta-0.001_lrInner-0.0001_warmUp-0.0_seed-667...
2022-01-12 00:21:19:INFO:Epoch: 1	 global_step: 750/3750	 lr: 0.00080	 loss: 0.0018
2022-01-12 00:22:33:INFO:Epoch: 1	 global_step: 800/3750	 lr: 0.00079	 loss: 0.0014
2022-01-12 00:23:47:INFO:Epoch: 1	 global_step: 850/3750	 lr: 0.00077	 loss: 0.0016
2022-01-12 00:25:01:INFO:Epoch: 1	 global_step: 900/3750	 lr: 0.00076	 loss: 0.0023
2022-01-12 00:26:16:INFO:Epoch: 1	 global_step: 950/3750	 lr: 0.00075	 loss: 0.0013
2022-01-12 00:27:30:INFO:Epoch: 1	 global_step: 1000/3750	 lr: 0.00073	 loss: 0.0016
2022-01-12 00:28:44:INFO:Epoch: 1	 global_step: 1050/3750	 lr: 0.00072	 loss: 0.0012
2022-01-12 00:29:58:INFO:Epoch: 1	 global_step: 1100/3750	 lr: 0.00071	 loss: 0.0012
2022-01-12 00:31:12:INFO:Epoch: 1	 global_step: 1150/3750	 lr: 0.00069	 loss: 0.0013
2022-01-12 00:32:27:INFO:Epoch: 1	 global_step: 1200/3750	 lr: 0.00068	 loss: 0.0011
2022-01-12 00:33:41:INFO:Epoch: 1	 global_step: 1250/3750	 lr: 0.00067	 loss: 0.0010
2022-01-12 00:34:56:INFO:Epoch: 1	 global_step: 1300/3750	 lr: 0.00065	 loss: 0.0010
2022-01-12 00:36:09:INFO:Epoch: 1	 global_step: 1350/3750	 lr: 0.00064	 loss: 0.0010
2022-01-12 00:37:23:INFO:Epoch: 1	 global_step: 1400/3750	 lr: 0.00063	 loss: 0.0010
2022-01-12 00:38:37:INFO:Epoch: 1	 global_step: 1450/3750	 lr: 0.00061	 loss: 0.0011
2022-01-12 00:39:57:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-12 00:39:57:INFO:	Num examples = 100
2022-01-12 00:39:57:INFO:	RMSE = 20.2022
2022-01-12 00:40:04:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-12 00:40:04:INFO:	Num examples = 100
2022-01-12 00:40:04:INFO:	RMSE = 26.4091
2022-01-12 00:40:04:INFO:==> Minimal valid RMSE!
2022-01-12 00:40:04:INFO:Save model to cnn2dmodels/data-1_n_epochs-5_aug-150_noise-0.01_supportSize-2_innerSteps-2_lrMeta-0.001_lrInner-0.0001_warmUp-0.0_seed-667...
2022-01-12 00:40:06:INFO:Epoch: 2	 global_step: 1500/3750	 lr: 0.00060	 loss: 0.0010
2022-01-12 00:41:19:INFO:Epoch: 2	 global_step: 1550/3750	 lr: 0.00059	 loss: 0.0010
2022-01-12 00:42:33:INFO:Epoch: 2	 global_step: 1600/3750	 lr: 0.00057	 loss: 0.0010
2022-01-12 00:43:47:INFO:Epoch: 2	 global_step: 1650/3750	 lr: 0.00056	 loss: 0.0009
2022-01-12 00:45:01:INFO:Epoch: 2	 global_step: 1700/3750	 lr: 0.00055	 loss: 0.0009
2022-01-12 00:46:15:INFO:Epoch: 2	 global_step: 1750/3750	 lr: 0.00053	 loss: 0.0007
2022-01-12 00:47:29:INFO:Epoch: 2	 global_step: 1800/3750	 lr: 0.00052	 loss: 0.0011
2022-01-12 00:48:43:INFO:Epoch: 2	 global_step: 1850/3750	 lr: 0.00051	 loss: 0.0007
2022-01-12 00:49:56:INFO:Epoch: 2	 global_step: 1900/3750	 lr: 0.00049	 loss: 0.0008
2022-01-12 00:51:10:INFO:Epoch: 2	 global_step: 1950/3750	 lr: 0.00048	 loss: 0.0007
2022-01-12 00:52:23:INFO:Epoch: 2	 global_step: 2000/3750	 lr: 0.00047	 loss: 0.0007
2022-01-12 00:53:37:INFO:Epoch: 2	 global_step: 2050/3750	 lr: 0.00045	 loss: 0.0007
2022-01-12 00:54:50:INFO:Epoch: 2	 global_step: 2100/3750	 lr: 0.00044	 loss: 0.0006
2022-01-12 00:56:04:INFO:Epoch: 2	 global_step: 2150/3750	 lr: 0.00043	 loss: 0.0006
2022-01-12 00:57:17:INFO:Epoch: 2	 global_step: 2200/3750	 lr: 0.00041	 loss: 0.0007
2022-01-12 00:58:37:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-12 00:58:37:INFO:	Num examples = 100
2022-01-12 00:58:37:INFO:	RMSE = 17.0139
2022-01-12 00:58:44:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-12 00:58:44:INFO:	Num examples = 100
2022-01-12 00:58:44:INFO:	RMSE = 23.3381
2022-01-12 00:58:44:INFO:==> Minimal valid RMSE!
2022-01-12 00:58:44:INFO:Save model to cnn2dmodels/data-1_n_epochs-5_aug-150_noise-0.01_supportSize-2_innerSteps-2_lrMeta-0.001_lrInner-0.0001_warmUp-0.0_seed-667...
2022-01-12 00:58:45:INFO:Epoch: 3	 global_step: 2250/3750	 lr: 0.00040	 loss: 0.0007
2022-01-12 00:59:59:INFO:Epoch: 3	 global_step: 2300/3750	 lr: 0.00039	 loss: 0.0007
2022-01-12 01:01:14:INFO:Epoch: 3	 global_step: 2350/3750	 lr: 0.00037	 loss: 0.0007
2022-01-12 01:02:28:INFO:Epoch: 3	 global_step: 2400/3750	 lr: 0.00036	 loss: 0.0005
2022-01-12 01:03:41:INFO:Epoch: 3	 global_step: 2450/3750	 lr: 0.00035	 loss: 0.0006
2022-01-12 01:04:55:INFO:Epoch: 3	 global_step: 2500/3750	 lr: 0.00033	 loss: 0.0006
2022-01-12 01:06:09:INFO:Epoch: 3	 global_step: 2550/3750	 lr: 0.00032	 loss: 0.0006
2022-01-12 01:07:23:INFO:Epoch: 3	 global_step: 2600/3750	 lr: 0.00031	 loss: 0.0005
2022-01-12 01:08:36:INFO:Epoch: 3	 global_step: 2650/3750	 lr: 0.00029	 loss: 0.0006
2022-01-12 01:09:50:INFO:Epoch: 3	 global_step: 2700/3750	 lr: 0.00028	 loss: 0.0006
2022-01-12 01:11:05:INFO:Epoch: 3	 global_step: 2750/3750	 lr: 0.00027	 loss: 0.0005
2022-01-12 01:12:18:INFO:Epoch: 3	 global_step: 2800/3750	 lr: 0.00025	 loss: 0.0005
2022-01-12 01:13:32:INFO:Epoch: 3	 global_step: 2850/3750	 lr: 0.00024	 loss: 0.0005
2022-01-12 01:14:46:INFO:Epoch: 3	 global_step: 2900/3750	 lr: 0.00023	 loss: 0.0005
2022-01-12 01:16:00:INFO:Epoch: 3	 global_step: 2950/3750	 lr: 0.00021	 loss: 0.0005
2022-01-12 01:17:19:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-12 01:17:19:INFO:	Num examples = 100
2022-01-12 01:17:19:INFO:	RMSE = 14.0719
2022-01-12 01:17:26:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-12 01:17:26:INFO:	Num examples = 100
2022-01-12 01:17:26:INFO:	RMSE = 24.5262
2022-01-12 01:17:27:INFO:Epoch: 4	 global_step: 3000/3750	 lr: 0.00020	 loss: 0.0005
2022-01-12 01:18:42:INFO:Epoch: 4	 global_step: 3050/3750	 lr: 0.00019	 loss: 0.0005
2022-01-12 01:19:56:INFO:Epoch: 4	 global_step: 3100/3750	 lr: 0.00017	 loss: 0.0005
2022-01-12 01:21:09:INFO:Epoch: 4	 global_step: 3150/3750	 lr: 0.00016	 loss: 0.0004
2022-01-12 01:22:23:INFO:Epoch: 4	 global_step: 3200/3750	 lr: 0.00015	 loss: 0.0004
2022-01-12 01:23:37:INFO:Epoch: 4	 global_step: 3250/3750	 lr: 0.00013	 loss: 0.0004
2022-01-12 01:24:51:INFO:Epoch: 4	 global_step: 3300/3750	 lr: 0.00012	 loss: 0.0004
2022-01-12 01:26:04:INFO:Epoch: 4	 global_step: 3350/3750	 lr: 0.00011	 loss: 0.0004
2022-01-12 01:27:18:INFO:Epoch: 4	 global_step: 3400/3750	 lr: 0.00009	 loss: 0.0004
2022-01-12 01:28:31:INFO:Epoch: 4	 global_step: 3450/3750	 lr: 0.00008	 loss: 0.0005
2022-01-12 01:29:45:INFO:Epoch: 4	 global_step: 3500/3750	 lr: 0.00007	 loss: 0.0005
2022-01-12 01:30:59:INFO:Epoch: 4	 global_step: 3550/3750	 lr: 0.00005	 loss: 0.0005
2022-01-12 01:32:12:INFO:Epoch: 4	 global_step: 3600/3750	 lr: 0.00004	 loss: 0.0005
2022-01-12 01:33:25:INFO:Epoch: 4	 global_step: 3650/3750	 lr: 0.00003	 loss: 0.0005
2022-01-12 01:34:38:INFO:Epoch: 4	 global_step: 3700/3750	 lr: 0.00001	 loss: 0.0005
2022-01-12 01:35:57:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-12 01:35:57:INFO:	Num examples = 100
2022-01-12 01:35:57:INFO:	RMSE = 12.6604
2022-01-12 01:36:04:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-12 01:36:04:INFO:	Num examples = 100
2022-01-12 01:36:04:INFO:	RMSE = 27.9775
2022-01-12 01:36:04:INFO:	Output TEST RMSE:	17.0139
2022-01-12 01:36:04:INFO:	VALID RMSEs:	29.6559	26.4091	23.3381	24.5262	27.9775
2022-01-12 01:36:04:INFO:	TEST RMSEs:	20.3023	20.2022	17.0139	14.0719	12.6604
!!! Reset batch info !!! mode: [TRAIN]
!!! Reset batch info !!! mode: [TEST]
!!! Reset batch info !!! mode: [VALID]
!!! Reset batch info !!! mode: [TRAIN]
!!! Reset batch info !!! mode: [TEST]
!!! Reset batch info !!! mode: [VALID]
!!! Reset batch info !!! mode: [TRAIN]
!!! Reset batch info !!! mode: [TEST]
!!! Reset batch info !!! mode: [VALID]
!!! Reset batch info !!! mode: [TRAIN]
!!! Reset batch info !!! mode: [TEST]
!!! Reset batch info !!! mode: [VALID]
2022-01-12 01:36:08:INFO:Finish setting logger...
2022-01-12 01:36:08:INFO:==> Training/Evaluation parameters are:
2022-01-12 01:36:08:INFO:	Namespace(model_dir='cnn2dmodels/data-1_n_epochs-5_aug-150_noise-0.01_supportSize-2_innerSteps-2_lrMeta-0.001_lrInner-0.001_warmUp-0.0_seed-667'
2022-01-12 01:36:08:INFO:	data_fn=1
2022-01-12 01:36:08:INFO:	datatest_fn=1
2022-01-12 01:36:08:INFO:	filter_kernel_size=1
2022-01-12 01:36:08:INFO:	override_data_cache=False
2022-01-12 01:36:08:INFO:	maxRUL=125
2022-01-12 01:36:08:INFO:	low_ratio=0.1
2022-01-12 01:36:08:INFO:	high_ratio=0.99
2022-01-12 01:36:08:INFO:	aug_ratio=150
2022-01-12 01:36:08:INFO:	noise_amplitude=0.01
2022-01-12 01:36:08:INFO:	modeltype='cnn2d'
2022-01-12 01:36:08:INFO:	max_seq_len=550
2022-01-12 01:36:08:INFO:	d_model=128
2022-01-12 01:36:08:INFO:	p_dropout=0.1
2022-01-12 01:36:08:INFO:	n_head=4
2022-01-12 01:36:08:INFO:	n_layer=2
2022-01-12 01:36:08:INFO:	dim_feedforward=512
2022-01-12 01:36:08:INFO:	e_dropout=0.1
2022-01-12 01:36:08:INFO:	activation='relu'
2022-01-12 01:36:08:INFO:	layer_norm=False
2022-01-12 01:36:08:INFO:	support_size=2
2022-01-12 01:36:08:INFO:	inner_steps=2
2022-01-12 01:36:08:INFO:	lr_inner=0.001
2022-01-12 01:36:08:INFO:	lr_meta=0.001
2022-01-12 01:36:08:INFO:	n_epochs=5
2022-01-12 01:36:08:INFO:	train_batch_size=20
2022-01-12 01:36:08:INFO:	eval_batch_size=1
2022-01-12 01:36:08:INFO:	lr=0.001
2022-01-12 01:36:08:INFO:	weight_decay=0.01
2022-01-12 01:36:08:INFO:	warmup_ratio=0.0
2022-01-12 01:36:08:INFO:	max_grad_norm=5.0
2022-01-12 01:36:08:INFO:	logging_steps=50
2022-01-12 01:36:08:INFO:	seed=667
2022-01-12 01:36:08:INFO:	gpu_id=2
2022-01-12 01:36:08:INFO:	do_train=True
2022-01-12 01:36:08:INFO:	do_eval=False
2022-01-12 01:36:08:INFO:	train_data_fn='data/train_FD001.txt'
2022-01-12 01:36:08:INFO:	test_data_fn='data/test_FD001.txt'
2022-01-12 01:36:08:INFO:	target_ruls_fn='data/RUL_FD001.txt'
2022-01-12 01:36:08:INFO:	device=device(type='cuda'))
2022-01-12 01:36:08:INFO:Dump arguments to cnn2dmodels/data-1_n_epochs-5_aug-150_noise-0.01_supportSize-2_innerSteps-2_lrMeta-0.001_lrInner-0.001_warmUp-0.0_seed-667...
2022-01-12 01:36:08:INFO:==> Read data from data/train_FD001.txt...
2022-01-12 01:36:08:INFO:	The selected feature idxs are: 0, 1, 4, 5, 6, 9, 10, 11, 13, 14, 15, 16, 17, 19, 22, 23
2022-01-12 01:36:08:INFO:==> Min_max normalization...
2022-01-12 01:36:08:INFO:	The min value is [-0.008700000122189522, -0.0006000000284984708, 641.2100219726562, 1571.0400390625, 1382.25, 549.8499755859375, 2387.89990234375, 9021.73046875, 46.849998474121094, 518.6900024414062, 2387.8798828125, 8099.93994140625, 8.324899673461914, 388.0, 38.13999938964844, 22.89419937133789]
2022-01-12 01:36:08:INFO:	The max value is [0.008700000122189522, 0.0006000000284984708, 644.530029296875, 1616.9100341796875, 1441.489990234375, 556.0599975585938, 2388.56005859375, 9244.58984375, 48.529998779296875, 523.3800048828125, 2388.56005859375, 8293.7197265625, 8.584799766540527, 400.0, 39.43000030517578, 23.61840057373047]
2022-01-12 01:36:08:INFO:==> Read data from data/test_FD001.txt...
2022-01-12 01:36:08:INFO:	The selected feature idxs are: 0, 1, 4, 5, 6, 9, 10, 11, 13, 14, 15, 16, 17, 19, 22, 23
2022-01-12 01:36:08:INFO:==> Read RULsfrom data/RUL_FD001.txt...
2022-01-12 01:36:08:INFO:	min_rul: 7, max_rul: 145
2022-01-12 01:36:08:INFO:==> Input length ratio of the [TEST] data:
2022-01-12 01:36:08:INFO:	min_ratio = 0.2067
2022-01-12 01:36:08:INFO:	max_ratio = 0.9667
2022-01-12 01:36:08:INFO:==> Min_max normalization...
2022-01-12 01:36:08:INFO:	With given min value [-0.008700000122189522, -0.0006000000284984708, 641.2100219726562, 1571.0400390625, 1382.25, 549.8499755859375, 2387.89990234375, 9021.73046875, 46.849998474121094, 518.6900024414062, 2387.8798828125, 8099.93994140625, 8.324899673461914, 388.0, 38.13999938964844, 22.89419937133789]
2022-01-12 01:36:08:INFO:	With given max value [0.008700000122189522, 0.0006000000284984708, 644.530029296875, 1616.9100341796875, 1441.489990234375, 556.0599975585938, 2388.56005859375, 9244.58984375, 48.529998779296875, 523.3800048828125, 2388.56005859375, 8293.7197265625, 8.584799766540527, 400.0, 39.43000030517578, 23.61840057373047]
2022-01-12 01:36:08:INFO:==> Computing Criterion...
2022-01-12 01:36:08:INFO:	The weights are: 0.007887763902544975, 0.008001004345715046, 0.06667434424161911, 0.0634712353348732, 0.07656104862689972, 0.0755249634385109, 0.06726357340812683, 0.0644979178905487, 0.0795108750462532, 0.07743842899799347, 0.0671684592962265, 0.06869389116764069, 0.07147877663373947, 0.06516212970018387, 0.07012488692998886, 0.07054071873426437
2022-01-12 01:36:16:INFO:Note: NumExpr detected 40 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2022-01-12 01:36:16:INFO:NumExpr defaulting to 8 threads.
2022-01-12 01:36:16:INFO:=============== Scheme: Meta Learning ===============
2022-01-12 01:36:16:INFO:	Num examples = 15000
2022-01-12 01:36:16:INFO:	Num epochs = 5
2022-01-12 01:36:16:INFO:	Batch size = 20
2022-01-12 01:36:16:INFO:	Total meta optimization steps = 3750
2022-01-12 01:36:16:INFO:	Total inner optimization steps = 7500
2022-01-12 01:36:23:INFO:==> Group parameters for optimization...
2022-01-12 01:36:23:INFO:    Parameters to update are:
2022-01-12 01:36:23:INFO:	conv1.0.weight
2022-01-12 01:36:23:INFO:	conv2.0.weight
2022-01-12 01:36:23:INFO:	conv3.0.weight
2022-01-12 01:36:23:INFO:	conv4.0.weight
2022-01-12 01:36:23:INFO:	conv5.0.weight
2022-01-12 01:36:23:INFO:	fc_1.0.weight
2022-01-12 01:36:23:INFO:	fc_1.0.bias
2022-01-12 01:36:23:INFO:	fc_2.weight
2022-01-12 01:36:23:INFO:	fc_2.bias
/data/moy20/Meta-Learning/Meta-prognosis-main/optimizer.py:78: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448255797/work/torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
/data/moy20/miniconda3/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
2022-01-12 01:36:26:INFO:Epoch: 0	 global_step: 0/3750	 lr: 0.00100	 loss: 0.0011
2022-01-12 01:37:39:INFO:Epoch: 0	 global_step: 50/3750	 lr: 0.00099	 loss: 0.0187
2022-01-12 01:38:52:INFO:Epoch: 0	 global_step: 100/3750	 lr: 0.00097	 loss: 0.0091
2022-01-12 01:40:06:INFO:Epoch: 0	 global_step: 150/3750	 lr: 0.00096	 loss: 0.0065
2022-01-12 01:41:08:INFO:Epoch: 0	 global_step: 200/3750	 lr: 0.00095	 loss: 0.0049
2022-01-12 01:41:58:INFO:Epoch: 0	 global_step: 250/3750	 lr: 0.00093	 loss: 0.0056
2022-01-12 01:42:48:INFO:Epoch: 0	 global_step: 300/3750	 lr: 0.00092	 loss: 0.0035
2022-01-12 01:43:37:INFO:Epoch: 0	 global_step: 350/3750	 lr: 0.00091	 loss: 0.0036
2022-01-12 01:44:27:INFO:Epoch: 0	 global_step: 400/3750	 lr: 0.00089	 loss: 0.0029
2022-01-12 01:45:16:INFO:Epoch: 0	 global_step: 450/3750	 lr: 0.00088	 loss: 0.0031
2022-01-12 01:46:06:INFO:Epoch: 0	 global_step: 500/3750	 lr: 0.00087	 loss: 0.0025
2022-01-12 01:46:55:INFO:Epoch: 0	 global_step: 550/3750	 lr: 0.00085	 loss: 0.0025
2022-01-12 01:47:44:INFO:Epoch: 0	 global_step: 600/3750	 lr: 0.00084	 loss: 0.0020
2022-01-12 01:48:34:INFO:Epoch: 0	 global_step: 650/3750	 lr: 0.00083	 loss: 0.0018
2022-01-12 01:49:23:INFO:Epoch: 0	 global_step: 700/3750	 lr: 0.00081	 loss: 0.0019
2022-01-12 01:50:16:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-12 01:50:16:INFO:	Num examples = 100
2022-01-12 01:50:16:INFO:	RMSE = 20.3023
2022-01-12 01:50:21:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-12 01:50:21:INFO:	Num examples = 100
2022-01-12 01:50:21:INFO:	RMSE = 29.6559
2022-01-12 01:50:21:INFO:==> Minimal valid RMSE!
2022-01-12 01:50:21:INFO:Save model to cnn2dmodels/data-1_n_epochs-5_aug-150_noise-0.01_supportSize-2_innerSteps-2_lrMeta-0.001_lrInner-0.001_warmUp-0.0_seed-667...
2022-01-12 01:50:22:INFO:Epoch: 1	 global_step: 750/3750	 lr: 0.00080	 loss: 0.0018
2022-01-12 01:51:11:INFO:Epoch: 1	 global_step: 800/3750	 lr: 0.00079	 loss: 0.0014
2022-01-12 01:52:01:INFO:Epoch: 1	 global_step: 850/3750	 lr: 0.00077	 loss: 0.0016
2022-01-12 01:52:50:INFO:Epoch: 1	 global_step: 900/3750	 lr: 0.00076	 loss: 0.0023
2022-01-12 01:53:40:INFO:Epoch: 1	 global_step: 950/3750	 lr: 0.00075	 loss: 0.0013
2022-01-12 01:54:29:INFO:Epoch: 1	 global_step: 1000/3750	 lr: 0.00073	 loss: 0.0016
2022-01-12 01:55:18:INFO:Epoch: 1	 global_step: 1050/3750	 lr: 0.00072	 loss: 0.0012
2022-01-12 01:56:07:INFO:Epoch: 1	 global_step: 1100/3750	 lr: 0.00071	 loss: 0.0012
2022-01-12 01:56:57:INFO:Epoch: 1	 global_step: 1150/3750	 lr: 0.00069	 loss: 0.0013
2022-01-12 01:57:46:INFO:Epoch: 1	 global_step: 1200/3750	 lr: 0.00068	 loss: 0.0011
2022-01-12 01:58:36:INFO:Epoch: 1	 global_step: 1250/3750	 lr: 0.00067	 loss: 0.0010
2022-01-12 01:59:24:INFO:Epoch: 1	 global_step: 1300/3750	 lr: 0.00065	 loss: 0.0010
2022-01-12 02:00:14:INFO:Epoch: 1	 global_step: 1350/3750	 lr: 0.00064	 loss: 0.0010
2022-01-12 02:01:04:INFO:Epoch: 1	 global_step: 1400/3750	 lr: 0.00063	 loss: 0.0010
2022-01-12 02:01:53:INFO:Epoch: 1	 global_step: 1450/3750	 lr: 0.00061	 loss: 0.0011
2022-01-12 02:02:46:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-12 02:02:46:INFO:	Num examples = 100
2022-01-12 02:02:46:INFO:	RMSE = 20.2022
2022-01-12 02:02:50:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-12 02:02:50:INFO:	Num examples = 100
2022-01-12 02:02:50:INFO:	RMSE = 26.4091
2022-01-12 02:02:50:INFO:==> Minimal valid RMSE!
2022-01-12 02:02:50:INFO:Save model to cnn2dmodels/data-1_n_epochs-5_aug-150_noise-0.01_supportSize-2_innerSteps-2_lrMeta-0.001_lrInner-0.001_warmUp-0.0_seed-667...
2022-01-12 02:02:52:INFO:Epoch: 2	 global_step: 1500/3750	 lr: 0.00060	 loss: 0.0010
2022-01-12 02:03:41:INFO:Epoch: 2	 global_step: 1550/3750	 lr: 0.00059	 loss: 0.0010
2022-01-12 02:04:30:INFO:Epoch: 2	 global_step: 1600/3750	 lr: 0.00057	 loss: 0.0010
2022-01-12 02:05:20:INFO:Epoch: 2	 global_step: 1650/3750	 lr: 0.00056	 loss: 0.0009
2022-01-12 02:06:09:INFO:Epoch: 2	 global_step: 1700/3750	 lr: 0.00055	 loss: 0.0009
2022-01-12 02:06:58:INFO:Epoch: 2	 global_step: 1750/3750	 lr: 0.00053	 loss: 0.0007
2022-01-12 02:07:48:INFO:Epoch: 2	 global_step: 1800/3750	 lr: 0.00052	 loss: 0.0011
2022-01-12 02:08:37:INFO:Epoch: 2	 global_step: 1850/3750	 lr: 0.00051	 loss: 0.0007
2022-01-12 02:09:27:INFO:Epoch: 2	 global_step: 1900/3750	 lr: 0.00049	 loss: 0.0008
2022-01-12 02:10:16:INFO:Epoch: 2	 global_step: 1950/3750	 lr: 0.00048	 loss: 0.0007
2022-01-12 02:11:06:INFO:Epoch: 2	 global_step: 2000/3750	 lr: 0.00047	 loss: 0.0007
2022-01-12 02:11:56:INFO:Epoch: 2	 global_step: 2050/3750	 lr: 0.00045	 loss: 0.0007
2022-01-12 02:12:45:INFO:Epoch: 2	 global_step: 2100/3750	 lr: 0.00044	 loss: 0.0006
2022-01-12 02:13:35:INFO:Epoch: 2	 global_step: 2150/3750	 lr: 0.00043	 loss: 0.0006
2022-01-12 02:14:24:INFO:Epoch: 2	 global_step: 2200/3750	 lr: 0.00041	 loss: 0.0007
2022-01-12 02:15:17:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-12 02:15:17:INFO:	Num examples = 100
2022-01-12 02:15:17:INFO:	RMSE = 17.0139
2022-01-12 02:15:22:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-12 02:15:22:INFO:	Num examples = 100
2022-01-12 02:15:22:INFO:	RMSE = 23.3381
2022-01-12 02:15:22:INFO:==> Minimal valid RMSE!
2022-01-12 02:15:22:INFO:Save model to cnn2dmodels/data-1_n_epochs-5_aug-150_noise-0.01_supportSize-2_innerSteps-2_lrMeta-0.001_lrInner-0.001_warmUp-0.0_seed-667...
2022-01-12 02:15:23:INFO:Epoch: 3	 global_step: 2250/3750	 lr: 0.00040	 loss: 0.0007
2022-01-12 02:16:12:INFO:Epoch: 3	 global_step: 2300/3750	 lr: 0.00039	 loss: 0.0007
2022-01-12 02:17:02:INFO:Epoch: 3	 global_step: 2350/3750	 lr: 0.00037	 loss: 0.0007
2022-01-12 02:17:51:INFO:Epoch: 3	 global_step: 2400/3750	 lr: 0.00036	 loss: 0.0005
2022-01-12 02:18:41:INFO:Epoch: 3	 global_step: 2450/3750	 lr: 0.00035	 loss: 0.0006
2022-01-12 02:19:30:INFO:Epoch: 3	 global_step: 2500/3750	 lr: 0.00033	 loss: 0.0006
2022-01-12 02:20:19:INFO:Epoch: 3	 global_step: 2550/3750	 lr: 0.00032	 loss: 0.0006
2022-01-12 02:21:08:INFO:Epoch: 3	 global_step: 2600/3750	 lr: 0.00031	 loss: 0.0005
2022-01-12 02:21:57:INFO:Epoch: 3	 global_step: 2650/3750	 lr: 0.00029	 loss: 0.0006
2022-01-12 02:22:47:INFO:Epoch: 3	 global_step: 2700/3750	 lr: 0.00028	 loss: 0.0006
2022-01-12 02:23:36:INFO:Epoch: 3	 global_step: 2750/3750	 lr: 0.00027	 loss: 0.0005
2022-01-12 02:24:25:INFO:Epoch: 3	 global_step: 2800/3750	 lr: 0.00025	 loss: 0.0005
2022-01-12 02:25:14:INFO:Epoch: 3	 global_step: 2850/3750	 lr: 0.00024	 loss: 0.0005
2022-01-12 02:26:03:INFO:Epoch: 3	 global_step: 2900/3750	 lr: 0.00023	 loss: 0.0005
2022-01-12 02:26:52:INFO:Epoch: 3	 global_step: 2950/3750	 lr: 0.00021	 loss: 0.0005
2022-01-12 02:27:46:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-12 02:27:46:INFO:	Num examples = 100
2022-01-12 02:27:46:INFO:	RMSE = 14.0719
2022-01-12 02:27:50:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-12 02:27:50:INFO:	Num examples = 100
2022-01-12 02:27:50:INFO:	RMSE = 24.5262
2022-01-12 02:27:51:INFO:Epoch: 4	 global_step: 3000/3750	 lr: 0.00020	 loss: 0.0005
2022-01-12 02:28:41:INFO:Epoch: 4	 global_step: 3050/3750	 lr: 0.00019	 loss: 0.0005
2022-01-12 02:29:30:INFO:Epoch: 4	 global_step: 3100/3750	 lr: 0.00017	 loss: 0.0005
2022-01-12 02:30:20:INFO:Epoch: 4	 global_step: 3150/3750	 lr: 0.00016	 loss: 0.0004
2022-01-12 02:31:09:INFO:Epoch: 4	 global_step: 3200/3750	 lr: 0.00015	 loss: 0.0004
2022-01-12 02:31:58:INFO:Epoch: 4	 global_step: 3250/3750	 lr: 0.00013	 loss: 0.0004
2022-01-12 02:32:48:INFO:Epoch: 4	 global_step: 3300/3750	 lr: 0.00012	 loss: 0.0004
2022-01-12 02:33:37:INFO:Epoch: 4	 global_step: 3350/3750	 lr: 0.00011	 loss: 0.0004
2022-01-12 02:34:27:INFO:Epoch: 4	 global_step: 3400/3750	 lr: 0.00009	 loss: 0.0004
2022-01-12 02:35:16:INFO:Epoch: 4	 global_step: 3450/3750	 lr: 0.00008	 loss: 0.0005
2022-01-12 02:36:06:INFO:Epoch: 4	 global_step: 3500/3750	 lr: 0.00007	 loss: 0.0005
2022-01-12 02:36:55:INFO:Epoch: 4	 global_step: 3550/3750	 lr: 0.00005	 loss: 0.0005
2022-01-12 02:37:44:INFO:Epoch: 4	 global_step: 3600/3750	 lr: 0.00004	 loss: 0.0005
2022-01-12 02:38:34:INFO:Epoch: 4	 global_step: 3650/3750	 lr: 0.00003	 loss: 0.0005
2022-01-12 02:39:23:INFO:Epoch: 4	 global_step: 3700/3750	 lr: 0.00001	 loss: 0.0005
2022-01-12 02:40:16:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-12 02:40:16:INFO:	Num examples = 100
2022-01-12 02:40:16:INFO:	RMSE = 12.6604
2022-01-12 02:40:21:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-12 02:40:21:INFO:	Num examples = 100
2022-01-12 02:40:21:INFO:	RMSE = 27.9775
2022-01-12 02:40:21:INFO:	Output TEST RMSE:	17.0139
2022-01-12 02:40:21:INFO:	VALID RMSEs:	29.6559	26.4091	23.3381	24.5262	27.9775
2022-01-12 02:40:21:INFO:	TEST RMSEs:	20.3023	20.2022	17.0139	14.0719	12.6604
!!! Reset batch info !!! mode: [TRAIN]
!!! Reset batch info !!! mode: [TEST]
!!! Reset batch info !!! mode: [VALID]
!!! Reset batch info !!! mode: [TRAIN]
!!! Reset batch info !!! mode: [TEST]
!!! Reset batch info !!! mode: [VALID]
!!! Reset batch info !!! mode: [TRAIN]
!!! Reset batch info !!! mode: [TEST]
!!! Reset batch info !!! mode: [VALID]
!!! Reset batch info !!! mode: [TRAIN]
!!! Reset batch info !!! mode: [TEST]
!!! Reset batch info !!! mode: [VALID]
2022-01-12 02:40:24:INFO:Finish setting logger...
2022-01-12 02:40:24:INFO:==> Training/Evaluation parameters are:
2022-01-12 02:40:24:INFO:	Namespace(model_dir='cnn2dmodels/data-1_n_epochs-5_aug-150_noise-0.01_supportSize-5_innerSteps-2_lrMeta-0.001_lrInner-0.0001_warmUp-0.0_seed-667'
2022-01-12 02:40:24:INFO:	data_fn=1
2022-01-12 02:40:24:INFO:	datatest_fn=1
2022-01-12 02:40:24:INFO:	filter_kernel_size=1
2022-01-12 02:40:24:INFO:	override_data_cache=False
2022-01-12 02:40:24:INFO:	maxRUL=125
2022-01-12 02:40:24:INFO:	low_ratio=0.1
2022-01-12 02:40:24:INFO:	high_ratio=0.99
2022-01-12 02:40:24:INFO:	aug_ratio=150
2022-01-12 02:40:24:INFO:	noise_amplitude=0.01
2022-01-12 02:40:24:INFO:	modeltype='cnn2d'
2022-01-12 02:40:24:INFO:	max_seq_len=550
2022-01-12 02:40:24:INFO:	d_model=128
2022-01-12 02:40:24:INFO:	p_dropout=0.1
2022-01-12 02:40:24:INFO:	n_head=4
2022-01-12 02:40:24:INFO:	n_layer=2
2022-01-12 02:40:24:INFO:	dim_feedforward=512
2022-01-12 02:40:24:INFO:	e_dropout=0.1
2022-01-12 02:40:24:INFO:	activation='relu'
2022-01-12 02:40:24:INFO:	layer_norm=False
2022-01-12 02:40:24:INFO:	support_size=5
2022-01-12 02:40:24:INFO:	inner_steps=2
2022-01-12 02:40:24:INFO:	lr_inner=0.0001
2022-01-12 02:40:24:INFO:	lr_meta=0.001
2022-01-12 02:40:24:INFO:	n_epochs=5
2022-01-12 02:40:24:INFO:	train_batch_size=20
2022-01-12 02:40:24:INFO:	eval_batch_size=1
2022-01-12 02:40:24:INFO:	lr=0.001
2022-01-12 02:40:24:INFO:	weight_decay=0.01
2022-01-12 02:40:24:INFO:	warmup_ratio=0.0
2022-01-12 02:40:24:INFO:	max_grad_norm=5.0
2022-01-12 02:40:24:INFO:	logging_steps=50
2022-01-12 02:40:24:INFO:	seed=667
2022-01-12 02:40:24:INFO:	gpu_id=2
2022-01-12 02:40:24:INFO:	do_train=True
2022-01-12 02:40:24:INFO:	do_eval=False
2022-01-12 02:40:24:INFO:	train_data_fn='data/train_FD001.txt'
2022-01-12 02:40:24:INFO:	test_data_fn='data/test_FD001.txt'
2022-01-12 02:40:24:INFO:	target_ruls_fn='data/RUL_FD001.txt'
2022-01-12 02:40:24:INFO:	device=device(type='cuda'))
2022-01-12 02:40:24:INFO:Dump arguments to cnn2dmodels/data-1_n_epochs-5_aug-150_noise-0.01_supportSize-5_innerSteps-2_lrMeta-0.001_lrInner-0.0001_warmUp-0.0_seed-667...
2022-01-12 02:40:24:INFO:==> Read data from data/train_FD001.txt...
2022-01-12 02:40:24:INFO:	The selected feature idxs are: 0, 1, 4, 5, 6, 9, 10, 11, 13, 14, 15, 16, 17, 19, 22, 23
2022-01-12 02:40:25:INFO:==> Min_max normalization...
2022-01-12 02:40:25:INFO:	The min value is [-0.008700000122189522, -0.0006000000284984708, 641.2100219726562, 1571.0400390625, 1382.25, 549.8499755859375, 2387.89990234375, 9021.73046875, 46.849998474121094, 518.6900024414062, 2387.8798828125, 8099.93994140625, 8.324899673461914, 388.0, 38.13999938964844, 22.89419937133789]
2022-01-12 02:40:25:INFO:	The max value is [0.008700000122189522, 0.0006000000284984708, 644.530029296875, 1616.9100341796875, 1441.489990234375, 556.0599975585938, 2388.56005859375, 9244.58984375, 48.529998779296875, 523.3800048828125, 2388.56005859375, 8293.7197265625, 8.584799766540527, 400.0, 39.43000030517578, 23.61840057373047]
2022-01-12 02:40:25:INFO:==> Read data from data/test_FD001.txt...
2022-01-12 02:40:25:INFO:	The selected feature idxs are: 0, 1, 4, 5, 6, 9, 10, 11, 13, 14, 15, 16, 17, 19, 22, 23
2022-01-12 02:40:25:INFO:==> Read RULsfrom data/RUL_FD001.txt...
2022-01-12 02:40:25:INFO:	min_rul: 7, max_rul: 145
2022-01-12 02:40:25:INFO:==> Input length ratio of the [TEST] data:
2022-01-12 02:40:25:INFO:	min_ratio = 0.2067
2022-01-12 02:40:25:INFO:	max_ratio = 0.9667
2022-01-12 02:40:25:INFO:==> Min_max normalization...
2022-01-12 02:40:25:INFO:	With given min value [-0.008700000122189522, -0.0006000000284984708, 641.2100219726562, 1571.0400390625, 1382.25, 549.8499755859375, 2387.89990234375, 9021.73046875, 46.849998474121094, 518.6900024414062, 2387.8798828125, 8099.93994140625, 8.324899673461914, 388.0, 38.13999938964844, 22.89419937133789]
2022-01-12 02:40:25:INFO:	With given max value [0.008700000122189522, 0.0006000000284984708, 644.530029296875, 1616.9100341796875, 1441.489990234375, 556.0599975585938, 2388.56005859375, 9244.58984375, 48.529998779296875, 523.3800048828125, 2388.56005859375, 8293.7197265625, 8.584799766540527, 400.0, 39.43000030517578, 23.61840057373047]
2022-01-12 02:40:25:INFO:==> Computing Criterion...
2022-01-12 02:40:25:INFO:	The weights are: 0.007887763902544975, 0.008001004345715046, 0.06667434424161911, 0.0634712353348732, 0.07656104862689972, 0.0755249634385109, 0.06726357340812683, 0.0644979178905487, 0.0795108750462532, 0.07743842899799347, 0.0671684592962265, 0.06869389116764069, 0.07147877663373947, 0.06516212970018387, 0.07012488692998886, 0.07054071873426437
2022-01-12 02:40:39:INFO:Note: NumExpr detected 40 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2022-01-12 02:40:39:INFO:NumExpr defaulting to 8 threads.
2022-01-12 02:40:39:INFO:=============== Scheme: Meta Learning ===============
2022-01-12 02:40:39:INFO:	Num examples = 15000
2022-01-12 02:40:39:INFO:	Num epochs = 5
2022-01-12 02:40:39:INFO:	Batch size = 20
2022-01-12 02:40:39:INFO:	Total meta optimization steps = 3750
2022-01-12 02:40:39:INFO:	Total inner optimization steps = 7500
2022-01-12 02:40:45:INFO:==> Group parameters for optimization...
2022-01-12 02:40:45:INFO:    Parameters to update are:
2022-01-12 02:40:45:INFO:	conv1.0.weight
2022-01-12 02:40:45:INFO:	conv2.0.weight
2022-01-12 02:40:45:INFO:	conv3.0.weight
2022-01-12 02:40:45:INFO:	conv4.0.weight
2022-01-12 02:40:45:INFO:	conv5.0.weight
2022-01-12 02:40:45:INFO:	fc_1.0.weight
2022-01-12 02:40:45:INFO:	fc_1.0.bias
2022-01-12 02:40:45:INFO:	fc_2.weight
2022-01-12 02:40:45:INFO:	fc_2.bias
/data/moy20/Meta-Learning/Meta-prognosis-main/optimizer.py:78: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448255797/work/torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
/data/moy20/miniconda3/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
2022-01-12 02:40:47:INFO:Epoch: 0	 global_step: 0/3750	 lr: 0.00100	 loss: 0.0010
2022-01-12 02:41:50:INFO:Epoch: 0	 global_step: 50/3750	 lr: 0.00099	 loss: 0.0194
2022-01-12 02:42:52:INFO:Epoch: 0	 global_step: 100/3750	 lr: 0.00097	 loss: 0.0091
2022-01-12 02:43:54:INFO:Epoch: 0	 global_step: 150/3750	 lr: 0.00096	 loss: 0.0069
2022-01-12 02:44:56:INFO:Epoch: 0	 global_step: 200/3750	 lr: 0.00095	 loss: 0.0049
2022-01-12 02:45:58:INFO:Epoch: 0	 global_step: 250/3750	 lr: 0.00093	 loss: 0.0054
2022-01-12 02:47:01:INFO:Epoch: 0	 global_step: 300/3750	 lr: 0.00092	 loss: 0.0037
2022-01-12 02:48:03:INFO:Epoch: 0	 global_step: 350/3750	 lr: 0.00091	 loss: 0.0046
2022-01-12 02:49:05:INFO:Epoch: 0	 global_step: 400/3750	 lr: 0.00089	 loss: 0.0034
2022-01-12 02:50:07:INFO:Epoch: 0	 global_step: 450/3750	 lr: 0.00088	 loss: 0.0031
2022-01-12 02:51:10:INFO:Epoch: 0	 global_step: 500/3750	 lr: 0.00087	 loss: 0.0028
2022-01-12 02:52:12:INFO:Epoch: 0	 global_step: 550/3750	 lr: 0.00085	 loss: 0.0025
2022-01-12 02:53:14:INFO:Epoch: 0	 global_step: 600/3750	 lr: 0.00084	 loss: 0.0028
2022-01-12 02:54:17:INFO:Epoch: 0	 global_step: 650/3750	 lr: 0.00083	 loss: 0.0020
2022-01-12 02:55:19:INFO:Epoch: 0	 global_step: 700/3750	 lr: 0.00081	 loss: 0.0020
2022-01-12 02:56:26:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-12 02:56:26:INFO:	Num examples = 100
2022-01-12 02:56:26:INFO:	RMSE = 23.8137
2022-01-12 02:56:32:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-12 02:56:32:INFO:	Num examples = 100
2022-01-12 02:56:32:INFO:	RMSE = 31.3588
2022-01-12 02:56:32:INFO:==> Minimal valid RMSE!
2022-01-12 02:56:32:INFO:Save model to cnn2dmodels/data-1_n_epochs-5_aug-150_noise-0.01_supportSize-5_innerSteps-2_lrMeta-0.001_lrInner-0.0001_warmUp-0.0_seed-667...
2022-01-12 02:56:33:INFO:Epoch: 1	 global_step: 750/3750	 lr: 0.00080	 loss: 0.0022
2022-01-12 02:57:36:INFO:Epoch: 1	 global_step: 800/3750	 lr: 0.00079	 loss: 0.0017
2022-01-12 02:58:38:INFO:Epoch: 1	 global_step: 850/3750	 lr: 0.00077	 loss: 0.0018
2022-01-12 02:59:40:INFO:Epoch: 1	 global_step: 900/3750	 lr: 0.00076	 loss: 0.0019
2022-01-12 03:00:43:INFO:Epoch: 1	 global_step: 950/3750	 lr: 0.00075	 loss: 0.0016
2022-01-12 03:01:44:INFO:Epoch: 1	 global_step: 1000/3750	 lr: 0.00073	 loss: 0.0017
2022-01-12 03:02:47:INFO:Epoch: 1	 global_step: 1050/3750	 lr: 0.00072	 loss: 0.0014
2022-01-12 03:03:49:INFO:Epoch: 1	 global_step: 1100/3750	 lr: 0.00071	 loss: 0.0015
2022-01-12 03:04:51:INFO:Epoch: 1	 global_step: 1150/3750	 lr: 0.00069	 loss: 0.0016
2022-01-12 03:05:54:INFO:Epoch: 1	 global_step: 1200/3750	 lr: 0.00068	 loss: 0.0014
2022-01-12 03:06:56:INFO:Epoch: 1	 global_step: 1250/3750	 lr: 0.00067	 loss: 0.0012
2022-01-12 03:07:59:INFO:Epoch: 1	 global_step: 1300/3750	 lr: 0.00065	 loss: 0.0013
2022-01-12 03:09:01:INFO:Epoch: 1	 global_step: 1350/3750	 lr: 0.00064	 loss: 0.0012
2022-01-12 03:10:03:INFO:Epoch: 1	 global_step: 1400/3750	 lr: 0.00063	 loss: 0.0013
2022-01-12 03:11:06:INFO:Epoch: 1	 global_step: 1450/3750	 lr: 0.00061	 loss: 0.0011
2022-01-12 03:12:14:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-12 03:12:14:INFO:	Num examples = 100
2022-01-12 03:12:14:INFO:	RMSE = 17.9665
2022-01-12 03:12:20:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-12 03:12:20:INFO:	Num examples = 100
2022-01-12 03:12:20:INFO:	RMSE = 27.6762
2022-01-12 03:12:20:INFO:==> Minimal valid RMSE!
2022-01-12 03:12:20:INFO:Save model to cnn2dmodels/data-1_n_epochs-5_aug-150_noise-0.01_supportSize-5_innerSteps-2_lrMeta-0.001_lrInner-0.0001_warmUp-0.0_seed-667...
2022-01-12 03:12:21:INFO:Epoch: 2	 global_step: 1500/3750	 lr: 0.00060	 loss: 0.0013
2022-01-12 03:13:23:INFO:Epoch: 2	 global_step: 1550/3750	 lr: 0.00059	 loss: 0.0011
2022-01-12 03:14:26:INFO:Epoch: 2	 global_step: 1600/3750	 lr: 0.00057	 loss: 0.0012
2022-01-12 03:15:29:INFO:Epoch: 2	 global_step: 1650/3750	 lr: 0.00056	 loss: 0.0011
2022-01-12 03:16:31:INFO:Epoch: 2	 global_step: 1700/3750	 lr: 0.00055	 loss: 0.0011
2022-01-12 03:17:33:INFO:Epoch: 2	 global_step: 1750/3750	 lr: 0.00053	 loss: 0.0009
2022-01-12 03:18:35:INFO:Epoch: 2	 global_step: 1800/3750	 lr: 0.00052	 loss: 0.0011
2022-01-12 03:19:37:INFO:Epoch: 2	 global_step: 1850/3750	 lr: 0.00051	 loss: 0.0009
2022-01-12 03:20:40:INFO:Epoch: 2	 global_step: 1900/3750	 lr: 0.00049	 loss: 0.0010
2022-01-12 03:21:43:INFO:Epoch: 2	 global_step: 1950/3750	 lr: 0.00048	 loss: 0.0009
2022-01-12 03:22:45:INFO:Epoch: 2	 global_step: 2000/3750	 lr: 0.00047	 loss: 0.0009
2022-01-12 03:23:48:INFO:Epoch: 2	 global_step: 2050/3750	 lr: 0.00045	 loss: 0.0010
2022-01-12 03:24:50:INFO:Epoch: 2	 global_step: 2100/3750	 lr: 0.00044	 loss: 0.0008
2022-01-12 03:25:51:INFO:Epoch: 2	 global_step: 2150/3750	 lr: 0.00043	 loss: 0.0008
2022-01-12 03:26:52:INFO:Epoch: 2	 global_step: 2200/3750	 lr: 0.00041	 loss: 0.0009
2022-01-12 03:27:59:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-12 03:27:59:INFO:	Num examples = 100
2022-01-12 03:27:59:INFO:	RMSE = 16.8384
2022-01-12 03:28:05:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-12 03:28:05:INFO:	Num examples = 100
2022-01-12 03:28:05:INFO:	RMSE = 23.3313
2022-01-12 03:28:05:INFO:==> Minimal valid RMSE!
2022-01-12 03:28:05:INFO:Save model to cnn2dmodels/data-1_n_epochs-5_aug-150_noise-0.01_supportSize-5_innerSteps-2_lrMeta-0.001_lrInner-0.0001_warmUp-0.0_seed-667...
2022-01-12 03:28:06:INFO:Epoch: 3	 global_step: 2250/3750	 lr: 0.00040	 loss: 0.0009
2022-01-12 03:29:09:INFO:Epoch: 3	 global_step: 2300/3750	 lr: 0.00039	 loss: 0.0009
2022-01-12 03:30:11:INFO:Epoch: 3	 global_step: 2350/3750	 lr: 0.00037	 loss: 0.0008
2022-01-12 03:31:13:INFO:Epoch: 3	 global_step: 2400/3750	 lr: 0.00036	 loss: 0.0008
2022-01-12 03:32:15:INFO:Epoch: 3	 global_step: 2450/3750	 lr: 0.00035	 loss: 0.0007
2022-01-12 03:33:17:INFO:Epoch: 3	 global_step: 2500/3750	 lr: 0.00033	 loss: 0.0008
2022-01-12 03:34:18:INFO:Epoch: 3	 global_step: 2550/3750	 lr: 0.00032	 loss: 0.0008
2022-01-12 03:35:20:INFO:Epoch: 3	 global_step: 2600/3750	 lr: 0.00031	 loss: 0.0007
2022-01-12 03:36:22:INFO:Epoch: 3	 global_step: 2650/3750	 lr: 0.00029	 loss: 0.0007
2022-01-12 03:37:23:INFO:Epoch: 3	 global_step: 2700/3750	 lr: 0.00028	 loss: 0.0008
2022-01-12 03:38:25:INFO:Epoch: 3	 global_step: 2750/3750	 lr: 0.00027	 loss: 0.0007
2022-01-12 03:39:26:INFO:Epoch: 3	 global_step: 2800/3750	 lr: 0.00025	 loss: 0.0006
2022-01-12 03:40:28:INFO:Epoch: 3	 global_step: 2850/3750	 lr: 0.00024	 loss: 0.0006
2022-01-12 03:41:31:INFO:Epoch: 3	 global_step: 2900/3750	 lr: 0.00023	 loss: 0.0007
2022-01-12 03:42:34:INFO:Epoch: 3	 global_step: 2950/3750	 lr: 0.00021	 loss: 0.0007
2022-01-12 03:43:41:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-12 03:43:41:INFO:	Num examples = 100
2022-01-12 03:43:41:INFO:	RMSE = 15.0693
2022-01-12 03:43:46:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-12 03:43:46:INFO:	Num examples = 100
2022-01-12 03:43:46:INFO:	RMSE = 23.2930
2022-01-12 03:43:46:INFO:==> Minimal valid RMSE!
2022-01-12 03:43:46:INFO:Save model to cnn2dmodels/data-1_n_epochs-5_aug-150_noise-0.01_supportSize-5_innerSteps-2_lrMeta-0.001_lrInner-0.0001_warmUp-0.0_seed-667...
2022-01-12 03:43:48:INFO:Epoch: 4	 global_step: 3000/3750	 lr: 0.00020	 loss: 0.0006
2022-01-12 03:44:50:INFO:Epoch: 4	 global_step: 3050/3750	 lr: 0.00019	 loss: 0.0006
2022-01-12 03:45:52:INFO:Epoch: 4	 global_step: 3100/3750	 lr: 0.00017	 loss: 0.0006
2022-01-12 03:46:55:INFO:Epoch: 4	 global_step: 3150/3750	 lr: 0.00016	 loss: 0.0006
2022-01-12 03:47:57:INFO:Epoch: 4	 global_step: 3200/3750	 lr: 0.00015	 loss: 0.0006
2022-01-12 03:49:00:INFO:Epoch: 4	 global_step: 3250/3750	 lr: 0.00013	 loss: 0.0005
2022-01-12 03:50:02:INFO:Epoch: 4	 global_step: 3300/3750	 lr: 0.00012	 loss: 0.0006
2022-01-12 03:51:05:INFO:Epoch: 4	 global_step: 3350/3750	 lr: 0.00011	 loss: 0.0005
2022-01-12 03:52:07:INFO:Epoch: 4	 global_step: 3400/3750	 lr: 0.00009	 loss: 0.0005
2022-01-12 03:53:09:INFO:Epoch: 4	 global_step: 3450/3750	 lr: 0.00008	 loss: 0.0006
2022-01-12 03:54:12:INFO:Epoch: 4	 global_step: 3500/3750	 lr: 0.00007	 loss: 0.0006
2022-01-12 03:55:14:INFO:Epoch: 4	 global_step: 3550/3750	 lr: 0.00005	 loss: 0.0005
2022-01-12 03:56:17:INFO:Epoch: 4	 global_step: 3600/3750	 lr: 0.00004	 loss: 0.0006
2022-01-12 03:57:20:INFO:Epoch: 4	 global_step: 3650/3750	 lr: 0.00003	 loss: 0.0005
2022-01-12 03:58:23:INFO:Epoch: 4	 global_step: 3700/3750	 lr: 0.00001	 loss: 0.0006
2022-01-12 03:59:31:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-12 03:59:31:INFO:	Num examples = 100
2022-01-12 03:59:31:INFO:	RMSE = 13.9635
2022-01-12 03:59:36:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-12 03:59:36:INFO:	Num examples = 100
2022-01-12 03:59:36:INFO:	RMSE = 28.3716
2022-01-12 03:59:36:INFO:	Output TEST RMSE:	15.0693
2022-01-12 03:59:36:INFO:	VALID RMSEs:	31.3588	27.6762	23.3313	23.2930	28.3716
2022-01-12 03:59:36:INFO:	TEST RMSEs:	23.8137	17.9665	16.8384	15.0693	13.9635
!!! Reset batch info !!! mode: [TRAIN]
!!! Reset batch info !!! mode: [TEST]
!!! Reset batch info !!! mode: [VALID]
!!! Reset batch info !!! mode: [TRAIN]
!!! Reset batch info !!! mode: [TEST]
!!! Reset batch info !!! mode: [VALID]
!!! Reset batch info !!! mode: [TRAIN]
!!! Reset batch info !!! mode: [TEST]
!!! Reset batch info !!! mode: [VALID]
!!! Reset batch info !!! mode: [TRAIN]
!!! Reset batch info !!! mode: [TEST]
!!! Reset batch info !!! mode: [VALID]
2022-01-12 03:59:41:INFO:Finish setting logger...
2022-01-12 03:59:41:INFO:==> Training/Evaluation parameters are:
2022-01-12 03:59:41:INFO:	Namespace(model_dir='cnn2dmodels/data-1_n_epochs-5_aug-150_noise-0.01_supportSize-5_innerSteps-2_lrMeta-0.001_lrInner-0.001_warmUp-0.0_seed-667'
2022-01-12 03:59:41:INFO:	data_fn=1
2022-01-12 03:59:41:INFO:	datatest_fn=1
2022-01-12 03:59:41:INFO:	filter_kernel_size=1
2022-01-12 03:59:41:INFO:	override_data_cache=False
2022-01-12 03:59:41:INFO:	maxRUL=125
2022-01-12 03:59:41:INFO:	low_ratio=0.1
2022-01-12 03:59:41:INFO:	high_ratio=0.99
2022-01-12 03:59:41:INFO:	aug_ratio=150
2022-01-12 03:59:41:INFO:	noise_amplitude=0.01
2022-01-12 03:59:41:INFO:	modeltype='cnn2d'
2022-01-12 03:59:41:INFO:	max_seq_len=550
2022-01-12 03:59:41:INFO:	d_model=128
2022-01-12 03:59:41:INFO:	p_dropout=0.1
2022-01-12 03:59:41:INFO:	n_head=4
2022-01-12 03:59:41:INFO:	n_layer=2
2022-01-12 03:59:41:INFO:	dim_feedforward=512
2022-01-12 03:59:41:INFO:	e_dropout=0.1
2022-01-12 03:59:41:INFO:	activation='relu'
2022-01-12 03:59:41:INFO:	layer_norm=False
2022-01-12 03:59:41:INFO:	support_size=5
2022-01-12 03:59:41:INFO:	inner_steps=2
2022-01-12 03:59:41:INFO:	lr_inner=0.001
2022-01-12 03:59:41:INFO:	lr_meta=0.001
2022-01-12 03:59:41:INFO:	n_epochs=5
2022-01-12 03:59:41:INFO:	train_batch_size=20
2022-01-12 03:59:41:INFO:	eval_batch_size=1
2022-01-12 03:59:41:INFO:	lr=0.001
2022-01-12 03:59:41:INFO:	weight_decay=0.01
2022-01-12 03:59:41:INFO:	warmup_ratio=0.0
2022-01-12 03:59:41:INFO:	max_grad_norm=5.0
2022-01-12 03:59:41:INFO:	logging_steps=50
2022-01-12 03:59:41:INFO:	seed=667
2022-01-12 03:59:41:INFO:	gpu_id=2
2022-01-12 03:59:41:INFO:	do_train=True
2022-01-12 03:59:41:INFO:	do_eval=False
2022-01-12 03:59:41:INFO:	train_data_fn='data/train_FD001.txt'
2022-01-12 03:59:41:INFO:	test_data_fn='data/test_FD001.txt'
2022-01-12 03:59:41:INFO:	target_ruls_fn='data/RUL_FD001.txt'
2022-01-12 03:59:41:INFO:	device=device(type='cuda'))
2022-01-12 03:59:41:INFO:Dump arguments to cnn2dmodels/data-1_n_epochs-5_aug-150_noise-0.01_supportSize-5_innerSteps-2_lrMeta-0.001_lrInner-0.001_warmUp-0.0_seed-667...
2022-01-12 03:59:41:INFO:==> Read data from data/train_FD001.txt...
2022-01-12 03:59:41:INFO:	The selected feature idxs are: 0, 1, 4, 5, 6, 9, 10, 11, 13, 14, 15, 16, 17, 19, 22, 23
2022-01-12 03:59:41:INFO:==> Min_max normalization...
2022-01-12 03:59:41:INFO:	The min value is [-0.008700000122189522, -0.0006000000284984708, 641.2100219726562, 1571.0400390625, 1382.25, 549.8499755859375, 2387.89990234375, 9021.73046875, 46.849998474121094, 518.6900024414062, 2387.8798828125, 8099.93994140625, 8.324899673461914, 388.0, 38.13999938964844, 22.89419937133789]
2022-01-12 03:59:41:INFO:	The max value is [0.008700000122189522, 0.0006000000284984708, 644.530029296875, 1616.9100341796875, 1441.489990234375, 556.0599975585938, 2388.56005859375, 9244.58984375, 48.529998779296875, 523.3800048828125, 2388.56005859375, 8293.7197265625, 8.584799766540527, 400.0, 39.43000030517578, 23.61840057373047]
2022-01-12 03:59:41:INFO:==> Read data from data/test_FD001.txt...
2022-01-12 03:59:41:INFO:	The selected feature idxs are: 0, 1, 4, 5, 6, 9, 10, 11, 13, 14, 15, 16, 17, 19, 22, 23
2022-01-12 03:59:41:INFO:==> Read RULsfrom data/RUL_FD001.txt...
2022-01-12 03:59:41:INFO:	min_rul: 7, max_rul: 145
2022-01-12 03:59:41:INFO:==> Input length ratio of the [TEST] data:
2022-01-12 03:59:41:INFO:	min_ratio = 0.2067
2022-01-12 03:59:41:INFO:	max_ratio = 0.9667
2022-01-12 03:59:41:INFO:==> Min_max normalization...
2022-01-12 03:59:41:INFO:	With given min value [-0.008700000122189522, -0.0006000000284984708, 641.2100219726562, 1571.0400390625, 1382.25, 549.8499755859375, 2387.89990234375, 9021.73046875, 46.849998474121094, 518.6900024414062, 2387.8798828125, 8099.93994140625, 8.324899673461914, 388.0, 38.13999938964844, 22.89419937133789]
2022-01-12 03:59:41:INFO:	With given max value [0.008700000122189522, 0.0006000000284984708, 644.530029296875, 1616.9100341796875, 1441.489990234375, 556.0599975585938, 2388.56005859375, 9244.58984375, 48.529998779296875, 523.3800048828125, 2388.56005859375, 8293.7197265625, 8.584799766540527, 400.0, 39.43000030517578, 23.61840057373047]
2022-01-12 03:59:41:INFO:==> Computing Criterion...
2022-01-12 03:59:41:INFO:	The weights are: 0.007887763902544975, 0.008001004345715046, 0.06667434424161911, 0.0634712353348732, 0.07656104862689972, 0.0755249634385109, 0.06726357340812683, 0.0644979178905487, 0.0795108750462532, 0.07743842899799347, 0.0671684592962265, 0.06869389116764069, 0.07147877663373947, 0.06516212970018387, 0.07012488692998886, 0.07054071873426437
2022-01-12 03:59:54:INFO:Note: NumExpr detected 40 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2022-01-12 03:59:54:INFO:NumExpr defaulting to 8 threads.
2022-01-12 03:59:54:INFO:=============== Scheme: Meta Learning ===============
2022-01-12 03:59:54:INFO:	Num examples = 15000
2022-01-12 03:59:54:INFO:	Num epochs = 5
2022-01-12 03:59:54:INFO:	Batch size = 20
2022-01-12 03:59:54:INFO:	Total meta optimization steps = 3750
2022-01-12 03:59:54:INFO:	Total inner optimization steps = 7500
2022-01-12 04:00:00:INFO:==> Group parameters for optimization...
2022-01-12 04:00:00:INFO:    Parameters to update are:
2022-01-12 04:00:00:INFO:	conv1.0.weight
2022-01-12 04:00:00:INFO:	conv2.0.weight
2022-01-12 04:00:00:INFO:	conv3.0.weight
2022-01-12 04:00:00:INFO:	conv4.0.weight
2022-01-12 04:00:00:INFO:	conv5.0.weight
2022-01-12 04:00:00:INFO:	fc_1.0.weight
2022-01-12 04:00:00:INFO:	fc_1.0.bias
2022-01-12 04:00:00:INFO:	fc_2.weight
2022-01-12 04:00:00:INFO:	fc_2.bias
/data/moy20/Meta-Learning/Meta-prognosis-main/optimizer.py:78: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448255797/work/torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
/data/moy20/miniconda3/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
2022-01-12 04:00:03:INFO:Epoch: 0	 global_step: 0/3750	 lr: 0.00100	 loss: 0.0010
2022-01-12 04:01:06:INFO:Epoch: 0	 global_step: 50/3750	 lr: 0.00099	 loss: 0.0194
2022-01-12 04:02:08:INFO:Epoch: 0	 global_step: 100/3750	 lr: 0.00097	 loss: 0.0091
2022-01-12 04:03:11:INFO:Epoch: 0	 global_step: 150/3750	 lr: 0.00096	 loss: 0.0069
2022-01-12 04:04:14:INFO:Epoch: 0	 global_step: 200/3750	 lr: 0.00095	 loss: 0.0049
2022-01-12 04:05:17:INFO:Epoch: 0	 global_step: 250/3750	 lr: 0.00093	 loss: 0.0054
2022-01-12 04:06:19:INFO:Epoch: 0	 global_step: 300/3750	 lr: 0.00092	 loss: 0.0037
2022-01-12 04:07:22:INFO:Epoch: 0	 global_step: 350/3750	 lr: 0.00091	 loss: 0.0046
2022-01-12 04:08:25:INFO:Epoch: 0	 global_step: 400/3750	 lr: 0.00089	 loss: 0.0034
2022-01-12 04:09:27:INFO:Epoch: 0	 global_step: 450/3750	 lr: 0.00088	 loss: 0.0031
2022-01-12 04:10:29:INFO:Epoch: 0	 global_step: 500/3750	 lr: 0.00087	 loss: 0.0028
2022-01-12 04:11:31:INFO:Epoch: 0	 global_step: 550/3750	 lr: 0.00085	 loss: 0.0025
2022-01-12 04:12:34:INFO:Epoch: 0	 global_step: 600/3750	 lr: 0.00084	 loss: 0.0028
2022-01-12 04:13:36:INFO:Epoch: 0	 global_step: 650/3750	 lr: 0.00083	 loss: 0.0020
2022-01-12 04:14:40:INFO:Epoch: 0	 global_step: 700/3750	 lr: 0.00081	 loss: 0.0020
2022-01-12 04:15:46:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-12 04:15:46:INFO:	Num examples = 100
2022-01-12 04:15:46:INFO:	RMSE = 23.8137
2022-01-12 04:15:52:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-12 04:15:52:INFO:	Num examples = 100
2022-01-12 04:15:52:INFO:	RMSE = 31.3588
2022-01-12 04:15:52:INFO:==> Minimal valid RMSE!
2022-01-12 04:15:52:INFO:Save model to cnn2dmodels/data-1_n_epochs-5_aug-150_noise-0.01_supportSize-5_innerSteps-2_lrMeta-0.001_lrInner-0.001_warmUp-0.0_seed-667...
2022-01-12 04:15:54:INFO:Epoch: 1	 global_step: 750/3750	 lr: 0.00080	 loss: 0.0022
2022-01-12 04:16:55:INFO:Epoch: 1	 global_step: 800/3750	 lr: 0.00079	 loss: 0.0017
2022-01-12 04:17:57:INFO:Epoch: 1	 global_step: 850/3750	 lr: 0.00077	 loss: 0.0018
2022-01-12 04:18:59:INFO:Epoch: 1	 global_step: 900/3750	 lr: 0.00076	 loss: 0.0019
2022-01-12 04:20:02:INFO:Epoch: 1	 global_step: 950/3750	 lr: 0.00075	 loss: 0.0016
2022-01-12 04:21:04:INFO:Epoch: 1	 global_step: 1000/3750	 lr: 0.00073	 loss: 0.0017
2022-01-12 04:22:06:INFO:Epoch: 1	 global_step: 1050/3750	 lr: 0.00072	 loss: 0.0014
2022-01-12 04:23:08:INFO:Epoch: 1	 global_step: 1100/3750	 lr: 0.00071	 loss: 0.0015
2022-01-12 04:24:10:INFO:Epoch: 1	 global_step: 1150/3750	 lr: 0.00069	 loss: 0.0016
2022-01-12 04:25:13:INFO:Epoch: 1	 global_step: 1200/3750	 lr: 0.00068	 loss: 0.0014
2022-01-12 04:26:16:INFO:Epoch: 1	 global_step: 1250/3750	 lr: 0.00067	 loss: 0.0012
2022-01-12 04:27:19:INFO:Epoch: 1	 global_step: 1300/3750	 lr: 0.00065	 loss: 0.0013
2022-01-12 04:28:22:INFO:Epoch: 1	 global_step: 1350/3750	 lr: 0.00064	 loss: 0.0012
2022-01-12 04:29:23:INFO:Epoch: 1	 global_step: 1400/3750	 lr: 0.00063	 loss: 0.0013
2022-01-12 04:30:26:INFO:Epoch: 1	 global_step: 1450/3750	 lr: 0.00061	 loss: 0.0011
2022-01-12 04:31:33:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-12 04:31:33:INFO:	Num examples = 100
2022-01-12 04:31:33:INFO:	RMSE = 17.9665
2022-01-12 04:31:39:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-12 04:31:39:INFO:	Num examples = 100
2022-01-12 04:31:39:INFO:	RMSE = 27.6762
2022-01-12 04:31:39:INFO:==> Minimal valid RMSE!
2022-01-12 04:31:39:INFO:Save model to cnn2dmodels/data-1_n_epochs-5_aug-150_noise-0.01_supportSize-5_innerSteps-2_lrMeta-0.001_lrInner-0.001_warmUp-0.0_seed-667...
2022-01-12 04:31:40:INFO:Epoch: 2	 global_step: 1500/3750	 lr: 0.00060	 loss: 0.0013
2022-01-12 04:32:41:INFO:Epoch: 2	 global_step: 1550/3750	 lr: 0.00059	 loss: 0.0011
2022-01-12 04:33:43:INFO:Epoch: 2	 global_step: 1600/3750	 lr: 0.00057	 loss: 0.0012
2022-01-12 04:34:45:INFO:Epoch: 2	 global_step: 1650/3750	 lr: 0.00056	 loss: 0.0011
2022-01-12 04:35:46:INFO:Epoch: 2	 global_step: 1700/3750	 lr: 0.00055	 loss: 0.0011
2022-01-12 04:36:49:INFO:Epoch: 2	 global_step: 1750/3750	 lr: 0.00053	 loss: 0.0009
2022-01-12 04:37:52:INFO:Epoch: 2	 global_step: 1800/3750	 lr: 0.00052	 loss: 0.0011
2022-01-12 04:38:55:INFO:Epoch: 2	 global_step: 1850/3750	 lr: 0.00051	 loss: 0.0009
2022-01-12 04:39:58:INFO:Epoch: 2	 global_step: 1900/3750	 lr: 0.00049	 loss: 0.0010
2022-01-12 04:41:01:INFO:Epoch: 2	 global_step: 1950/3750	 lr: 0.00048	 loss: 0.0009
2022-01-12 04:42:04:INFO:Epoch: 2	 global_step: 2000/3750	 lr: 0.00047	 loss: 0.0009
2022-01-12 04:43:06:INFO:Epoch: 2	 global_step: 2050/3750	 lr: 0.00045	 loss: 0.0010
2022-01-12 04:44:09:INFO:Epoch: 2	 global_step: 2100/3750	 lr: 0.00044	 loss: 0.0008
2022-01-12 04:45:12:INFO:Epoch: 2	 global_step: 2150/3750	 lr: 0.00043	 loss: 0.0008
2022-01-12 04:46:14:INFO:Epoch: 2	 global_step: 2200/3750	 lr: 0.00041	 loss: 0.0009
2022-01-12 04:47:22:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-12 04:47:22:INFO:	Num examples = 100
2022-01-12 04:47:22:INFO:	RMSE = 16.8384
2022-01-12 04:47:27:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-12 04:47:27:INFO:	Num examples = 100
2022-01-12 04:47:27:INFO:	RMSE = 23.3313
2022-01-12 04:47:27:INFO:==> Minimal valid RMSE!
2022-01-12 04:47:27:INFO:Save model to cnn2dmodels/data-1_n_epochs-5_aug-150_noise-0.01_supportSize-5_innerSteps-2_lrMeta-0.001_lrInner-0.001_warmUp-0.0_seed-667...
2022-01-12 04:47:29:INFO:Epoch: 3	 global_step: 2250/3750	 lr: 0.00040	 loss: 0.0009
2022-01-12 04:48:30:INFO:Epoch: 3	 global_step: 2300/3750	 lr: 0.00039	 loss: 0.0009
2022-01-12 04:49:33:INFO:Epoch: 3	 global_step: 2350/3750	 lr: 0.00037	 loss: 0.0008
2022-01-12 04:50:35:INFO:Epoch: 3	 global_step: 2400/3750	 lr: 0.00036	 loss: 0.0008
2022-01-12 04:51:38:INFO:Epoch: 3	 global_step: 2450/3750	 lr: 0.00035	 loss: 0.0007
2022-01-12 04:52:39:INFO:Epoch: 3	 global_step: 2500/3750	 lr: 0.00033	 loss: 0.0008
2022-01-12 04:53:42:INFO:Epoch: 3	 global_step: 2550/3750	 lr: 0.00032	 loss: 0.0008
2022-01-12 04:54:45:INFO:Epoch: 3	 global_step: 2600/3750	 lr: 0.00031	 loss: 0.0007
2022-01-12 04:55:48:INFO:Epoch: 3	 global_step: 2650/3750	 lr: 0.00029	 loss: 0.0007
2022-01-12 04:56:50:INFO:Epoch: 3	 global_step: 2700/3750	 lr: 0.00028	 loss: 0.0008
2022-01-12 04:57:53:INFO:Epoch: 3	 global_step: 2750/3750	 lr: 0.00027	 loss: 0.0007
2022-01-12 04:58:56:INFO:Epoch: 3	 global_step: 2800/3750	 lr: 0.00025	 loss: 0.0006
2022-01-12 04:59:59:INFO:Epoch: 3	 global_step: 2850/3750	 lr: 0.00024	 loss: 0.0006
2022-01-12 05:01:01:INFO:Epoch: 3	 global_step: 2900/3750	 lr: 0.00023	 loss: 0.0007
2022-01-12 05:02:03:INFO:Epoch: 3	 global_step: 2950/3750	 lr: 0.00021	 loss: 0.0007
2022-01-12 05:03:11:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-12 05:03:11:INFO:	Num examples = 100
2022-01-12 05:03:11:INFO:	RMSE = 15.0693
2022-01-12 05:03:17:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-12 05:03:17:INFO:	Num examples = 100
2022-01-12 05:03:17:INFO:	RMSE = 23.2930
2022-01-12 05:03:17:INFO:==> Minimal valid RMSE!
2022-01-12 05:03:17:INFO:Save model to cnn2dmodels/data-1_n_epochs-5_aug-150_noise-0.01_supportSize-5_innerSteps-2_lrMeta-0.001_lrInner-0.001_warmUp-0.0_seed-667...
2022-01-12 05:03:18:INFO:Epoch: 4	 global_step: 3000/3750	 lr: 0.00020	 loss: 0.0006
2022-01-12 05:04:20:INFO:Epoch: 4	 global_step: 3050/3750	 lr: 0.00019	 loss: 0.0006
2022-01-12 05:05:23:INFO:Epoch: 4	 global_step: 3100/3750	 lr: 0.00017	 loss: 0.0006
2022-01-12 05:06:25:INFO:Epoch: 4	 global_step: 3150/3750	 lr: 0.00016	 loss: 0.0006
2022-01-12 05:07:27:INFO:Epoch: 4	 global_step: 3200/3750	 lr: 0.00015	 loss: 0.0006
2022-01-12 05:08:30:INFO:Epoch: 4	 global_step: 3250/3750	 lr: 0.00013	 loss: 0.0005
2022-01-12 05:09:32:INFO:Epoch: 4	 global_step: 3300/3750	 lr: 0.00012	 loss: 0.0006
2022-01-12 05:10:34:INFO:Epoch: 4	 global_step: 3350/3750	 lr: 0.00011	 loss: 0.0005
2022-01-12 05:11:36:INFO:Epoch: 4	 global_step: 3400/3750	 lr: 0.00009	 loss: 0.0005
2022-01-12 05:12:39:INFO:Epoch: 4	 global_step: 3450/3750	 lr: 0.00008	 loss: 0.0006
2022-01-12 05:13:41:INFO:Epoch: 4	 global_step: 3500/3750	 lr: 0.00007	 loss: 0.0006
2022-01-12 05:14:44:INFO:Epoch: 4	 global_step: 3550/3750	 lr: 0.00005	 loss: 0.0005
2022-01-12 05:15:47:INFO:Epoch: 4	 global_step: 3600/3750	 lr: 0.00004	 loss: 0.0006
2022-01-12 05:16:51:INFO:Epoch: 4	 global_step: 3650/3750	 lr: 0.00003	 loss: 0.0005
2022-01-12 05:17:53:INFO:Epoch: 4	 global_step: 3700/3750	 lr: 0.00001	 loss: 0.0006
2022-01-12 05:19:01:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-12 05:19:01:INFO:	Num examples = 100
2022-01-12 05:19:01:INFO:	RMSE = 13.9635
2022-01-12 05:19:06:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-12 05:19:06:INFO:	Num examples = 100
2022-01-12 05:19:06:INFO:	RMSE = 28.3716
2022-01-12 05:19:06:INFO:	Output TEST RMSE:	15.0693
2022-01-12 05:19:06:INFO:	VALID RMSEs:	31.3588	27.6762	23.3313	23.2930	28.3716
2022-01-12 05:19:06:INFO:	TEST RMSEs:	23.8137	17.9665	16.8384	15.0693	13.9635
!!! Reset batch info !!! mode: [TRAIN]
!!! Reset batch info !!! mode: [TEST]
!!! Reset batch info !!! mode: [VALID]
!!! Reset batch info !!! mode: [TRAIN]
!!! Reset batch info !!! mode: [TEST]
!!! Reset batch info !!! mode: [VALID]
!!! Reset batch info !!! mode: [TRAIN]
!!! Reset batch info !!! mode: [TEST]
!!! Reset batch info !!! mode: [VALID]
!!! Reset batch info !!! mode: [TRAIN]
!!! Reset batch info !!! mode: [TEST]
!!! Reset batch info !!! mode: [VALID]
2022-01-12 05:19:11:INFO:Finish setting logger...
2022-01-12 05:19:11:INFO:==> Training/Evaluation parameters are:
2022-01-12 05:19:11:INFO:	Namespace(model_dir='cnn2dmodels/data-1_n_epochs-5_aug-150_noise-0.01_supportSize-2_innerSteps-2_lrMeta-0.001_lrInner-0.0001_warmUp-0.0_seed-128'
2022-01-12 05:19:11:INFO:	data_fn=1
2022-01-12 05:19:11:INFO:	datatest_fn=1
2022-01-12 05:19:11:INFO:	filter_kernel_size=1
2022-01-12 05:19:11:INFO:	override_data_cache=False
2022-01-12 05:19:11:INFO:	maxRUL=125
2022-01-12 05:19:11:INFO:	low_ratio=0.1
2022-01-12 05:19:11:INFO:	high_ratio=0.99
2022-01-12 05:19:11:INFO:	aug_ratio=150
2022-01-12 05:19:11:INFO:	noise_amplitude=0.01
2022-01-12 05:19:11:INFO:	modeltype='cnn2d'
2022-01-12 05:19:11:INFO:	max_seq_len=550
2022-01-12 05:19:11:INFO:	d_model=128
2022-01-12 05:19:11:INFO:	p_dropout=0.1
2022-01-12 05:19:11:INFO:	n_head=4
2022-01-12 05:19:11:INFO:	n_layer=2
2022-01-12 05:19:11:INFO:	dim_feedforward=512
2022-01-12 05:19:11:INFO:	e_dropout=0.1
2022-01-12 05:19:11:INFO:	activation='relu'
2022-01-12 05:19:11:INFO:	layer_norm=False
2022-01-12 05:19:11:INFO:	support_size=2
2022-01-12 05:19:11:INFO:	inner_steps=2
2022-01-12 05:19:11:INFO:	lr_inner=0.0001
2022-01-12 05:19:11:INFO:	lr_meta=0.001
2022-01-12 05:19:11:INFO:	n_epochs=5
2022-01-12 05:19:11:INFO:	train_batch_size=20
2022-01-12 05:19:11:INFO:	eval_batch_size=1
2022-01-12 05:19:11:INFO:	lr=0.001
2022-01-12 05:19:11:INFO:	weight_decay=0.01
2022-01-12 05:19:11:INFO:	warmup_ratio=0.0
2022-01-12 05:19:11:INFO:	max_grad_norm=5.0
2022-01-12 05:19:11:INFO:	logging_steps=50
2022-01-12 05:19:11:INFO:	seed=128
2022-01-12 05:19:11:INFO:	gpu_id=2
2022-01-12 05:19:11:INFO:	do_train=True
2022-01-12 05:19:11:INFO:	do_eval=False
2022-01-12 05:19:11:INFO:	train_data_fn='data/train_FD001.txt'
2022-01-12 05:19:11:INFO:	test_data_fn='data/test_FD001.txt'
2022-01-12 05:19:11:INFO:	target_ruls_fn='data/RUL_FD001.txt'
2022-01-12 05:19:11:INFO:	device=device(type='cuda'))
2022-01-12 05:19:11:INFO:Dump arguments to cnn2dmodels/data-1_n_epochs-5_aug-150_noise-0.01_supportSize-2_innerSteps-2_lrMeta-0.001_lrInner-0.0001_warmUp-0.0_seed-128...
2022-01-12 05:19:11:INFO:==> Read data from data/train_FD001.txt...
2022-01-12 05:19:11:INFO:	The selected feature idxs are: 0, 1, 4, 5, 6, 9, 10, 11, 13, 14, 15, 16, 17, 19, 22, 23
2022-01-12 05:19:11:INFO:==> Min_max normalization...
2022-01-12 05:19:11:INFO:	The min value is [-0.008700000122189522, -0.0006000000284984708, 641.2100219726562, 1571.0400390625, 1382.25, 549.8499755859375, 2387.89990234375, 9021.73046875, 46.849998474121094, 518.6900024414062, 2387.8798828125, 8099.93994140625, 8.324899673461914, 388.0, 38.13999938964844, 22.89419937133789]
2022-01-12 05:19:11:INFO:	The max value is [0.008700000122189522, 0.0006000000284984708, 644.530029296875, 1616.9100341796875, 1441.489990234375, 556.0599975585938, 2388.56005859375, 9244.58984375, 48.529998779296875, 523.3800048828125, 2388.56005859375, 8293.7197265625, 8.584799766540527, 400.0, 39.43000030517578, 23.61840057373047]
2022-01-12 05:19:11:INFO:==> Read data from data/test_FD001.txt...
2022-01-12 05:19:11:INFO:	The selected feature idxs are: 0, 1, 4, 5, 6, 9, 10, 11, 13, 14, 15, 16, 17, 19, 22, 23
2022-01-12 05:19:11:INFO:==> Read RULsfrom data/RUL_FD001.txt...
2022-01-12 05:19:11:INFO:	min_rul: 7, max_rul: 145
2022-01-12 05:19:11:INFO:==> Input length ratio of the [TEST] data:
2022-01-12 05:19:11:INFO:	min_ratio = 0.2067
2022-01-12 05:19:11:INFO:	max_ratio = 0.9667
2022-01-12 05:19:11:INFO:==> Min_max normalization...
2022-01-12 05:19:11:INFO:	With given min value [-0.008700000122189522, -0.0006000000284984708, 641.2100219726562, 1571.0400390625, 1382.25, 549.8499755859375, 2387.89990234375, 9021.73046875, 46.849998474121094, 518.6900024414062, 2387.8798828125, 8099.93994140625, 8.324899673461914, 388.0, 38.13999938964844, 22.89419937133789]
2022-01-12 05:19:11:INFO:	With given max value [0.008700000122189522, 0.0006000000284984708, 644.530029296875, 1616.9100341796875, 1441.489990234375, 556.0599975585938, 2388.56005859375, 9244.58984375, 48.529998779296875, 523.3800048828125, 2388.56005859375, 8293.7197265625, 8.584799766540527, 400.0, 39.43000030517578, 23.61840057373047]
2022-01-12 05:19:11:INFO:==> Computing Criterion...
2022-01-12 05:19:11:INFO:	The weights are: 0.007887763902544975, 0.008001004345715046, 0.06667434424161911, 0.0634712353348732, 0.07656104862689972, 0.0755249634385109, 0.06726357340812683, 0.0644979178905487, 0.0795108750462532, 0.07743842899799347, 0.0671684592962265, 0.06869389116764069, 0.07147877663373947, 0.06516212970018387, 0.07012488692998886, 0.07054071873426437
2022-01-12 05:19:18:INFO:Note: NumExpr detected 40 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2022-01-12 05:19:18:INFO:NumExpr defaulting to 8 threads.
2022-01-12 05:19:18:INFO:=============== Scheme: Meta Learning ===============
2022-01-12 05:19:18:INFO:	Num examples = 15000
2022-01-12 05:19:18:INFO:	Num epochs = 5
2022-01-12 05:19:18:INFO:	Batch size = 20
2022-01-12 05:19:18:INFO:	Total meta optimization steps = 3750
2022-01-12 05:19:18:INFO:	Total inner optimization steps = 7500
2022-01-12 05:19:24:INFO:==> Group parameters for optimization...
2022-01-12 05:19:24:INFO:    Parameters to update are:
2022-01-12 05:19:24:INFO:	conv1.0.weight
2022-01-12 05:19:24:INFO:	conv2.0.weight
2022-01-12 05:19:24:INFO:	conv3.0.weight
2022-01-12 05:19:24:INFO:	conv4.0.weight
2022-01-12 05:19:24:INFO:	conv5.0.weight
2022-01-12 05:19:24:INFO:	fc_1.0.weight
2022-01-12 05:19:24:INFO:	fc_1.0.bias
2022-01-12 05:19:24:INFO:	fc_2.weight
2022-01-12 05:19:24:INFO:	fc_2.bias
/data/moy20/Meta-Learning/Meta-prognosis-main/optimizer.py:78: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448255797/work/torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
/data/moy20/miniconda3/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
2022-01-12 05:19:26:INFO:Epoch: 0	 global_step: 0/3750	 lr: 0.00100	 loss: 0.0011
2022-01-12 05:20:16:INFO:Epoch: 0	 global_step: 50/3750	 lr: 0.00099	 loss: 0.0219
2022-01-12 05:21:06:INFO:Epoch: 0	 global_step: 100/3750	 lr: 0.00097	 loss: 0.0084
2022-01-12 05:21:56:INFO:Epoch: 0	 global_step: 150/3750	 lr: 0.00096	 loss: 0.0052
2022-01-12 05:22:46:INFO:Epoch: 0	 global_step: 200/3750	 lr: 0.00095	 loss: 0.0047
2022-01-12 05:23:36:INFO:Epoch: 0	 global_step: 250/3750	 lr: 0.00093	 loss: 0.0042
2022-01-12 05:24:25:INFO:Epoch: 0	 global_step: 300/3750	 lr: 0.00092	 loss: 0.0046
2022-01-12 05:25:16:INFO:Epoch: 0	 global_step: 350/3750	 lr: 0.00091	 loss: 0.0033
2022-01-12 05:26:06:INFO:Epoch: 0	 global_step: 400/3750	 lr: 0.00089	 loss: 0.0027
2022-01-12 05:26:56:INFO:Epoch: 0	 global_step: 450/3750	 lr: 0.00088	 loss: 0.0030
2022-01-12 05:27:46:INFO:Epoch: 0	 global_step: 500/3750	 lr: 0.00087	 loss: 0.0024
2022-01-12 05:28:36:INFO:Epoch: 0	 global_step: 550/3750	 lr: 0.00085	 loss: 0.0021
2022-01-12 05:29:26:INFO:Epoch: 0	 global_step: 600/3750	 lr: 0.00084	 loss: 0.0019
2022-01-12 05:30:16:INFO:Epoch: 0	 global_step: 650/3750	 lr: 0.00083	 loss: 0.0015
2022-01-12 05:31:06:INFO:Epoch: 0	 global_step: 700/3750	 lr: 0.00081	 loss: 0.0016
2022-01-12 05:32:00:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-12 05:32:00:INFO:	Num examples = 100
2022-01-12 05:32:00:INFO:	RMSE = 22.8605
2022-01-12 05:32:05:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-12 05:32:05:INFO:	Num examples = 100
2022-01-12 05:32:05:INFO:	RMSE = 27.9723
2022-01-12 05:32:05:INFO:==> Minimal valid RMSE!
2022-01-12 05:32:05:INFO:Save model to cnn2dmodels/data-1_n_epochs-5_aug-150_noise-0.01_supportSize-2_innerSteps-2_lrMeta-0.001_lrInner-0.0001_warmUp-0.0_seed-128...
2022-01-12 05:32:06:INFO:Epoch: 1	 global_step: 750/3750	 lr: 0.00080	 loss: 0.0015
2022-01-12 05:32:56:INFO:Epoch: 1	 global_step: 800/3750	 lr: 0.00079	 loss: 0.0017
2022-01-12 05:33:46:INFO:Epoch: 1	 global_step: 850/3750	 lr: 0.00077	 loss: 0.0014
2022-01-12 05:34:35:INFO:Epoch: 1	 global_step: 900/3750	 lr: 0.00076	 loss: 0.0013
2022-01-12 05:35:25:INFO:Epoch: 1	 global_step: 950/3750	 lr: 0.00075	 loss: 0.0019
2022-01-12 05:36:14:INFO:Epoch: 1	 global_step: 1000/3750	 lr: 0.00073	 loss: 0.0020
2022-01-12 05:37:04:INFO:Epoch: 1	 global_step: 1050/3750	 lr: 0.00072	 loss: 0.0013
2022-01-12 05:37:54:INFO:Epoch: 1	 global_step: 1100/3750	 lr: 0.00071	 loss: 0.0014
2022-01-12 05:38:45:INFO:Epoch: 1	 global_step: 1150/3750	 lr: 0.00069	 loss: 0.0012
2022-01-12 05:39:35:INFO:Epoch: 1	 global_step: 1200/3750	 lr: 0.00068	 loss: 0.0011
2022-01-12 05:40:24:INFO:Epoch: 1	 global_step: 1250/3750	 lr: 0.00067	 loss: 0.0010
2022-01-12 05:41:14:INFO:Epoch: 1	 global_step: 1300/3750	 lr: 0.00065	 loss: 0.0011
2022-01-12 05:42:04:INFO:Epoch: 1	 global_step: 1350/3750	 lr: 0.00064	 loss: 0.0010
2022-01-12 05:42:53:INFO:Epoch: 1	 global_step: 1400/3750	 lr: 0.00063	 loss: 0.0009
2022-01-12 05:43:43:INFO:Epoch: 1	 global_step: 1450/3750	 lr: 0.00061	 loss: 0.0009
2022-01-12 05:44:36:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-12 05:44:36:INFO:	Num examples = 100
2022-01-12 05:44:36:INFO:	RMSE = 14.6861
2022-01-12 05:44:41:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-12 05:44:41:INFO:	Num examples = 100
2022-01-12 05:44:41:INFO:	RMSE = 30.2122
2022-01-12 05:44:42:INFO:Epoch: 2	 global_step: 1500/3750	 lr: 0.00060	 loss: 0.0009
2022-01-12 05:45:32:INFO:Epoch: 2	 global_step: 1550/3750	 lr: 0.00059	 loss: 0.0008
2022-01-12 05:46:21:INFO:Epoch: 2	 global_step: 1600/3750	 lr: 0.00057	 loss: 0.0009
2022-01-12 05:47:11:INFO:Epoch: 2	 global_step: 1650/3750	 lr: 0.00056	 loss: 0.0008
2022-01-12 05:48:01:INFO:Epoch: 2	 global_step: 1700/3750	 lr: 0.00055	 loss: 0.0009
2022-01-12 05:48:51:INFO:Epoch: 2	 global_step: 1750/3750	 lr: 0.00053	 loss: 0.0007
2022-01-12 05:49:40:INFO:Epoch: 2	 global_step: 1800/3750	 lr: 0.00052	 loss: 0.0007
2022-01-12 05:50:30:INFO:Epoch: 2	 global_step: 1850/3750	 lr: 0.00051	 loss: 0.0007
2022-01-12 05:51:20:INFO:Epoch: 2	 global_step: 1900/3750	 lr: 0.00049	 loss: 0.0008
2022-01-12 05:52:10:INFO:Epoch: 2	 global_step: 1950/3750	 lr: 0.00048	 loss: 0.0007
2022-01-12 05:53:00:INFO:Epoch: 2	 global_step: 2000/3750	 lr: 0.00047	 loss: 0.0007
2022-01-12 05:53:49:INFO:Epoch: 2	 global_step: 2050/3750	 lr: 0.00045	 loss: 0.0007
2022-01-12 05:54:39:INFO:Epoch: 2	 global_step: 2100/3750	 lr: 0.00044	 loss: 0.0006
2022-01-12 05:55:29:INFO:Epoch: 2	 global_step: 2150/3750	 lr: 0.00043	 loss: 0.0006
2022-01-12 05:56:19:INFO:Epoch: 2	 global_step: 2200/3750	 lr: 0.00041	 loss: 0.0006
2022-01-12 05:57:12:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-12 05:57:12:INFO:	Num examples = 100
2022-01-12 05:57:12:INFO:	RMSE = 17.4614
2022-01-12 05:57:17:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-12 05:57:17:INFO:	Num examples = 100
2022-01-12 05:57:17:INFO:	RMSE = 24.0902
2022-01-12 05:57:17:INFO:==> Minimal valid RMSE!
2022-01-12 05:57:17:INFO:Save model to cnn2dmodels/data-1_n_epochs-5_aug-150_noise-0.01_supportSize-2_innerSteps-2_lrMeta-0.001_lrInner-0.0001_warmUp-0.0_seed-128...
2022-01-12 05:57:18:INFO:Epoch: 3	 global_step: 2250/3750	 lr: 0.00040	 loss: 0.0005
2022-01-12 05:58:08:INFO:Epoch: 3	 global_step: 2300/3750	 lr: 0.00039	 loss: 0.0006
2022-01-12 05:58:58:INFO:Epoch: 3	 global_step: 2350/3750	 lr: 0.00037	 loss: 0.0005
2022-01-12 05:59:48:INFO:Epoch: 3	 global_step: 2400/3750	 lr: 0.00036	 loss: 0.0005
2022-01-12 06:00:38:INFO:Epoch: 3	 global_step: 2450/3750	 lr: 0.00035	 loss: 0.0005
2022-01-12 06:01:28:INFO:Epoch: 3	 global_step: 2500/3750	 lr: 0.00033	 loss: 0.0005
2022-01-12 06:02:18:INFO:Epoch: 3	 global_step: 2550/3750	 lr: 0.00032	 loss: 0.0004
2022-01-12 06:03:08:INFO:Epoch: 3	 global_step: 2600/3750	 lr: 0.00031	 loss: 0.0005
2022-01-12 06:03:58:INFO:Epoch: 3	 global_step: 2650/3750	 lr: 0.00029	 loss: 0.0004
2022-01-12 06:04:48:INFO:Epoch: 3	 global_step: 2700/3750	 lr: 0.00028	 loss: 0.0004
2022-01-12 06:05:38:INFO:Epoch: 3	 global_step: 2750/3750	 lr: 0.00027	 loss: 0.0005
2022-01-12 06:06:28:INFO:Epoch: 3	 global_step: 2800/3750	 lr: 0.00025	 loss: 0.0004
2022-01-12 06:07:18:INFO:Epoch: 3	 global_step: 2850/3750	 lr: 0.00024	 loss: 0.0004
2022-01-12 06:08:07:INFO:Epoch: 3	 global_step: 2900/3750	 lr: 0.00023	 loss: 0.0004
2022-01-12 06:08:57:INFO:Epoch: 3	 global_step: 2950/3750	 lr: 0.00021	 loss: 0.0004
2022-01-12 06:09:51:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-12 06:09:51:INFO:	Num examples = 100
2022-01-12 06:09:51:INFO:	RMSE = 15.3601
2022-01-12 06:09:55:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-12 06:09:55:INFO:	Num examples = 100
2022-01-12 06:09:55:INFO:	RMSE = 25.7713
2022-01-12 06:09:56:INFO:Epoch: 4	 global_step: 3000/3750	 lr: 0.00020	 loss: 0.0004
2022-01-12 06:10:46:INFO:Epoch: 4	 global_step: 3050/3750	 lr: 0.00019	 loss: 0.0004
2022-01-12 06:11:36:INFO:Epoch: 4	 global_step: 3100/3750	 lr: 0.00017	 loss: 0.0004
2022-01-12 06:12:26:INFO:Epoch: 4	 global_step: 3150/3750	 lr: 0.00016	 loss: 0.0004
2022-01-12 06:13:15:INFO:Epoch: 4	 global_step: 3200/3750	 lr: 0.00015	 loss: 0.0004
2022-01-12 06:14:05:INFO:Epoch: 4	 global_step: 3250/3750	 lr: 0.00013	 loss: 0.0004
2022-01-12 06:14:54:INFO:Epoch: 4	 global_step: 3300/3750	 lr: 0.00012	 loss: 0.0004
2022-01-12 06:15:44:INFO:Epoch: 4	 global_step: 3350/3750	 lr: 0.00011	 loss: 0.0004
2022-01-12 06:16:34:INFO:Epoch: 4	 global_step: 3400/3750	 lr: 0.00009	 loss: 0.0004
2022-01-12 06:17:24:INFO:Epoch: 4	 global_step: 3450/3750	 lr: 0.00008	 loss: 0.0004
2022-01-12 06:18:14:INFO:Epoch: 4	 global_step: 3500/3750	 lr: 0.00007	 loss: 0.0004
2022-01-12 06:19:04:INFO:Epoch: 4	 global_step: 3550/3750	 lr: 0.00005	 loss: 0.0004
2022-01-12 06:19:54:INFO:Epoch: 4	 global_step: 3600/3750	 lr: 0.00004	 loss: 0.0005
2022-01-12 06:20:44:INFO:Epoch: 4	 global_step: 3650/3750	 lr: 0.00003	 loss: 0.0005
2022-01-12 06:21:34:INFO:Epoch: 4	 global_step: 3700/3750	 lr: 0.00001	 loss: 0.0004
2022-01-12 06:22:28:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-12 06:22:28:INFO:	Num examples = 100
2022-01-12 06:22:28:INFO:	RMSE = 13.5414
2022-01-12 06:22:33:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-12 06:22:33:INFO:	Num examples = 100
2022-01-12 06:22:33:INFO:	RMSE = 32.2087
2022-01-12 06:22:33:INFO:	Output TEST RMSE:	17.4614
2022-01-12 06:22:33:INFO:	VALID RMSEs:	27.9723	30.2122	24.0902	25.7713	32.2087
2022-01-12 06:22:33:INFO:	TEST RMSEs:	22.8605	14.6861	17.4614	15.3601	13.5414
!!! Reset batch info !!! mode: [TRAIN]
!!! Reset batch info !!! mode: [TEST]
!!! Reset batch info !!! mode: [VALID]
!!! Reset batch info !!! mode: [TRAIN]
!!! Reset batch info !!! mode: [TEST]
!!! Reset batch info !!! mode: [VALID]
!!! Reset batch info !!! mode: [TRAIN]
!!! Reset batch info !!! mode: [TEST]
!!! Reset batch info !!! mode: [VALID]
!!! Reset batch info !!! mode: [TRAIN]
!!! Reset batch info !!! mode: [TEST]
!!! Reset batch info !!! mode: [VALID]
2022-01-12 06:22:36:INFO:Finish setting logger...
2022-01-12 06:22:36:INFO:==> Training/Evaluation parameters are:
2022-01-12 06:22:36:INFO:	Namespace(model_dir='cnn2dmodels/data-1_n_epochs-5_aug-150_noise-0.01_supportSize-2_innerSteps-2_lrMeta-0.001_lrInner-0.001_warmUp-0.0_seed-128'
2022-01-12 06:22:36:INFO:	data_fn=1
2022-01-12 06:22:36:INFO:	datatest_fn=1
2022-01-12 06:22:36:INFO:	filter_kernel_size=1
2022-01-12 06:22:36:INFO:	override_data_cache=False
2022-01-12 06:22:36:INFO:	maxRUL=125
2022-01-12 06:22:36:INFO:	low_ratio=0.1
2022-01-12 06:22:36:INFO:	high_ratio=0.99
2022-01-12 06:22:36:INFO:	aug_ratio=150
2022-01-12 06:22:36:INFO:	noise_amplitude=0.01
2022-01-12 06:22:36:INFO:	modeltype='cnn2d'
2022-01-12 06:22:36:INFO:	max_seq_len=550
2022-01-12 06:22:36:INFO:	d_model=128
2022-01-12 06:22:36:INFO:	p_dropout=0.1
2022-01-12 06:22:36:INFO:	n_head=4
2022-01-12 06:22:36:INFO:	n_layer=2
2022-01-12 06:22:36:INFO:	dim_feedforward=512
2022-01-12 06:22:36:INFO:	e_dropout=0.1
2022-01-12 06:22:36:INFO:	activation='relu'
2022-01-12 06:22:36:INFO:	layer_norm=False
2022-01-12 06:22:36:INFO:	support_size=2
2022-01-12 06:22:36:INFO:	inner_steps=2
2022-01-12 06:22:36:INFO:	lr_inner=0.001
2022-01-12 06:22:36:INFO:	lr_meta=0.001
2022-01-12 06:22:36:INFO:	n_epochs=5
2022-01-12 06:22:36:INFO:	train_batch_size=20
2022-01-12 06:22:36:INFO:	eval_batch_size=1
2022-01-12 06:22:36:INFO:	lr=0.001
2022-01-12 06:22:36:INFO:	weight_decay=0.01
2022-01-12 06:22:36:INFO:	warmup_ratio=0.0
2022-01-12 06:22:36:INFO:	max_grad_norm=5.0
2022-01-12 06:22:36:INFO:	logging_steps=50
2022-01-12 06:22:36:INFO:	seed=128
2022-01-12 06:22:36:INFO:	gpu_id=2
2022-01-12 06:22:36:INFO:	do_train=True
2022-01-12 06:22:36:INFO:	do_eval=False
2022-01-12 06:22:36:INFO:	train_data_fn='data/train_FD001.txt'
2022-01-12 06:22:36:INFO:	test_data_fn='data/test_FD001.txt'
2022-01-12 06:22:36:INFO:	target_ruls_fn='data/RUL_FD001.txt'
2022-01-12 06:22:36:INFO:	device=device(type='cuda'))
2022-01-12 06:22:36:INFO:Dump arguments to cnn2dmodels/data-1_n_epochs-5_aug-150_noise-0.01_supportSize-2_innerSteps-2_lrMeta-0.001_lrInner-0.001_warmUp-0.0_seed-128...
2022-01-12 06:22:36:INFO:==> Read data from data/train_FD001.txt...
2022-01-12 06:22:36:INFO:	The selected feature idxs are: 0, 1, 4, 5, 6, 9, 10, 11, 13, 14, 15, 16, 17, 19, 22, 23
2022-01-12 06:22:36:INFO:==> Min_max normalization...
2022-01-12 06:22:36:INFO:	The min value is [-0.008700000122189522, -0.0006000000284984708, 641.2100219726562, 1571.0400390625, 1382.25, 549.8499755859375, 2387.89990234375, 9021.73046875, 46.849998474121094, 518.6900024414062, 2387.8798828125, 8099.93994140625, 8.324899673461914, 388.0, 38.13999938964844, 22.89419937133789]
2022-01-12 06:22:36:INFO:	The max value is [0.008700000122189522, 0.0006000000284984708, 644.530029296875, 1616.9100341796875, 1441.489990234375, 556.0599975585938, 2388.56005859375, 9244.58984375, 48.529998779296875, 523.3800048828125, 2388.56005859375, 8293.7197265625, 8.584799766540527, 400.0, 39.43000030517578, 23.61840057373047]
2022-01-12 06:22:36:INFO:==> Read data from data/test_FD001.txt...
2022-01-12 06:22:36:INFO:	The selected feature idxs are: 0, 1, 4, 5, 6, 9, 10, 11, 13, 14, 15, 16, 17, 19, 22, 23
2022-01-12 06:22:37:INFO:==> Read RULsfrom data/RUL_FD001.txt...
2022-01-12 06:22:37:INFO:	min_rul: 7, max_rul: 145
2022-01-12 06:22:37:INFO:==> Input length ratio of the [TEST] data:
2022-01-12 06:22:37:INFO:	min_ratio = 0.2067
2022-01-12 06:22:37:INFO:	max_ratio = 0.9667
2022-01-12 06:22:37:INFO:==> Min_max normalization...
2022-01-12 06:22:37:INFO:	With given min value [-0.008700000122189522, -0.0006000000284984708, 641.2100219726562, 1571.0400390625, 1382.25, 549.8499755859375, 2387.89990234375, 9021.73046875, 46.849998474121094, 518.6900024414062, 2387.8798828125, 8099.93994140625, 8.324899673461914, 388.0, 38.13999938964844, 22.89419937133789]
2022-01-12 06:22:37:INFO:	With given max value [0.008700000122189522, 0.0006000000284984708, 644.530029296875, 1616.9100341796875, 1441.489990234375, 556.0599975585938, 2388.56005859375, 9244.58984375, 48.529998779296875, 523.3800048828125, 2388.56005859375, 8293.7197265625, 8.584799766540527, 400.0, 39.43000030517578, 23.61840057373047]
2022-01-12 06:22:37:INFO:==> Computing Criterion...
2022-01-12 06:22:37:INFO:	The weights are: 0.007887763902544975, 0.008001004345715046, 0.06667434424161911, 0.0634712353348732, 0.07656104862689972, 0.0755249634385109, 0.06726357340812683, 0.0644979178905487, 0.0795108750462532, 0.07743842899799347, 0.0671684592962265, 0.06869389116764069, 0.07147877663373947, 0.06516212970018387, 0.07012488692998886, 0.07054071873426437
2022-01-12 06:22:44:INFO:Note: NumExpr detected 40 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2022-01-12 06:22:44:INFO:NumExpr defaulting to 8 threads.
2022-01-12 06:22:44:INFO:=============== Scheme: Meta Learning ===============
2022-01-12 06:22:44:INFO:	Num examples = 15000
2022-01-12 06:22:44:INFO:	Num epochs = 5
2022-01-12 06:22:44:INFO:	Batch size = 20
2022-01-12 06:22:44:INFO:	Total meta optimization steps = 3750
2022-01-12 06:22:44:INFO:	Total inner optimization steps = 7500
2022-01-12 06:22:50:INFO:==> Group parameters for optimization...
2022-01-12 06:22:50:INFO:    Parameters to update are:
2022-01-12 06:22:50:INFO:	conv1.0.weight
2022-01-12 06:22:50:INFO:	conv2.0.weight
2022-01-12 06:22:50:INFO:	conv3.0.weight
2022-01-12 06:22:50:INFO:	conv4.0.weight
2022-01-12 06:22:50:INFO:	conv5.0.weight
2022-01-12 06:22:50:INFO:	fc_1.0.weight
2022-01-12 06:22:50:INFO:	fc_1.0.bias
2022-01-12 06:22:50:INFO:	fc_2.weight
2022-01-12 06:22:50:INFO:	fc_2.bias
/data/moy20/Meta-Learning/Meta-prognosis-main/optimizer.py:78: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448255797/work/torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
/data/moy20/miniconda3/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
2022-01-12 06:22:52:INFO:Epoch: 0	 global_step: 0/3750	 lr: 0.00100	 loss: 0.0011
2022-01-12 06:23:42:INFO:Epoch: 0	 global_step: 50/3750	 lr: 0.00099	 loss: 0.0219
2022-01-12 06:24:31:INFO:Epoch: 0	 global_step: 100/3750	 lr: 0.00097	 loss: 0.0084
2022-01-12 06:25:20:INFO:Epoch: 0	 global_step: 150/3750	 lr: 0.00096	 loss: 0.0052
2022-01-12 06:26:09:INFO:Epoch: 0	 global_step: 200/3750	 lr: 0.00095	 loss: 0.0047
2022-01-12 06:26:58:INFO:Epoch: 0	 global_step: 250/3750	 lr: 0.00093	 loss: 0.0042
2022-01-12 06:27:46:INFO:Epoch: 0	 global_step: 300/3750	 lr: 0.00092	 loss: 0.0046
2022-01-12 06:28:35:INFO:Epoch: 0	 global_step: 350/3750	 lr: 0.00091	 loss: 0.0033
2022-01-12 06:29:25:INFO:Epoch: 0	 global_step: 400/3750	 lr: 0.00089	 loss: 0.0027
2022-01-12 06:30:14:INFO:Epoch: 0	 global_step: 450/3750	 lr: 0.00088	 loss: 0.0030
2022-01-12 06:31:03:INFO:Epoch: 0	 global_step: 500/3750	 lr: 0.00087	 loss: 0.0024
2022-01-12 06:31:53:INFO:Epoch: 0	 global_step: 550/3750	 lr: 0.00085	 loss: 0.0021
2022-01-12 06:32:42:INFO:Epoch: 0	 global_step: 600/3750	 lr: 0.00084	 loss: 0.0019
2022-01-12 06:33:32:INFO:Epoch: 0	 global_step: 650/3750	 lr: 0.00083	 loss: 0.0015
2022-01-12 06:34:21:INFO:Epoch: 0	 global_step: 700/3750	 lr: 0.00081	 loss: 0.0016
2022-01-12 06:35:14:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-12 06:35:14:INFO:	Num examples = 100
2022-01-12 06:35:14:INFO:	RMSE = 22.8605
2022-01-12 06:35:19:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-12 06:35:19:INFO:	Num examples = 100
2022-01-12 06:35:19:INFO:	RMSE = 27.9723
2022-01-12 06:35:19:INFO:==> Minimal valid RMSE!
2022-01-12 06:35:19:INFO:Save model to cnn2dmodels/data-1_n_epochs-5_aug-150_noise-0.01_supportSize-2_innerSteps-2_lrMeta-0.001_lrInner-0.001_warmUp-0.0_seed-128...
2022-01-12 06:35:20:INFO:Epoch: 1	 global_step: 750/3750	 lr: 0.00080	 loss: 0.0015
2022-01-12 06:36:08:INFO:Epoch: 1	 global_step: 800/3750	 lr: 0.00079	 loss: 0.0017
2022-01-12 06:36:58:INFO:Epoch: 1	 global_step: 850/3750	 lr: 0.00077	 loss: 0.0014
2022-01-12 06:37:48:INFO:Epoch: 1	 global_step: 900/3750	 lr: 0.00076	 loss: 0.0013
2022-01-12 06:38:37:INFO:Epoch: 1	 global_step: 950/3750	 lr: 0.00075	 loss: 0.0019
2022-01-12 06:39:26:INFO:Epoch: 1	 global_step: 1000/3750	 lr: 0.00073	 loss: 0.0020
2022-01-12 06:40:15:INFO:Epoch: 1	 global_step: 1050/3750	 lr: 0.00072	 loss: 0.0013
2022-01-12 06:41:04:INFO:Epoch: 1	 global_step: 1100/3750	 lr: 0.00071	 loss: 0.0014
2022-01-12 06:41:53:INFO:Epoch: 1	 global_step: 1150/3750	 lr: 0.00069	 loss: 0.0012
2022-01-12 06:42:43:INFO:Epoch: 1	 global_step: 1200/3750	 lr: 0.00068	 loss: 0.0011
2022-01-12 06:43:32:INFO:Epoch: 1	 global_step: 1250/3750	 lr: 0.00067	 loss: 0.0010
2022-01-12 06:44:21:INFO:Epoch: 1	 global_step: 1300/3750	 lr: 0.00065	 loss: 0.0011
2022-01-12 06:45:10:INFO:Epoch: 1	 global_step: 1350/3750	 lr: 0.00064	 loss: 0.0010
2022-01-12 06:45:59:INFO:Epoch: 1	 global_step: 1400/3750	 lr: 0.00063	 loss: 0.0009
2022-01-12 06:46:48:INFO:Epoch: 1	 global_step: 1450/3750	 lr: 0.00061	 loss: 0.0009
2022-01-12 06:47:41:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-12 06:47:41:INFO:	Num examples = 100
2022-01-12 06:47:41:INFO:	RMSE = 14.6861
2022-01-12 06:47:46:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-12 06:47:46:INFO:	Num examples = 100
2022-01-12 06:47:46:INFO:	RMSE = 30.2122
2022-01-12 06:47:47:INFO:Epoch: 2	 global_step: 1500/3750	 lr: 0.00060	 loss: 0.0009
2022-01-12 06:48:36:INFO:Epoch: 2	 global_step: 1550/3750	 lr: 0.00059	 loss: 0.0008
2022-01-12 06:49:25:INFO:Epoch: 2	 global_step: 1600/3750	 lr: 0.00057	 loss: 0.0009
2022-01-12 06:50:14:INFO:Epoch: 2	 global_step: 1650/3750	 lr: 0.00056	 loss: 0.0008
2022-01-12 06:51:03:INFO:Epoch: 2	 global_step: 1700/3750	 lr: 0.00055	 loss: 0.0009
2022-01-12 06:51:51:INFO:Epoch: 2	 global_step: 1750/3750	 lr: 0.00053	 loss: 0.0007
2022-01-12 06:52:41:INFO:Epoch: 2	 global_step: 1800/3750	 lr: 0.00052	 loss: 0.0007
2022-01-12 06:53:30:INFO:Epoch: 2	 global_step: 1850/3750	 lr: 0.00051	 loss: 0.0007
2022-01-12 06:54:20:INFO:Epoch: 2	 global_step: 1900/3750	 lr: 0.00049	 loss: 0.0008
2022-01-12 06:55:09:INFO:Epoch: 2	 global_step: 1950/3750	 lr: 0.00048	 loss: 0.0007
2022-01-12 06:55:58:INFO:Epoch: 2	 global_step: 2000/3750	 lr: 0.00047	 loss: 0.0007
2022-01-12 06:56:47:INFO:Epoch: 2	 global_step: 2050/3750	 lr: 0.00045	 loss: 0.0007
2022-01-12 06:57:36:INFO:Epoch: 2	 global_step: 2100/3750	 lr: 0.00044	 loss: 0.0006
2022-01-12 06:58:25:INFO:Epoch: 2	 global_step: 2150/3750	 lr: 0.00043	 loss: 0.0006
2022-01-12 06:59:15:INFO:Epoch: 2	 global_step: 2200/3750	 lr: 0.00041	 loss: 0.0006
2022-01-12 07:00:08:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-12 07:00:08:INFO:	Num examples = 100
2022-01-12 07:00:08:INFO:	RMSE = 17.4614
2022-01-12 07:00:13:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-12 07:00:13:INFO:	Num examples = 100
2022-01-12 07:00:13:INFO:	RMSE = 24.0902
2022-01-12 07:00:13:INFO:==> Minimal valid RMSE!
2022-01-12 07:00:13:INFO:Save model to cnn2dmodels/data-1_n_epochs-5_aug-150_noise-0.01_supportSize-2_innerSteps-2_lrMeta-0.001_lrInner-0.001_warmUp-0.0_seed-128...
2022-01-12 07:00:14:INFO:Epoch: 3	 global_step: 2250/3750	 lr: 0.00040	 loss: 0.0005
2022-01-12 07:01:03:INFO:Epoch: 3	 global_step: 2300/3750	 lr: 0.00039	 loss: 0.0006
2022-01-12 07:01:52:INFO:Epoch: 3	 global_step: 2350/3750	 lr: 0.00037	 loss: 0.0005
2022-01-12 07:02:41:INFO:Epoch: 3	 global_step: 2400/3750	 lr: 0.00036	 loss: 0.0005
2022-01-12 07:03:31:INFO:Epoch: 3	 global_step: 2450/3750	 lr: 0.00035	 loss: 0.0005
2022-01-12 07:04:20:INFO:Epoch: 3	 global_step: 2500/3750	 lr: 0.00033	 loss: 0.0005
2022-01-12 07:05:09:INFO:Epoch: 3	 global_step: 2550/3750	 lr: 0.00032	 loss: 0.0004
2022-01-12 07:05:58:INFO:Epoch: 3	 global_step: 2600/3750	 lr: 0.00031	 loss: 0.0005
2022-01-12 07:06:47:INFO:Epoch: 3	 global_step: 2650/3750	 lr: 0.00029	 loss: 0.0004
2022-01-12 07:07:37:INFO:Epoch: 3	 global_step: 2700/3750	 lr: 0.00028	 loss: 0.0004
2022-01-12 07:08:26:INFO:Epoch: 3	 global_step: 2750/3750	 lr: 0.00027	 loss: 0.0005
2022-01-12 07:09:15:INFO:Epoch: 3	 global_step: 2800/3750	 lr: 0.00025	 loss: 0.0004
2022-01-12 07:10:04:INFO:Epoch: 3	 global_step: 2850/3750	 lr: 0.00024	 loss: 0.0004
2022-01-12 07:10:53:INFO:Epoch: 3	 global_step: 2900/3750	 lr: 0.00023	 loss: 0.0004
2022-01-12 07:11:42:INFO:Epoch: 3	 global_step: 2950/3750	 lr: 0.00021	 loss: 0.0004
2022-01-12 07:12:35:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-12 07:12:35:INFO:	Num examples = 100
2022-01-12 07:12:35:INFO:	RMSE = 15.3601
2022-01-12 07:12:40:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-12 07:12:40:INFO:	Num examples = 100
2022-01-12 07:12:40:INFO:	RMSE = 25.7713
2022-01-12 07:12:41:INFO:Epoch: 4	 global_step: 3000/3750	 lr: 0.00020	 loss: 0.0004
2022-01-12 07:13:30:INFO:Epoch: 4	 global_step: 3050/3750	 lr: 0.00019	 loss: 0.0004
2022-01-12 07:14:20:INFO:Epoch: 4	 global_step: 3100/3750	 lr: 0.00017	 loss: 0.0004
2022-01-12 07:15:09:INFO:Epoch: 4	 global_step: 3150/3750	 lr: 0.00016	 loss: 0.0004
2022-01-12 07:16:06:INFO:Epoch: 4	 global_step: 3200/3750	 lr: 0.00015	 loss: 0.0004
2022-01-12 07:17:20:INFO:Epoch: 4	 global_step: 3250/3750	 lr: 0.00013	 loss: 0.0004
2022-01-12 07:18:34:INFO:Epoch: 4	 global_step: 3300/3750	 lr: 0.00012	 loss: 0.0004
2022-01-12 07:19:48:INFO:Epoch: 4	 global_step: 3350/3750	 lr: 0.00011	 loss: 0.0004
2022-01-12 07:21:03:INFO:Epoch: 4	 global_step: 3400/3750	 lr: 0.00009	 loss: 0.0004
2022-01-12 07:22:18:INFO:Epoch: 4	 global_step: 3450/3750	 lr: 0.00008	 loss: 0.0004
2022-01-12 07:23:32:INFO:Epoch: 4	 global_step: 3500/3750	 lr: 0.00007	 loss: 0.0004
2022-01-12 07:24:47:INFO:Epoch: 4	 global_step: 3550/3750	 lr: 0.00005	 loss: 0.0004
2022-01-12 07:26:01:INFO:Epoch: 4	 global_step: 3600/3750	 lr: 0.00004	 loss: 0.0005
2022-01-12 07:27:15:INFO:Epoch: 4	 global_step: 3650/3750	 lr: 0.00003	 loss: 0.0005
2022-01-12 07:28:30:INFO:Epoch: 4	 global_step: 3700/3750	 lr: 0.00001	 loss: 0.0004
2022-01-12 07:29:50:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-12 07:29:50:INFO:	Num examples = 100
2022-01-12 07:29:50:INFO:	RMSE = 13.5414
2022-01-12 07:29:57:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-12 07:29:57:INFO:	Num examples = 100
2022-01-12 07:29:57:INFO:	RMSE = 32.2087
2022-01-12 07:29:57:INFO:	Output TEST RMSE:	17.4614
2022-01-12 07:29:57:INFO:	VALID RMSEs:	27.9723	30.2122	24.0902	25.7713	32.2087
2022-01-12 07:29:57:INFO:	TEST RMSEs:	22.8605	14.6861	17.4614	15.3601	13.5414
!!! Reset batch info !!! mode: [TRAIN]
!!! Reset batch info !!! mode: [TEST]
!!! Reset batch info !!! mode: [VALID]
!!! Reset batch info !!! mode: [TRAIN]
!!! Reset batch info !!! mode: [TEST]
!!! Reset batch info !!! mode: [VALID]
!!! Reset batch info !!! mode: [TRAIN]
!!! Reset batch info !!! mode: [TEST]
!!! Reset batch info !!! mode: [VALID]
!!! Reset batch info !!! mode: [TRAIN]
!!! Reset batch info !!! mode: [TEST]
!!! Reset batch info !!! mode: [VALID]
2022-01-12 07:30:01:INFO:Finish setting logger...
2022-01-12 07:30:01:INFO:==> Training/Evaluation parameters are:
2022-01-12 07:30:01:INFO:	Namespace(model_dir='cnn2dmodels/data-1_n_epochs-5_aug-150_noise-0.01_supportSize-5_innerSteps-2_lrMeta-0.001_lrInner-0.0001_warmUp-0.0_seed-128'
2022-01-12 07:30:01:INFO:	data_fn=1
2022-01-12 07:30:01:INFO:	datatest_fn=1
2022-01-12 07:30:01:INFO:	filter_kernel_size=1
2022-01-12 07:30:01:INFO:	override_data_cache=False
2022-01-12 07:30:01:INFO:	maxRUL=125
2022-01-12 07:30:01:INFO:	low_ratio=0.1
2022-01-12 07:30:01:INFO:	high_ratio=0.99
2022-01-12 07:30:01:INFO:	aug_ratio=150
2022-01-12 07:30:01:INFO:	noise_amplitude=0.01
2022-01-12 07:30:01:INFO:	modeltype='cnn2d'
2022-01-12 07:30:01:INFO:	max_seq_len=550
2022-01-12 07:30:01:INFO:	d_model=128
2022-01-12 07:30:01:INFO:	p_dropout=0.1
2022-01-12 07:30:01:INFO:	n_head=4
2022-01-12 07:30:01:INFO:	n_layer=2
2022-01-12 07:30:01:INFO:	dim_feedforward=512
2022-01-12 07:30:01:INFO:	e_dropout=0.1
2022-01-12 07:30:01:INFO:	activation='relu'
2022-01-12 07:30:01:INFO:	layer_norm=False
2022-01-12 07:30:01:INFO:	support_size=5
2022-01-12 07:30:01:INFO:	inner_steps=2
2022-01-12 07:30:01:INFO:	lr_inner=0.0001
2022-01-12 07:30:01:INFO:	lr_meta=0.001
2022-01-12 07:30:01:INFO:	n_epochs=5
2022-01-12 07:30:01:INFO:	train_batch_size=20
2022-01-12 07:30:01:INFO:	eval_batch_size=1
2022-01-12 07:30:01:INFO:	lr=0.001
2022-01-12 07:30:01:INFO:	weight_decay=0.01
2022-01-12 07:30:01:INFO:	warmup_ratio=0.0
2022-01-12 07:30:01:INFO:	max_grad_norm=5.0
2022-01-12 07:30:01:INFO:	logging_steps=50
2022-01-12 07:30:01:INFO:	seed=128
2022-01-12 07:30:01:INFO:	gpu_id=2
2022-01-12 07:30:01:INFO:	do_train=True
2022-01-12 07:30:01:INFO:	do_eval=False
2022-01-12 07:30:01:INFO:	train_data_fn='data/train_FD001.txt'
2022-01-12 07:30:01:INFO:	test_data_fn='data/test_FD001.txt'
2022-01-12 07:30:01:INFO:	target_ruls_fn='data/RUL_FD001.txt'
2022-01-12 07:30:01:INFO:	device=device(type='cuda'))
2022-01-12 07:30:01:INFO:Dump arguments to cnn2dmodels/data-1_n_epochs-5_aug-150_noise-0.01_supportSize-5_innerSteps-2_lrMeta-0.001_lrInner-0.0001_warmUp-0.0_seed-128...
2022-01-12 07:30:01:INFO:==> Read data from data/train_FD001.txt...
2022-01-12 07:30:01:INFO:	The selected feature idxs are: 0, 1, 4, 5, 6, 9, 10, 11, 13, 14, 15, 16, 17, 19, 22, 23
2022-01-12 07:30:01:INFO:==> Min_max normalization...
2022-01-12 07:30:01:INFO:	The min value is [-0.008700000122189522, -0.0006000000284984708, 641.2100219726562, 1571.0400390625, 1382.25, 549.8499755859375, 2387.89990234375, 9021.73046875, 46.849998474121094, 518.6900024414062, 2387.8798828125, 8099.93994140625, 8.324899673461914, 388.0, 38.13999938964844, 22.89419937133789]
2022-01-12 07:30:01:INFO:	The max value is [0.008700000122189522, 0.0006000000284984708, 644.530029296875, 1616.9100341796875, 1441.489990234375, 556.0599975585938, 2388.56005859375, 9244.58984375, 48.529998779296875, 523.3800048828125, 2388.56005859375, 8293.7197265625, 8.584799766540527, 400.0, 39.43000030517578, 23.61840057373047]
2022-01-12 07:30:01:INFO:==> Read data from data/test_FD001.txt...
2022-01-12 07:30:01:INFO:	The selected feature idxs are: 0, 1, 4, 5, 6, 9, 10, 11, 13, 14, 15, 16, 17, 19, 22, 23
2022-01-12 07:30:01:INFO:==> Read RULsfrom data/RUL_FD001.txt...
2022-01-12 07:30:01:INFO:	min_rul: 7, max_rul: 145
2022-01-12 07:30:01:INFO:==> Input length ratio of the [TEST] data:
2022-01-12 07:30:01:INFO:	min_ratio = 0.2067
2022-01-12 07:30:01:INFO:	max_ratio = 0.9667
2022-01-12 07:30:01:INFO:==> Min_max normalization...
2022-01-12 07:30:01:INFO:	With given min value [-0.008700000122189522, -0.0006000000284984708, 641.2100219726562, 1571.0400390625, 1382.25, 549.8499755859375, 2387.89990234375, 9021.73046875, 46.849998474121094, 518.6900024414062, 2387.8798828125, 8099.93994140625, 8.324899673461914, 388.0, 38.13999938964844, 22.89419937133789]
2022-01-12 07:30:01:INFO:	With given max value [0.008700000122189522, 0.0006000000284984708, 644.530029296875, 1616.9100341796875, 1441.489990234375, 556.0599975585938, 2388.56005859375, 9244.58984375, 48.529998779296875, 523.3800048828125, 2388.56005859375, 8293.7197265625, 8.584799766540527, 400.0, 39.43000030517578, 23.61840057373047]
2022-01-12 07:30:01:INFO:==> Computing Criterion...
2022-01-12 07:30:01:INFO:	The weights are: 0.007887763902544975, 0.008001004345715046, 0.06667434424161911, 0.0634712353348732, 0.07656104862689972, 0.0755249634385109, 0.06726357340812683, 0.0644979178905487, 0.0795108750462532, 0.07743842899799347, 0.0671684592962265, 0.06869389116764069, 0.07147877663373947, 0.06516212970018387, 0.07012488692998886, 0.07054071873426437
2022-01-12 07:30:15:INFO:Note: NumExpr detected 40 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2022-01-12 07:30:15:INFO:NumExpr defaulting to 8 threads.
2022-01-12 07:30:15:INFO:=============== Scheme: Meta Learning ===============
2022-01-12 07:30:15:INFO:	Num examples = 15000
2022-01-12 07:30:15:INFO:	Num epochs = 5
2022-01-12 07:30:15:INFO:	Batch size = 20
2022-01-12 07:30:15:INFO:	Total meta optimization steps = 3750
2022-01-12 07:30:15:INFO:	Total inner optimization steps = 7500
2022-01-12 07:30:22:INFO:==> Group parameters for optimization...
2022-01-12 07:30:22:INFO:    Parameters to update are:
2022-01-12 07:30:22:INFO:	conv1.0.weight
2022-01-12 07:30:22:INFO:	conv2.0.weight
2022-01-12 07:30:22:INFO:	conv3.0.weight
2022-01-12 07:30:22:INFO:	conv4.0.weight
2022-01-12 07:30:22:INFO:	conv5.0.weight
2022-01-12 07:30:22:INFO:	fc_1.0.weight
2022-01-12 07:30:22:INFO:	fc_1.0.bias
2022-01-12 07:30:22:INFO:	fc_2.weight
2022-01-12 07:30:22:INFO:	fc_2.bias
/data/moy20/Meta-Learning/Meta-prognosis-main/optimizer.py:78: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448255797/work/torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
/data/moy20/miniconda3/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
2022-01-12 07:30:26:INFO:Epoch: 0	 global_step: 0/3750	 lr: 0.00100	 loss: 0.0011
2022-01-12 07:31:57:INFO:Epoch: 0	 global_step: 50/3750	 lr: 0.00099	 loss: 0.0256
2022-01-12 07:33:29:INFO:Epoch: 0	 global_step: 100/3750	 lr: 0.00097	 loss: 0.0098
2022-01-12 07:35:00:INFO:Epoch: 0	 global_step: 150/3750	 lr: 0.00096	 loss: 0.0065
2022-01-12 07:36:31:INFO:Epoch: 0	 global_step: 200/3750	 lr: 0.00095	 loss: 0.0050
2022-01-12 07:38:03:INFO:Epoch: 0	 global_step: 250/3750	 lr: 0.00093	 loss: 0.0054
2022-01-12 07:39:34:INFO:Epoch: 0	 global_step: 300/3750	 lr: 0.00092	 loss: 0.0045
2022-01-12 07:41:06:INFO:Epoch: 0	 global_step: 350/3750	 lr: 0.00091	 loss: 0.0036
2022-01-12 07:42:38:INFO:Epoch: 0	 global_step: 400/3750	 lr: 0.00089	 loss: 0.0037
2022-01-12 07:44:09:INFO:Epoch: 0	 global_step: 450/3750	 lr: 0.00088	 loss: 0.0026
2022-01-12 07:45:41:INFO:Epoch: 0	 global_step: 500/3750	 lr: 0.00087	 loss: 0.0027
2022-01-12 07:47:12:INFO:Epoch: 0	 global_step: 550/3750	 lr: 0.00085	 loss: 0.0024
2022-01-12 07:48:43:INFO:Epoch: 0	 global_step: 600/3750	 lr: 0.00084	 loss: 0.0021
2022-01-12 07:50:15:INFO:Epoch: 0	 global_step: 650/3750	 lr: 0.00083	 loss: 0.0017
2022-01-12 07:51:46:INFO:Epoch: 0	 global_step: 700/3750	 lr: 0.00081	 loss: 0.0018
2022-01-12 07:53:25:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-12 07:53:25:INFO:	Num examples = 100
2022-01-12 07:53:25:INFO:	RMSE = 19.8765
2022-01-12 07:53:34:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-12 07:53:34:INFO:	Num examples = 100
2022-01-12 07:53:34:INFO:	RMSE = 34.6558
2022-01-12 07:53:34:INFO:==> Minimal valid RMSE!
2022-01-12 07:53:34:INFO:Save model to cnn2dmodels/data-1_n_epochs-5_aug-150_noise-0.01_supportSize-5_innerSteps-2_lrMeta-0.001_lrInner-0.0001_warmUp-0.0_seed-128...
2022-01-12 07:53:35:INFO:Epoch: 1	 global_step: 750/3750	 lr: 0.00080	 loss: 0.0019
2022-01-12 07:55:07:INFO:Epoch: 1	 global_step: 800/3750	 lr: 0.00079	 loss: 0.0015
2022-01-12 07:56:39:INFO:Epoch: 1	 global_step: 850/3750	 lr: 0.00077	 loss: 0.0029
2022-01-12 07:58:10:INFO:Epoch: 1	 global_step: 900/3750	 lr: 0.00076	 loss: 0.0017
2022-01-12 07:59:42:INFO:Epoch: 1	 global_step: 950/3750	 lr: 0.00075	 loss: 0.0015
2022-01-12 08:01:13:INFO:Epoch: 1	 global_step: 1000/3750	 lr: 0.00073	 loss: 0.0015
2022-01-12 08:02:45:INFO:Epoch: 1	 global_step: 1050/3750	 lr: 0.00072	 loss: 0.0014
2022-01-12 08:04:15:INFO:Epoch: 1	 global_step: 1100/3750	 lr: 0.00071	 loss: 0.0013
2022-01-12 08:05:46:INFO:Epoch: 1	 global_step: 1150/3750	 lr: 0.00069	 loss: 0.0013
2022-01-12 08:07:18:INFO:Epoch: 1	 global_step: 1200/3750	 lr: 0.00068	 loss: 0.0013
2022-01-12 08:08:49:INFO:Epoch: 1	 global_step: 1250/3750	 lr: 0.00067	 loss: 0.0011
2022-01-12 08:10:20:INFO:Epoch: 1	 global_step: 1300/3750	 lr: 0.00065	 loss: 0.0012
2022-01-12 08:11:52:INFO:Epoch: 1	 global_step: 1350/3750	 lr: 0.00064	 loss: 0.0012
2022-01-12 08:13:23:INFO:Epoch: 1	 global_step: 1400/3750	 lr: 0.00063	 loss: 0.0010
2022-01-12 08:14:55:INFO:Epoch: 1	 global_step: 1450/3750	 lr: 0.00061	 loss: 0.0011
2022-01-12 08:16:33:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-12 08:16:33:INFO:	Num examples = 100
2022-01-12 08:16:33:INFO:	RMSE = 17.0393
2022-01-12 08:16:42:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-12 08:16:42:INFO:	Num examples = 100
2022-01-12 08:16:42:INFO:	RMSE = 37.5380
2022-01-12 08:16:44:INFO:Epoch: 2	 global_step: 1500/3750	 lr: 0.00060	 loss: 0.0010
2022-01-12 08:18:15:INFO:Epoch: 2	 global_step: 1550/3750	 lr: 0.00059	 loss: 0.0010
2022-01-12 08:19:46:INFO:Epoch: 2	 global_step: 1600/3750	 lr: 0.00057	 loss: 0.0011
2022-01-12 08:21:17:INFO:Epoch: 2	 global_step: 1650/3750	 lr: 0.00056	 loss: 0.0011
2022-01-12 08:22:48:INFO:Epoch: 2	 global_step: 1700/3750	 lr: 0.00055	 loss: 0.0010
2022-01-12 08:24:19:INFO:Epoch: 2	 global_step: 1750/3750	 lr: 0.00053	 loss: 0.0009
2022-01-12 08:25:50:INFO:Epoch: 2	 global_step: 1800/3750	 lr: 0.00052	 loss: 0.0010
2022-01-12 08:27:21:INFO:Epoch: 2	 global_step: 1850/3750	 lr: 0.00051	 loss: 0.0009
2022-01-12 08:28:53:INFO:Epoch: 2	 global_step: 1900/3750	 lr: 0.00049	 loss: 0.0009
2022-01-12 08:30:24:INFO:Epoch: 2	 global_step: 1950/3750	 lr: 0.00048	 loss: 0.0009
2022-01-12 08:31:55:INFO:Epoch: 2	 global_step: 2000/3750	 lr: 0.00047	 loss: 0.0008
2022-01-12 08:33:26:INFO:Epoch: 2	 global_step: 2050/3750	 lr: 0.00045	 loss: 0.0009
2022-01-12 08:34:58:INFO:Epoch: 2	 global_step: 2100/3750	 lr: 0.00044	 loss: 0.0007
2022-01-12 08:36:30:INFO:Epoch: 2	 global_step: 2150/3750	 lr: 0.00043	 loss: 0.0009
2022-01-12 08:38:01:INFO:Epoch: 2	 global_step: 2200/3750	 lr: 0.00041	 loss: 0.0008
2022-01-12 08:39:40:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-12 08:39:40:INFO:	Num examples = 100
2022-01-12 08:39:40:INFO:	RMSE = 15.1562
2022-01-12 08:39:48:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-12 08:39:48:INFO:	Num examples = 100
2022-01-12 08:39:48:INFO:	RMSE = 27.9923
2022-01-12 08:39:48:INFO:==> Minimal valid RMSE!
2022-01-12 08:39:48:INFO:Save model to cnn2dmodels/data-1_n_epochs-5_aug-150_noise-0.01_supportSize-5_innerSteps-2_lrMeta-0.001_lrInner-0.0001_warmUp-0.0_seed-128...
2022-01-12 08:39:50:INFO:Epoch: 3	 global_step: 2250/3750	 lr: 0.00040	 loss: 0.0007
2022-01-12 08:41:22:INFO:Epoch: 3	 global_step: 2300/3750	 lr: 0.00039	 loss: 0.0008
2022-01-12 08:42:53:INFO:Epoch: 3	 global_step: 2350/3750	 lr: 0.00037	 loss: 0.0007
2022-01-12 08:44:24:INFO:Epoch: 3	 global_step: 2400/3750	 lr: 0.00036	 loss: 0.0006
2022-01-12 08:45:56:INFO:Epoch: 3	 global_step: 2450/3750	 lr: 0.00035	 loss: 0.0007
2022-01-12 08:47:27:INFO:Epoch: 3	 global_step: 2500/3750	 lr: 0.00033	 loss: 0.0007
2022-01-12 08:48:58:INFO:Epoch: 3	 global_step: 2550/3750	 lr: 0.00032	 loss: 0.0006
2022-01-12 08:50:29:INFO:Epoch: 3	 global_step: 2600/3750	 lr: 0.00031	 loss: 0.0006
2022-01-12 08:52:01:INFO:Epoch: 3	 global_step: 2650/3750	 lr: 0.00029	 loss: 0.0006
2022-01-12 08:53:31:INFO:Epoch: 3	 global_step: 2700/3750	 lr: 0.00028	 loss: 0.0006
2022-01-12 08:55:02:INFO:Epoch: 3	 global_step: 2750/3750	 lr: 0.00027	 loss: 0.0006
2022-01-12 08:56:33:INFO:Epoch: 3	 global_step: 2800/3750	 lr: 0.00025	 loss: 0.0006
2022-01-12 08:58:04:INFO:Epoch: 3	 global_step: 2850/3750	 lr: 0.00024	 loss: 0.0006
2022-01-12 08:59:35:INFO:Epoch: 3	 global_step: 2900/3750	 lr: 0.00023	 loss: 0.0006
2022-01-12 09:01:06:INFO:Epoch: 3	 global_step: 2950/3750	 lr: 0.00021	 loss: 0.0006
2022-01-12 09:02:44:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-12 09:02:44:INFO:	Num examples = 100
2022-01-12 09:02:44:INFO:	RMSE = 14.1903
2022-01-12 09:02:53:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-12 09:02:53:INFO:	Num examples = 100
2022-01-12 09:02:53:INFO:	RMSE = 29.2381
2022-01-12 09:02:54:INFO:Epoch: 4	 global_step: 3000/3750	 lr: 0.00020	 loss: 0.0005
2022-01-12 09:04:26:INFO:Epoch: 4	 global_step: 3050/3750	 lr: 0.00019	 loss: 0.0005
2022-01-12 09:05:57:INFO:Epoch: 4	 global_step: 3100/3750	 lr: 0.00017	 loss: 0.0006
2022-01-12 09:07:28:INFO:Epoch: 4	 global_step: 3150/3750	 lr: 0.00016	 loss: 0.0006
2022-01-12 09:08:59:INFO:Epoch: 4	 global_step: 3200/3750	 lr: 0.00015	 loss: 0.0005
2022-01-12 09:10:30:INFO:Epoch: 4	 global_step: 3250/3750	 lr: 0.00013	 loss: 0.0005
2022-01-12 09:12:01:INFO:Epoch: 4	 global_step: 3300/3750	 lr: 0.00012	 loss: 0.0005
2022-01-12 09:13:32:INFO:Epoch: 4	 global_step: 3350/3750	 lr: 0.00011	 loss: 0.0005
2022-01-12 09:15:03:INFO:Epoch: 4	 global_step: 3400/3750	 lr: 0.00009	 loss: 0.0005
2022-01-12 09:16:35:INFO:Epoch: 4	 global_step: 3450/3750	 lr: 0.00008	 loss: 0.0005
2022-01-12 09:18:05:INFO:Epoch: 4	 global_step: 3500/3750	 lr: 0.00007	 loss: 0.0005
2022-01-12 09:19:37:INFO:Epoch: 4	 global_step: 3550/3750	 lr: 0.00005	 loss: 0.0006
2022-01-12 09:21:08:INFO:Epoch: 4	 global_step: 3600/3750	 lr: 0.00004	 loss: 0.0006
2022-01-12 09:22:40:INFO:Epoch: 4	 global_step: 3650/3750	 lr: 0.00003	 loss: 0.0005
2022-01-12 09:24:11:INFO:Epoch: 4	 global_step: 3700/3750	 lr: 0.00001	 loss: 0.0005
2022-01-12 09:25:50:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-12 09:25:50:INFO:	Num examples = 100
2022-01-12 09:25:50:INFO:	RMSE = 13.8967
2022-01-12 09:25:59:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-12 09:25:59:INFO:	Num examples = 100
2022-01-12 09:25:59:INFO:	RMSE = 32.9399
2022-01-12 09:25:59:INFO:	Output TEST RMSE:	15.1562
2022-01-12 09:25:59:INFO:	VALID RMSEs:	34.6558	37.5380	27.9923	29.2381	32.9399
2022-01-12 09:25:59:INFO:	TEST RMSEs:	19.8765	17.0393	15.1562	14.1903	13.8967
!!! Reset batch info !!! mode: [TRAIN]
!!! Reset batch info !!! mode: [TEST]
!!! Reset batch info !!! mode: [VALID]
!!! Reset batch info !!! mode: [TRAIN]
!!! Reset batch info !!! mode: [TEST]
!!! Reset batch info !!! mode: [VALID]
!!! Reset batch info !!! mode: [TRAIN]
!!! Reset batch info !!! mode: [TEST]
!!! Reset batch info !!! mode: [VALID]
!!! Reset batch info !!! mode: [TRAIN]
!!! Reset batch info !!! mode: [TEST]
!!! Reset batch info !!! mode: [VALID]
2022-01-12 09:26:04:INFO:Finish setting logger...
2022-01-12 09:26:04:INFO:==> Training/Evaluation parameters are:
2022-01-12 09:26:04:INFO:	Namespace(model_dir='cnn2dmodels/data-1_n_epochs-5_aug-150_noise-0.01_supportSize-5_innerSteps-2_lrMeta-0.001_lrInner-0.001_warmUp-0.0_seed-128'
2022-01-12 09:26:04:INFO:	data_fn=1
2022-01-12 09:26:04:INFO:	datatest_fn=1
2022-01-12 09:26:04:INFO:	filter_kernel_size=1
2022-01-12 09:26:04:INFO:	override_data_cache=False
2022-01-12 09:26:04:INFO:	maxRUL=125
2022-01-12 09:26:04:INFO:	low_ratio=0.1
2022-01-12 09:26:04:INFO:	high_ratio=0.99
2022-01-12 09:26:04:INFO:	aug_ratio=150
2022-01-12 09:26:04:INFO:	noise_amplitude=0.01
2022-01-12 09:26:04:INFO:	modeltype='cnn2d'
2022-01-12 09:26:04:INFO:	max_seq_len=550
2022-01-12 09:26:04:INFO:	d_model=128
2022-01-12 09:26:04:INFO:	p_dropout=0.1
2022-01-12 09:26:04:INFO:	n_head=4
2022-01-12 09:26:04:INFO:	n_layer=2
2022-01-12 09:26:04:INFO:	dim_feedforward=512
2022-01-12 09:26:04:INFO:	e_dropout=0.1
2022-01-12 09:26:04:INFO:	activation='relu'
2022-01-12 09:26:04:INFO:	layer_norm=False
2022-01-12 09:26:04:INFO:	support_size=5
2022-01-12 09:26:04:INFO:	inner_steps=2
2022-01-12 09:26:04:INFO:	lr_inner=0.001
2022-01-12 09:26:04:INFO:	lr_meta=0.001
2022-01-12 09:26:04:INFO:	n_epochs=5
2022-01-12 09:26:04:INFO:	train_batch_size=20
2022-01-12 09:26:04:INFO:	eval_batch_size=1
2022-01-12 09:26:04:INFO:	lr=0.001
2022-01-12 09:26:04:INFO:	weight_decay=0.01
2022-01-12 09:26:04:INFO:	warmup_ratio=0.0
2022-01-12 09:26:04:INFO:	max_grad_norm=5.0
2022-01-12 09:26:04:INFO:	logging_steps=50
2022-01-12 09:26:04:INFO:	seed=128
2022-01-12 09:26:04:INFO:	gpu_id=2
2022-01-12 09:26:04:INFO:	do_train=True
2022-01-12 09:26:04:INFO:	do_eval=False
2022-01-12 09:26:04:INFO:	train_data_fn='data/train_FD001.txt'
2022-01-12 09:26:04:INFO:	test_data_fn='data/test_FD001.txt'
2022-01-12 09:26:04:INFO:	target_ruls_fn='data/RUL_FD001.txt'
2022-01-12 09:26:04:INFO:	device=device(type='cuda'))
2022-01-12 09:26:04:INFO:Dump arguments to cnn2dmodels/data-1_n_epochs-5_aug-150_noise-0.01_supportSize-5_innerSteps-2_lrMeta-0.001_lrInner-0.001_warmUp-0.0_seed-128...
2022-01-12 09:26:04:INFO:==> Read data from data/train_FD001.txt...
2022-01-12 09:26:04:INFO:	The selected feature idxs are: 0, 1, 4, 5, 6, 9, 10, 11, 13, 14, 15, 16, 17, 19, 22, 23
2022-01-12 09:26:04:INFO:==> Min_max normalization...
2022-01-12 09:26:04:INFO:	The min value is [-0.008700000122189522, -0.0006000000284984708, 641.2100219726562, 1571.0400390625, 1382.25, 549.8499755859375, 2387.89990234375, 9021.73046875, 46.849998474121094, 518.6900024414062, 2387.8798828125, 8099.93994140625, 8.324899673461914, 388.0, 38.13999938964844, 22.89419937133789]
2022-01-12 09:26:04:INFO:	The max value is [0.008700000122189522, 0.0006000000284984708, 644.530029296875, 1616.9100341796875, 1441.489990234375, 556.0599975585938, 2388.56005859375, 9244.58984375, 48.529998779296875, 523.3800048828125, 2388.56005859375, 8293.7197265625, 8.584799766540527, 400.0, 39.43000030517578, 23.61840057373047]
2022-01-12 09:26:04:INFO:==> Read data from data/test_FD001.txt...
2022-01-12 09:26:04:INFO:	The selected feature idxs are: 0, 1, 4, 5, 6, 9, 10, 11, 13, 14, 15, 16, 17, 19, 22, 23
2022-01-12 09:26:04:INFO:==> Read RULsfrom data/RUL_FD001.txt...
2022-01-12 09:26:04:INFO:	min_rul: 7, max_rul: 145
2022-01-12 09:26:04:INFO:==> Input length ratio of the [TEST] data:
2022-01-12 09:26:04:INFO:	min_ratio = 0.2067
2022-01-12 09:26:04:INFO:	max_ratio = 0.9667
2022-01-12 09:26:04:INFO:==> Min_max normalization...
2022-01-12 09:26:04:INFO:	With given min value [-0.008700000122189522, -0.0006000000284984708, 641.2100219726562, 1571.0400390625, 1382.25, 549.8499755859375, 2387.89990234375, 9021.73046875, 46.849998474121094, 518.6900024414062, 2387.8798828125, 8099.93994140625, 8.324899673461914, 388.0, 38.13999938964844, 22.89419937133789]
2022-01-12 09:26:04:INFO:	With given max value [0.008700000122189522, 0.0006000000284984708, 644.530029296875, 1616.9100341796875, 1441.489990234375, 556.0599975585938, 2388.56005859375, 9244.58984375, 48.529998779296875, 523.3800048828125, 2388.56005859375, 8293.7197265625, 8.584799766540527, 400.0, 39.43000030517578, 23.61840057373047]
2022-01-12 09:26:04:INFO:==> Computing Criterion...
2022-01-12 09:26:05:INFO:	The weights are: 0.007887763902544975, 0.008001004345715046, 0.06667434424161911, 0.0634712353348732, 0.07656104862689972, 0.0755249634385109, 0.06726357340812683, 0.0644979178905487, 0.0795108750462532, 0.07743842899799347, 0.0671684592962265, 0.06869389116764069, 0.07147877663373947, 0.06516212970018387, 0.07012488692998886, 0.07054071873426437
2022-01-12 09:26:18:INFO:Note: NumExpr detected 40 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
2022-01-12 09:26:18:INFO:NumExpr defaulting to 8 threads.
2022-01-12 09:26:18:INFO:=============== Scheme: Meta Learning ===============
2022-01-12 09:26:18:INFO:	Num examples = 15000
2022-01-12 09:26:18:INFO:	Num epochs = 5
2022-01-12 09:26:18:INFO:	Batch size = 20
2022-01-12 09:26:18:INFO:	Total meta optimization steps = 3750
2022-01-12 09:26:18:INFO:	Total inner optimization steps = 7500
2022-01-12 09:26:26:INFO:==> Group parameters for optimization...
2022-01-12 09:26:26:INFO:    Parameters to update are:
2022-01-12 09:26:26:INFO:	conv1.0.weight
2022-01-12 09:26:26:INFO:	conv2.0.weight
2022-01-12 09:26:26:INFO:	conv3.0.weight
2022-01-12 09:26:26:INFO:	conv4.0.weight
2022-01-12 09:26:26:INFO:	conv5.0.weight
2022-01-12 09:26:26:INFO:	fc_1.0.weight
2022-01-12 09:26:26:INFO:	fc_1.0.bias
2022-01-12 09:26:26:INFO:	fc_2.weight
2022-01-12 09:26:26:INFO:	fc_2.bias
/data/moy20/Meta-Learning/Meta-prognosis-main/optimizer.py:78: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448255797/work/torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
/data/moy20/miniconda3/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
2022-01-12 09:26:29:INFO:Epoch: 0	 global_step: 0/3750	 lr: 0.00100	 loss: 0.0011
2022-01-12 09:28:01:INFO:Epoch: 0	 global_step: 50/3750	 lr: 0.00099	 loss: 0.0256
2022-01-12 09:29:32:INFO:Epoch: 0	 global_step: 100/3750	 lr: 0.00097	 loss: 0.0098
2022-01-12 09:31:03:INFO:Epoch: 0	 global_step: 150/3750	 lr: 0.00096	 loss: 0.0065
2022-01-12 09:32:35:INFO:Epoch: 0	 global_step: 200/3750	 lr: 0.00095	 loss: 0.0050
2022-01-12 09:34:06:INFO:Epoch: 0	 global_step: 250/3750	 lr: 0.00093	 loss: 0.0054
2022-01-12 09:35:38:INFO:Epoch: 0	 global_step: 300/3750	 lr: 0.00092	 loss: 0.0045
2022-01-12 09:37:09:INFO:Epoch: 0	 global_step: 350/3750	 lr: 0.00091	 loss: 0.0036
2022-01-12 09:38:41:INFO:Epoch: 0	 global_step: 400/3750	 lr: 0.00089	 loss: 0.0037
2022-01-12 09:40:12:INFO:Epoch: 0	 global_step: 450/3750	 lr: 0.00088	 loss: 0.0026
2022-01-12 09:41:43:INFO:Epoch: 0	 global_step: 500/3750	 lr: 0.00087	 loss: 0.0027
2022-01-12 09:43:14:INFO:Epoch: 0	 global_step: 550/3750	 lr: 0.00085	 loss: 0.0024
2022-01-12 09:44:46:INFO:Epoch: 0	 global_step: 600/3750	 lr: 0.00084	 loss: 0.0021
2022-01-12 09:46:17:INFO:Epoch: 0	 global_step: 650/3750	 lr: 0.00083	 loss: 0.0017
2022-01-12 09:47:49:INFO:Epoch: 0	 global_step: 700/3750	 lr: 0.00081	 loss: 0.0018
2022-01-12 09:49:28:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-12 09:49:28:INFO:	Num examples = 100
2022-01-12 09:49:28:INFO:	RMSE = 19.8765
2022-01-12 09:49:36:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-12 09:49:36:INFO:	Num examples = 100
2022-01-12 09:49:36:INFO:	RMSE = 34.6558
2022-01-12 09:49:36:INFO:==> Minimal valid RMSE!
2022-01-12 09:49:36:INFO:Save model to cnn2dmodels/data-1_n_epochs-5_aug-150_noise-0.01_supportSize-5_innerSteps-2_lrMeta-0.001_lrInner-0.001_warmUp-0.0_seed-128...
2022-01-12 09:49:38:INFO:Epoch: 1	 global_step: 750/3750	 lr: 0.00080	 loss: 0.0019
2022-01-12 09:51:10:INFO:Epoch: 1	 global_step: 800/3750	 lr: 0.00079	 loss: 0.0015
2022-01-12 09:52:41:INFO:Epoch: 1	 global_step: 850/3750	 lr: 0.00077	 loss: 0.0029
2022-01-12 09:54:12:INFO:Epoch: 1	 global_step: 900/3750	 lr: 0.00076	 loss: 0.0017
2022-01-12 09:55:43:INFO:Epoch: 1	 global_step: 950/3750	 lr: 0.00075	 loss: 0.0015
2022-01-12 09:57:14:INFO:Epoch: 1	 global_step: 1000/3750	 lr: 0.00073	 loss: 0.0015
2022-01-12 09:58:46:INFO:Epoch: 1	 global_step: 1050/3750	 lr: 0.00072	 loss: 0.0014
2022-01-12 10:00:17:INFO:Epoch: 1	 global_step: 1100/3750	 lr: 0.00071	 loss: 0.0013
2022-01-12 10:01:48:INFO:Epoch: 1	 global_step: 1150/3750	 lr: 0.00069	 loss: 0.0013
2022-01-12 10:03:20:INFO:Epoch: 1	 global_step: 1200/3750	 lr: 0.00068	 loss: 0.0013
2022-01-12 10:04:51:INFO:Epoch: 1	 global_step: 1250/3750	 lr: 0.00067	 loss: 0.0011
2022-01-12 10:06:22:INFO:Epoch: 1	 global_step: 1300/3750	 lr: 0.00065	 loss: 0.0012
2022-01-12 10:07:54:INFO:Epoch: 1	 global_step: 1350/3750	 lr: 0.00064	 loss: 0.0012
2022-01-12 10:09:25:INFO:Epoch: 1	 global_step: 1400/3750	 lr: 0.00063	 loss: 0.0010
2022-01-12 10:10:57:INFO:Epoch: 1	 global_step: 1450/3750	 lr: 0.00061	 loss: 0.0011
2022-01-12 10:12:35:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-12 10:12:35:INFO:	Num examples = 100
2022-01-12 10:12:35:INFO:	RMSE = 17.0393
2022-01-12 10:12:44:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-12 10:12:44:INFO:	Num examples = 100
2022-01-12 10:12:44:INFO:	RMSE = 37.5380
2022-01-12 10:12:45:INFO:Epoch: 2	 global_step: 1500/3750	 lr: 0.00060	 loss: 0.0010
2022-01-12 10:14:17:INFO:Epoch: 2	 global_step: 1550/3750	 lr: 0.00059	 loss: 0.0010
2022-01-12 10:15:48:INFO:Epoch: 2	 global_step: 1600/3750	 lr: 0.00057	 loss: 0.0011
2022-01-12 10:17:19:INFO:Epoch: 2	 global_step: 1650/3750	 lr: 0.00056	 loss: 0.0011
2022-01-12 10:18:50:INFO:Epoch: 2	 global_step: 1700/3750	 lr: 0.00055	 loss: 0.0010
2022-01-12 10:20:21:INFO:Epoch: 2	 global_step: 1750/3750	 lr: 0.00053	 loss: 0.0009
2022-01-12 10:21:52:INFO:Epoch: 2	 global_step: 1800/3750	 lr: 0.00052	 loss: 0.0010
2022-01-12 10:23:22:INFO:Epoch: 2	 global_step: 1850/3750	 lr: 0.00051	 loss: 0.0009
2022-01-12 10:24:53:INFO:Epoch: 2	 global_step: 1900/3750	 lr: 0.00049	 loss: 0.0009
2022-01-12 10:26:25:INFO:Epoch: 2	 global_step: 1950/3750	 lr: 0.00048	 loss: 0.0009
2022-01-12 10:27:56:INFO:Epoch: 2	 global_step: 2000/3750	 lr: 0.00047	 loss: 0.0008
2022-01-12 10:29:27:INFO:Epoch: 2	 global_step: 2050/3750	 lr: 0.00045	 loss: 0.0009
2022-01-12 10:30:58:INFO:Epoch: 2	 global_step: 2100/3750	 lr: 0.00044	 loss: 0.0007
2022-01-12 10:32:30:INFO:Epoch: 2	 global_step: 2150/3750	 lr: 0.00043	 loss: 0.0009
2022-01-12 10:34:03:INFO:Epoch: 2	 global_step: 2200/3750	 lr: 0.00041	 loss: 0.0008
2022-01-12 10:35:43:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-12 10:35:43:INFO:	Num examples = 100
2022-01-12 10:35:43:INFO:	RMSE = 15.1562
2022-01-12 10:35:52:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-12 10:35:52:INFO:	Num examples = 100
2022-01-12 10:35:52:INFO:	RMSE = 27.9923
2022-01-12 10:35:52:INFO:==> Minimal valid RMSE!
2022-01-12 10:35:52:INFO:Save model to cnn2dmodels/data-1_n_epochs-5_aug-150_noise-0.01_supportSize-5_innerSteps-2_lrMeta-0.001_lrInner-0.001_warmUp-0.0_seed-128...
2022-01-12 10:35:54:INFO:Epoch: 3	 global_step: 2250/3750	 lr: 0.00040	 loss: 0.0007
2022-01-12 10:37:25:INFO:Epoch: 3	 global_step: 2300/3750	 lr: 0.00039	 loss: 0.0008
2022-01-12 10:38:57:INFO:Epoch: 3	 global_step: 2350/3750	 lr: 0.00037	 loss: 0.0007
2022-01-12 10:40:28:INFO:Epoch: 3	 global_step: 2400/3750	 lr: 0.00036	 loss: 0.0006
2022-01-12 10:42:00:INFO:Epoch: 3	 global_step: 2450/3750	 lr: 0.00035	 loss: 0.0007
2022-01-12 10:43:31:INFO:Epoch: 3	 global_step: 2500/3750	 lr: 0.00033	 loss: 0.0007
2022-01-12 10:45:02:INFO:Epoch: 3	 global_step: 2550/3750	 lr: 0.00032	 loss: 0.0006
2022-01-12 10:46:34:INFO:Epoch: 3	 global_step: 2600/3750	 lr: 0.00031	 loss: 0.0006
2022-01-12 10:48:05:INFO:Epoch: 3	 global_step: 2650/3750	 lr: 0.00029	 loss: 0.0006
2022-01-12 10:49:37:INFO:Epoch: 3	 global_step: 2700/3750	 lr: 0.00028	 loss: 0.0006
2022-01-12 10:51:08:INFO:Epoch: 3	 global_step: 2750/3750	 lr: 0.00027	 loss: 0.0006
2022-01-12 10:52:40:INFO:Epoch: 3	 global_step: 2800/3750	 lr: 0.00025	 loss: 0.0006
2022-01-12 10:54:12:INFO:Epoch: 3	 global_step: 2850/3750	 lr: 0.00024	 loss: 0.0006
2022-01-12 10:55:43:INFO:Epoch: 3	 global_step: 2900/3750	 lr: 0.00023	 loss: 0.0006
2022-01-12 10:57:15:INFO:Epoch: 3	 global_step: 2950/3750	 lr: 0.00021	 loss: 0.0006
2022-01-12 10:58:53:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-12 10:58:53:INFO:	Num examples = 100
2022-01-12 10:58:53:INFO:	RMSE = 14.1903
2022-01-12 10:59:02:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-12 10:59:02:INFO:	Num examples = 100
2022-01-12 10:59:02:INFO:	RMSE = 29.2381
2022-01-12 10:59:04:INFO:Epoch: 4	 global_step: 3000/3750	 lr: 0.00020	 loss: 0.0005
2022-01-12 11:00:35:INFO:Epoch: 4	 global_step: 3050/3750	 lr: 0.00019	 loss: 0.0005
2022-01-12 11:02:07:INFO:Epoch: 4	 global_step: 3100/3750	 lr: 0.00017	 loss: 0.0006
2022-01-12 11:03:38:INFO:Epoch: 4	 global_step: 3150/3750	 lr: 0.00016	 loss: 0.0006
2022-01-12 11:05:10:INFO:Epoch: 4	 global_step: 3200/3750	 lr: 0.00015	 loss: 0.0005
2022-01-12 11:06:41:INFO:Epoch: 4	 global_step: 3250/3750	 lr: 0.00013	 loss: 0.0005
2022-01-12 11:08:13:INFO:Epoch: 4	 global_step: 3300/3750	 lr: 0.00012	 loss: 0.0005
2022-01-12 11:09:44:INFO:Epoch: 4	 global_step: 3350/3750	 lr: 0.00011	 loss: 0.0005
2022-01-12 11:11:15:INFO:Epoch: 4	 global_step: 3400/3750	 lr: 0.00009	 loss: 0.0005
2022-01-12 11:12:46:INFO:Epoch: 4	 global_step: 3450/3750	 lr: 0.00008	 loss: 0.0005
2022-01-12 11:14:18:INFO:Epoch: 4	 global_step: 3500/3750	 lr: 0.00007	 loss: 0.0005
2022-01-12 11:15:49:INFO:Epoch: 4	 global_step: 3550/3750	 lr: 0.00005	 loss: 0.0006
2022-01-12 11:17:20:INFO:Epoch: 4	 global_step: 3600/3750	 lr: 0.00004	 loss: 0.0006
2022-01-12 11:18:52:INFO:Epoch: 4	 global_step: 3650/3750	 lr: 0.00003	 loss: 0.0005
2022-01-12 11:20:23:INFO:Epoch: 4	 global_step: 3700/3750	 lr: 0.00001	 loss: 0.0005
2022-01-12 11:22:01:INFO:############### Compute RMSEs @ mode [TEST] ###############
2022-01-12 11:22:01:INFO:	Num examples = 100
2022-01-12 11:22:01:INFO:	RMSE = 13.8967
2022-01-12 11:22:10:INFO:############### Compute RMSEs @ mode [VALID] ###############
2022-01-12 11:22:10:INFO:	Num examples = 100
2022-01-12 11:22:10:INFO:	RMSE = 32.9399
2022-01-12 11:22:10:INFO:	Output TEST RMSE:	15.1562
2022-01-12 11:22:10:INFO:	VALID RMSEs:	34.6558	37.5380	27.9923	29.2381	32.9399
2022-01-12 11:22:10:INFO:	TEST RMSEs:	19.8765	17.0393	15.1562	14.1903	13.8967
!!! Reset batch info !!! mode: [TRAIN]
!!! Reset batch info !!! mode: [TEST]
!!! Reset batch info !!! mode: [VALID]
!!! Reset batch info !!! mode: [TRAIN]
!!! Reset batch info !!! mode: [TEST]
!!! Reset batch info !!! mode: [VALID]
!!! Reset batch info !!! mode: [TRAIN]
!!! Reset batch info !!! mode: [TEST]
!!! Reset batch info !!! mode: [VALID]
!!! Reset batch info !!! mode: [TRAIN]
!!! Reset batch info !!! mode: [TEST]
!!! Reset batch info !!! mode: [VALID]
